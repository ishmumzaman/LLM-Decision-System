{"run_id": "regression:postgresql_docs_mvp_v1:20251229T232339Z:001:what_is_postgresql", "timestamp": "2025-12-29T23:23:44.321776Z", "domain": "postgresql_docs", "mode": "docs", "query": "What is PostgreSQL and what is it commonly used for?", "case": {"id": "what_is_postgresql", "tags": ["intro"], "answerable_from_general_knowledge": true, "requires_docs": false, "expected_abstain_in_docs": null}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "PostgreSQL is an open-source relational database management system (RDBMS) that is known for its robustness, extensibility, and standards compliance. It is designed to handle a wide range of workloads, from single machines to data warehouses or web services with many concurrent users.\n\nCommon uses of PostgreSQL include:\n\n1. **Web Applications**: It is often used as the backend database for web applications due to its reliability and performance.\n2. **Data Warehousing**: PostgreSQL can be used for analytical queries and data warehousing tasks.\n3. **Geospatial Applications**: With the PostGIS extension, PostgreSQL is widely used for geographic information systems (GIS) and spatial data analysis.\n4. **Business Applications**: Many enterprise applications use PostgreSQL for transaction processing and data management.\n5. **Scientific Data Management**: It is also used in research and scientific applications for managing large datasets.\n\nOverall, PostgreSQL is valued for its advanced features, such as support for complex queries, foreign keys, triggers, views, stored procedures, and more.", "latency_ms": 4683, "tokens_in": 146, "tokens_out": 213, "cost_estimate_usd": 0.00014969999999999998, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "PostgreSQL is an open-source descendant of the original Berkeley code from the POSTGRES project, which began in 1986. It supports a large part of the SQL standard and offers many modern features, including complex queries, foreign keys, triggers, updatable views, transactional integrity, and multiversion concurrency control (MVCC) [6708]. \n\nIt is commonly used for managing relational databases and is known for its robustness, extensibility, and support for advanced data types and performance optimization features [6708].", "latency_ms": 4188, "tokens_in": 1394, "tokens_out": 104, "cost_estimate_usd": 0.00027150000000000004, "retrieved_chunks": [{"chunk_id": 5837, "source": "domains/postgresql_docs/data/history.sgml", "text_preview": "k at Postgres</quote>\n  <xref linkend=\"hell18\"/>.\n </para>\n\n <sect2 id=\"history-berkeley\">\n  <title>The Berkeley <productname>POSTGRES</productname> Project</title>\n\n  <indexterm zone=\"history-berkeley\">\n   <primary>POSTGRES</primary>\n  </indexterm>\n\n  <para>\n   The <productname>POSTGRES</productname> project, led by Professor\n   Michael Stonebraker, was sponsored by the Defense Advanced Research\n   Projects Agency (<acronym>DARPA</acronym>), the Army Research\n   Office (<acronym>ARO</acronym>), the National Science Foundation\n   (<acronym>NSF</acronym>), and ESL, Inc.  The implementation of\n   <productname>POSTGRES</productname> began in 1986.  The initial\n   concepts for the system were presented in <xref linkend=\"ston86\"/>,\n   and the definition of the initial data model appeared in <xref\n   linkend=\"rowe87\"/>.  The design of the rule system at that time was\n   described in <xref link", "score": 0.554345965385437}, {"chunk_id": 6708, "source": "domains/postgresql_docs/data/intro.sgml", "text_preview": "ble in some commercial database systems much later.\n  </para>\n\n  <para>\n   <productname>PostgreSQL</productname> is an open-source descendant\n   of this original Berkeley code.  It supports a large part of the SQL\n   standard and offers many modern features:\n\n   <itemizedlist spacing=\"compact\">\n    <listitem>\n     <simpara><link linkend=\"sql\">complex queries</link></simpara>\n    </listitem>\n    <listitem>\n     <simpara><link linkend=\"ddl-constraints-fk\">foreign keys</link></simpara>\n    </listitem>\n    <listitem>\n     <simpara><link linkend=\"triggers\">triggers</link></simpara>\n    </listitem>\n    <listitem>\n     <simpara><link linkend=\"sql-createview-updatable-views\">updatable views</link></simpara>\n    </listitem>\n    <listitem>\n     <simpara><link linkend=\"transaction-iso\">transactional integrity</link></simpara>\n    </listitem>\n    <listitem>\n     <simpara><link linkend=\"mvcc\">multive", "score": 0.5531245470046997}, {"chunk_id": 10690, "source": "domains/postgresql_docs/data/ref/alter_trigger.sgml", "text_preview": "e>PostgreSQL</productname>\n   extension of the SQL standard.\n  </para>\n </refsect1>\n\n <refsect1>\n  <title>See Also</title>\n\n  <simplelist type=\"inline\">\n   <member><xref linkend=\"sql-altertable\"/></member>\n  </simplelist>\n </refsect1>\n</refentry>", "score": 0.5431632399559021}, {"chunk_id": 9080, "source": "domains/postgresql_docs/data/plpgsql.sgml", "text_preview": "putation functions and later use\n    them to define operators or use them in index expressions.\n   </para>\n\n   <para>\n    In <productname>PostgreSQL</productname> 9.0 and later,\n    <application>PL/pgSQL</application> is installed by default.\n    However it is still a loadable module, so especially security-conscious\n    administrators could choose to remove it.\n   </para>\n\n  <sect2 id=\"plpgsql-advantages\">\n   <title>Advantages of Using <application>PL/pgSQL</application></title>\n\n    <para>\n     <acronym>SQL</acronym> is the language <productname>PostgreSQL</productname>\n     and most other relational databases use as query language. It's\n     portable and easy to learn. But every <acronym>SQL</acronym>\n     statement must be executed individually by the database server.\n    </para>\n\n    <para>\n     That means that your client application must send each query to\n     the database server", "score": 0.5362441539764404}, {"chunk_id": 7420, "source": "domains/postgresql_docs/data/lobj.sgml", "text_preview": "ge object data.  We use the <application>libpq</application> C\n    library for the examples in this chapter, but most programming\n    interfaces native to <productname>PostgreSQL</productname> support\n    equivalent functionality.  Other interfaces might use the large\n    object interface internally to provide generic support for large\n    values.  This is not described here.\n   </para>\n\n  <sect1 id=\"lo-intro\">\n   <title>Introduction</title>\n\n   <indexterm>\n    <primary>TOAST</primary>\n    <secondary>versus large objects</secondary>\n   </indexterm>\n\n   <para>\n    All large objects are stored in a single system table named <link\n    linkend=\"catalog-pg-largeobject\"><structname>pg_largeobject</structname></link>.\n    Each large object also has an entry in the system table <link\n    linkend=\"catalog-pg-largeobject-metadata\"><structname>pg_largeobject_metadata</structname></link>.\n    Large", "score": 0.5288234353065491}, {"chunk_id": 11435, "source": "domains/postgresql_docs/data/ref/create_schema.sgml", "text_preview": ">PostgreSQL</productname> extension.\n  </para>\n </refsect1>\n\n <refsect1>\n  <title>See Also</title>\n\n  <simplelist type=\"inline\">\n   <member><xref linkend=\"sql-alterschema\"/></member>\n   <member><xref linkend=\"sql-dropschema\"/></member>\n </simplelist>\n </refsect1>\n\n</refentry>", "score": 0.5239441394805908}], "flags": {}, "error": null}, "finetune": {"pipeline": "finetune", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "", "latency_ms": 0, "tokens_in": null, "tokens_out": null, "cost_estimate_usd": null, "retrieved_chunks": null, "flags": {}, "error": "MISSING_FINETUNED_MODEL: set OPENAI_FINETUNED_MODEL or domains/<domain>/config.yaml finetuned_model"}}, "evaluations": {"prompt": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}, "rag": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}, "finetune": {"quality_score": null, "penalty_total": null, "rule_breakdown": [], "expect_score": null, "expect_details": null, "abstained": null, "abstention_expected": null, "abstention_correct": null, "abstention_score": null, "hallucination_flags": [], "grounding_flags": [], "notes": null}}, "summary_metrics": {"winner_by_quality": null, "winner_by_quality_ties": ["prompt", "rag"], "winner_by_latency": "rag", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": null, "winner_by_expect_ties": ["prompt", "rag"]}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251229T232339Z:002:create_table_basics", "timestamp": "2025-12-29T23:23:47.213097Z", "domain": "postgresql_docs", "mode": "docs", "query": "How do I create a table in PostgreSQL? Show a minimal example.", "case": {"id": "create_table_basics", "tags": ["sql", "ddl"], "answerable_from_general_knowledge": true, "requires_docs": false, "expected_abstain_in_docs": null}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "To create a table in PostgreSQL, you use the `CREATE TABLE` statement followed by the table name and the definition of its columns. Here is a minimal example:\n\n```sql\nCREATE TABLE my_table (\n    id SERIAL PRIMARY KEY,\n    name VARCHAR(100)\n);\n```\n\nIn this example:\n- `my_table` is the name of the table.\n- `id` is an integer column that automatically increments (due to the `SERIAL` type) and serves as the primary key.\n- `name` is a variable character string column with a maximum length of 100 characters. \n\nThis is a basic structure to create a table in PostgreSQL.", "latency_ms": 2461, "tokens_in": 149, "tokens_out": 134, "cost_estimate_usd": 0.00010275, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "To create a table in PostgreSQL, you can use the `CREATE TABLE` statement followed by the table name and the definitions of its columns. Here is a minimal example:\n\n```sql\nCREATE TABLE weather (\n    city varchar(80),\n    temp_lo int,\n    temp_hi int\n);\n```\n\nIn this example, a table named `weather` is created with three columns: `city`, `temp_lo`, and `temp_hi`, where `city` is of type `varchar(80)` and both `temp_lo` and `temp_hi` are of type `int` [10118].", "latency_ms": 2862, "tokens_in": 1671, "tokens_out": 122, "cost_estimate_usd": 0.00032385, "retrieved_chunks": [{"chunk_id": 11524, "source": "domains/postgresql_docs/data/ref/create_table.sgml", "text_preview": "<!--\ndoc/src/sgml/ref/create_table.sgml\nPostgreSQL documentation\n-->\n\n<refentry id=\"sql-createtable\">\n <indexterm zone=\"sql-createtable\">\n  <primary>CREATE TABLE</primary>\n </indexterm>\n\n <refmeta>\n  <refentrytitle>CREATE TABLE</refentrytitle>\n  <manvolnum>7</manvolnum>\n  <refmiscinfo>SQL - Language Statements</refmiscinfo>\n </refmeta>\n\n <refnamediv>\n  <refname>CREATE TABLE</refname>\n  <refpurpose>define a new table</refpurpose>\n </refnamediv>\n\n <refsynopsisdiv>\n<synopsis>\nCREATE [ [ GLOBAL | LOCAL ] { TEMPORARY | TEMP } | UNLOGGED ] TABLE [ IF NOT EXISTS ] <replaceable class=\"parameter\">table_name</replaceable> ( [\n  { <replaceable class=\"parameter\">column_name</replaceable> <replaceable class=\"parameter\">data_type</replaceable> [ STORAGE { PLAIN | EXTERNAL | EXTENDED | MAIN | DEFAULT } ] [ COMPRESSION <replaceable>compression_method</replaceable> ] [ COLLATE <replaceable>collation</rep", "score": 0.6500338912010193}, {"chunk_id": 432, "source": "domains/postgresql_docs/data/bki.sgml", "text_preview": "ill create the table\n   <literal>test_table</literal> with OID 420, having three columns\n   <literal>oid</literal>, <literal>cola</literal> and <literal>colb</literal>\n   of type <type>oid</type>, <type>int4</type> and <type>text</type>,\n   respectively, and insert two rows into the table:\n<programlisting>\ncreate test_table 420 (oid = oid, cola = int4, colb = text)\nopen test_table\ninsert ( 421 1 'value 1' )\ninsert ( 422 2 _null_ )\nclose test_table\n</programlisting>\n  </para>\n </sect1>\n</chapter>", "score": 0.6008813381195068}, {"chunk_id": 11677, "source": "domains/postgresql_docs/data/ref/create_table_as.sgml", "text_preview": "<!--\ndoc/src/sgml/ref/create_table_as.sgml\nPostgreSQL documentation\n-->\n\n<refentry id=\"sql-createtableas\">\n <indexterm zone=\"sql-createtableas\">\n  <primary>CREATE TABLE AS</primary>\n </indexterm>\n\n <refmeta>\n  <refentrytitle>CREATE TABLE AS</refentrytitle>\n  <manvolnum>7</manvolnum>\n  <refmiscinfo>SQL - Language Statements</refmiscinfo>\n </refmeta>\n\n <refnamediv>\n  <refname>CREATE TABLE AS</refname>\n  <refpurpose>define a new table from the results of a query</refpurpose>\n </refnamediv>\n\n <refsynopsisdiv>\n<synopsis>\nCREATE [ [ GLOBAL | LOCAL ] { TEMPORARY | TEMP } | UNLOGGED ] TABLE [ IF NOT EXISTS ] <replaceable>table_name</replaceable>\n    [ (<replaceable>column_name</replaceable> [, ...] ) ]\n    [ USING <replaceable class=\"parameter\">method</replaceable> ]\n    [ WITH ( <replaceable class=\"parameter\">storage_parameter</replaceable> [= <replaceable class=\"parameter\">value</replaceable>]", "score": 0.5858688354492188}, {"chunk_id": 10118, "source": "domains/postgresql_docs/data/query.sgml", "text_preview": "isplay).\n   </para>\n\n   <para>\n    <indexterm><primary>database cluster</primary></indexterm>\n    <indexterm><primary>cluster</primary><secondary>of databases</secondary><see>database cluster</see></indexterm>\n\n    Tables are grouped into databases, and a collection of databases\n    managed by a single <productname>PostgreSQL</productname> server\n    instance constitutes a database <firstterm>cluster</firstterm>.\n   </para>\n  </sect1>\n\n\n  <sect1 id=\"tutorial-table\">\n   <title>Creating a New Table</title>\n\n   <indexterm zone=\"tutorial-table\">\n    <primary>CREATE TABLE</primary>\n   </indexterm>\n\n   <para>\n    You  can  create  a  new  table by specifying the table\n    name, along with all column names and their types:\n\n<programlisting>\nCREATE TABLE weather (\n    city            varchar(80),\n    temp_lo         int,           -- low temperature\n    temp_hi         int,           -- high tem", "score": 0.5616394281387329}, {"chunk_id": 11024, "source": "domains/postgresql_docs/data/ref/create_database.sgml", "text_preview": "[ COLLATION_VERSION = <replaceable>collation_version</replaceable> ]\n           [ TABLESPACE [=] <replaceable class=\"parameter\">tablespace_name</replaceable> ]\n           [ ALLOW_CONNECTIONS [=] <replaceable class=\"parameter\">allowconn</replaceable> ]\n           [ CONNECTION LIMIT [=] <replaceable class=\"parameter\">connlimit</replaceable> ]\n           [ IS_TEMPLATE [=] <replaceable class=\"parameter\">istemplate</replaceable> ]\n           [ OID [=] <replaceable class=\"parameter\">oid</replaceable> ]\n</synopsis>\n </refsynopsisdiv>\n\n <refsect1>\n  <title>Description</title>\n\n  <para>\n   <command>CREATE DATABASE</command> creates a new\n   <productname>PostgreSQL</productname> database.\n  </para>\n\n  <para>\n   To create a database, you must be a superuser or have the special\n   <literal>CREATEDB</literal> privilege.\n   See <xref linkend=\"sql-createrole\"/>.\n  </para>\n\n  <para>\n   By defa", "score": 0.557640790939331}, {"chunk_id": 11093, "source": "domains/postgresql_docs/data/ref/create_foreign_table.sgml", "text_preview": "<!--\ndoc/src/sgml/ref/create_foreign_table.sgml\nPostgreSQL documentation\n-->\n\n<refentry id=\"sql-createforeigntable\">\n <indexterm zone=\"sql-createforeigntable\">\n  <primary>CREATE FOREIGN TABLE</primary>\n </indexterm>\n\n <refmeta>\n  <refentrytitle>CREATE FOREIGN TABLE</refentrytitle>\n  <manvolnum>7</manvolnum>\n  <refmiscinfo>SQL - Language Statements</refmiscinfo>\n </refmeta>\n\n <refnamediv>\n  <refname>CREATE FOREIGN TABLE</refname>\n  <refpurpose>define a new foreign table</refpurpose>\n </refnamediv>\n\n <refsynopsisdiv>\n<synopsis>\nCREATE FOREIGN TABLE [ IF NOT EXISTS ] <replaceable class=\"parameter\">table_name</replaceable> ( [\n  { <replaceable class=\"parameter\">column_name</replaceable> <replaceable class=\"parameter\">data_type</replaceable> [ OPTIONS ( <replaceable class=\"parameter\">option</replaceable> '<replaceable class=\"parameter\">value</replaceable>' [, ... ] ) ] [ COLLATE <replaceable>", "score": 0.5558017492294312}], "flags": {}, "error": null}, "finetune": {"pipeline": "finetune", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "", "latency_ms": 0, "tokens_in": null, "tokens_out": null, "cost_estimate_usd": null, "retrieved_chunks": null, "flags": {}, "error": "MISSING_FINETUNED_MODEL: set OPENAI_FINETUNED_MODEL or domains/<domain>/config.yaml finetuned_model"}}, "evaluations": {"prompt": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}, "rag": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}, "finetune": {"quality_score": null, "penalty_total": null, "rule_breakdown": [], "expect_score": null, "expect_details": null, "abstained": null, "abstention_expected": null, "abstention_correct": null, "abstention_score": null, "hallucination_flags": [], "grounding_flags": [], "notes": null}}, "summary_metrics": {"winner_by_quality": null, "winner_by_quality_ties": ["prompt", "rag"], "winner_by_latency": "prompt", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": null, "winner_by_expect_ties": ["prompt", "rag"]}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251229T232339Z:003:primary_key", "timestamp": "2025-12-29T23:23:51.646269Z", "domain": "postgresql_docs", "mode": "docs", "query": "How do I define a primary key in PostgreSQL?", "case": {"id": "primary_key", "tags": ["sql", "ddl"], "answerable_from_general_knowledge": true, "requires_docs": false, "expected_abstain_in_docs": null}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "In PostgreSQL, you can define a primary key using the `PRIMARY KEY` constraint when creating a table. This can be done either in the column definition or as a table constraint. \n\nHere are two common ways to define a primary key:\n\n1. **In the column definition**:\n   ```sql\n   CREATE TABLE my_table (\n       id SERIAL PRIMARY KEY,\n       name VARCHAR(100)\n   );\n   ```\n\n2. **As a table constraint**:\n   ```sql\n   CREATE TABLE my_table (\n       id SERIAL,\n       name VARCHAR(100),\n       CONSTRAINT my_table_pkey PRIMARY KEY (id)\n   );\n   ```\n\nIn both examples, the `id` column is defined as the primary key, which means it must contain unique values and cannot be null.\n\nYou can also add a primary key to an existing table using the `ALTER TABLE` statement:\n```sql\nALTER TABLE my_table\nADD CONSTRAINT my_table_pkey PRIMARY KEY (id);\n```\n\nFor more details, you can refer to the official PostgreSQL documentation on constraints.", "latency_ms": 3632, "tokens_in": 145, "tokens_out": 216, "cost_estimate_usd": 0.00015134999999999997, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "To define a primary key in PostgreSQL, you can use the `PRIMARY KEY` constraint in your `CREATE TABLE` statement. This can be applied to a single column or a group of columns. For example, you can define a primary key on a single column like this:\n\n```sql\nCREATE TABLE products (\n    product_no integer PRIMARY KEY,\n    name text,\n    price numeric\n);\n```\n\nAlternatively, you can define a primary key that spans multiple columns, as shown in the following example:\n\n```sql\nCREATE TABLE example (\n    a integer,\n    b integer,\n    c integer,\n    PRIMARY KEY (a, c)\n);\n```\n\nWhen you add a primary key, PostgreSQL automatically creates a unique B-tree index on the specified column(s) and enforces that the values are both unique and not null [2675][2674].", "latency_ms": 4416, "tokens_in": 1609, "tokens_out": 172, "cost_estimate_usd": 0.00034455, "retrieved_chunks": [{"chunk_id": 2675, "source": "domains/postgresql_docs/data/ddl.sgml", "text_preview": "b integer,\n    c integer,\n    <emphasis>PRIMARY KEY (a, c)</emphasis>\n);\n</programlisting>\n   </para>\n\n   <para>\n    Adding a primary key will automatically create a unique B-tree index\n    on the column or group of columns listed in the primary key, and will\n    force the column(s) to be marked <literal>NOT NULL</literal>.\n   </para>\n\n   <para>\n    A table can have at most one primary key.  (There can be any number\n    of unique constraints, which combined with not-null constraints are functionally almost the\n    same thing, but only one can be identified as the primary key.)\n    Relational database theory\n    dictates that every table must have a primary key.  This rule is\n    not enforced by <productname>PostgreSQL</productname>, but it is\n    usually best to follow it.\n   </para>\n\n   <para>\n    Primary keys are useful both for\n    documentation purposes and for client applications.", "score": 0.6213139891624451}, {"chunk_id": 2276, "source": "domains/postgresql_docs/data/datatype.sgml", "text_preview": "mary>\n    </indexterm>\n\n    <indexterm>\n     <primary>auto-increment</primary>\n     <see>serial</see>\n    </indexterm>\n\n    <indexterm>\n     <primary>sequence</primary>\n     <secondary>and serial type</secondary>\n    </indexterm>\n\n    <note>\n     <para>\n      This section describes a PostgreSQL-specific way to create an\n      autoincrementing column.  Another way is to use the SQL-standard\n      identity column feature, described at <xref linkend=\"ddl-identity-columns\"/>.\n     </para>\n    </note>\n\n    <para>\n     The data types <type>smallserial</type>, <type>serial</type> and\n     <type>bigserial</type> are not true types, but merely\n     a notational convenience for creating unique identifier columns\n     (similar to the <literal>AUTO_INCREMENT</literal> property\n     supported by some other databases). In the current\n     implementation, specifying:\n\n<programlisting>\nCREATE TABLE <rep", "score": 0.5678164958953857}, {"chunk_id": 2714, "source": "domains/postgresql_docs/data/ddl.sgml", "text_preview": "gn key to our table is:\n\n<programlisting>\nCREATE TABLE variants (\n  id         integer,\n  product_no integer,\n  name       text,\n  valid_at   daterange,\n  PRIMARY KEY (id, valid_at WITHOUT OVERLAPS),\n  <emphasis>FOREIGN KEY (product_no, PERIOD valid_at) REFERENCES products (product_no, PERIOD valid_at)</emphasis>\n);\n</programlisting>\n\n     Note that the keyword <literal>PERIOD</literal> must be used for the\n     application-time column in both the referencing and referenced table.\n    </para>\n\n    <para>\n     A temporal primary key or unique constraint matching the referenced columns\n     must exist on the referenced table.\n    </para>\n\n    <para>\n     <productname>PostgreSQL</productname> supports temporal foreign keys with\n     action <literal>NO ACTION</literal>, but not <literal>RESTRICT</literal>,\n     <literal>CASCADE</literal>, <literal>SET NULL</literal>, or <literal>SET\n     DEF", "score": 0.537816047668457}, {"chunk_id": 2674, "source": "domains/postgresql_docs/data/ddl.sgml", "text_preview": "erm>\n\n   <para>\n    A primary key constraint indicates that a column, or group of columns,\n    can be used as a unique identifier for rows in the table.  This\n    requires that the values be both unique and not null.  So, the following\n    two table definitions accept the same data:\n<programlisting>\nCREATE TABLE products (\n    product_no integer UNIQUE NOT NULL,\n    name text,\n    price numeric\n);\n</programlisting>\n\n<programlisting>\nCREATE TABLE products (\n    product_no integer <emphasis>PRIMARY KEY</emphasis>,\n    name text,\n    price numeric\n);\n</programlisting>\n   </para>\n\n   <para>\n    Primary keys can span more than one column; the syntax\n    is similar to unique constraints:\n<programlisting>\nCREATE TABLE example (\n    a integer,\n    b integer,\n    c integer,\n    <emphasis>PRIMARY KEY (a, c)</emphasis>\n);\n</programlisting>\n   </para>\n\n   <para>\n    Adding a primary key will automat", "score": 0.530471682548523}, {"chunk_id": 2622, "source": "domains/postgresql_docs/data/dblink.sgml", "text_preview": "</refsect1>\n\n  <refsect1>\n   <title>Notes</title>\n\n   <para>\n    As of <productname>PostgreSQL</productname> 9.0, the attribute numbers in\n    <parameter>primary_key_attnums</parameter> are interpreted as logical\n    column numbers, corresponding to the column's position in\n    <literal>SELECT * FROM relname</literal>.  Previous versions interpreted the\n    numbers as physical column positions.  There is a difference if any\n    column(s) to the left of the indicated column have been dropped during\n    the lifetime of the table.\n   </para>\n  </refsect1>\n\n  <refsect1>\n   <title>Examples</title>\n\n<screen>\nSELECT dblink_build_sql_update('foo', '1 2', 2, '{\"1\", \"a\"}', '{\"1\", \"b\"}');\n                   dblink_build_sql_update\n-------------------------------------------------------------\n UPDATE foo SET f1='1',f2='b',f3='1' WHERE f1='1' AND f2='b'\n(1 row)\n</screen>\n  </refsect1>\n </refentry>", "score": 0.5199845433235168}, {"chunk_id": 6172, "source": "domains/postgresql_docs/data/information_schema.sgml", "text_preview": "ave unlimited maximum cardinality in <productname>PostgreSQL</productname>\n      </para></entry>\n     </row>\n\n     <row>\n      <entry role=\"catalog_table_entry\"><para role=\"column_definition\">\n       <structfield>dtd_identifier</structfield> <type>sql_identifier</type>\n      </para>\n      <para>\n       An identifier of the data type descriptor of the column, unique\n       among the data type descriptors pertaining to the table.  This\n       is mainly useful for joining with other instances of such\n       identifiers.  (The specific format of the identifier is not\n       defined and not guaranteed to remain the same in future\n       versions.)\n      </para></entry>\n     </row>\n\n     <row>\n      <entry role=\"catalog_table_entry\"><para role=\"column_definition\">\n       <structfield>is_self_referencing</structfield> <type>yes_or_no</type>\n      </para>\n      <para>\n       Applies to a feature", "score": 0.5155947208404541}], "flags": {}, "error": null}, "finetune": {"pipeline": "finetune", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "", "latency_ms": 0, "tokens_in": null, "tokens_out": null, "cost_estimate_usd": null, "retrieved_chunks": null, "flags": {}, "error": "MISSING_FINETUNED_MODEL: set OPENAI_FINETUNED_MODEL or domains/<domain>/config.yaml finetuned_model"}}, "evaluations": {"prompt": {"quality_score": 0.85, "penalty_total": 0.15, "rule_breakdown": [{"rule": "overconfident_language_check", "penalty": 0.15, "hallucination_flags": ["OVERCONFIDENT_LANGUAGE"], "grounding_flags": [], "note": "Overconfident language detected."}], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": ["OVERCONFIDENT_LANGUAGE"], "grounding_flags": [], "notes": "Overconfident language detected."}, "rag": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}, "finetune": {"quality_score": null, "penalty_total": null, "rule_breakdown": [], "expect_score": null, "expect_details": null, "abstained": null, "abstention_expected": null, "abstention_correct": null, "abstention_score": null, "hallucination_flags": [], "grounding_flags": [], "notes": null}}, "summary_metrics": {"winner_by_quality": "rag", "winner_by_latency": "prompt", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": null, "winner_by_expect_ties": ["prompt", "rag"]}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251229T232339Z:004:transactions_basics", "timestamp": "2025-12-29T23:23:58.236545Z", "domain": "postgresql_docs", "mode": "docs", "query": "What is a transaction in PostgreSQL and how do I use BEGIN/COMMIT?", "case": {"id": "transactions_basics", "tags": ["transactions"], "answerable_from_general_knowledge": true, "requires_docs": false, "expected_abstain_in_docs": null}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "In PostgreSQL, a transaction is a sequence of one or more SQL operations that are executed as a single unit of work. Transactions ensure that either all operations are completed successfully, or none are applied, maintaining the integrity of the database. This is often referred to as the ACID properties of transactions: Atomicity, Consistency, Isolation, and Durability.\n\nTo use transactions in PostgreSQL, you typically use the `BEGIN`, `COMMIT`, and `ROLLBACK` commands:\n\n1. **BEGIN**: This command starts a new transaction. After this command is issued, all subsequent operations will be part of this transaction until it is either committed or rolled back.\n\n   ```sql\n   BEGIN;\n   ```\n\n2. **COMMIT**: This command is used to save all the changes made during the transaction to the database. Once you issue a `COMMIT`, all operations performed since the `BEGIN` are permanently applied.\n\n   ```sql\n   COMMIT;\n   ```\n\n3. **ROLLBACK**: If you encounter an error or decide not to apply the changes made during the transaction, you can use the `ROLLBACK` command to undo all operations performed since the `BEGIN`.\n\n   ```sql\n   ROLLBACK;\n   ```\n\nHere is a simple example of using a transaction in PostgreSQL:\n\n```sql\nBEGIN;\n\nINSERT INTO accounts (account_id, balance) VALUES (1, 1000);\nINSERT INTO accounts (account_id, balance) VALUES (2, 500);\n\n-- If everything is fine, commit the transaction\nCOMMIT;\n\n-- If there was an error, you could have rolled back instead\n-- ROLLBACK;\n```\n\nIn this example, if both `INSERT` statements succeed, the changes are saved with `COMMIT`. If there is an error during the inserts, you would use `ROLLBACK` to revert any changes made during the transaction.\n\nThis information is grounded in the official PostgreSQL documentation regarding transactions.", "latency_ms": 6583, "tokens_in": 151, "tokens_out": 400, "cost_estimate_usd": 0.00026265, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "In PostgreSQL, a transaction is a sequence of SQL statements that are executed as a single unit of work. Transactions are initiated by surrounding the SQL commands with `BEGIN` and `COMMIT` commands. For example, a typical transaction might look like this:\n\n```sql\nBEGIN;\nUPDATE accounts SET balance = balance - 100.00 WHERE name = 'Alice';\nCOMMIT;\n```\n\nIn this example, the `BEGIN` command starts the transaction, and the `COMMIT` command ends it, making all changes permanent [39]. If you decide not to commit the changes during the transaction, you can issue the `ROLLBACK` command instead, which will cancel all updates made in that transaction [39].\n\nPostgreSQL treats every SQL statement as being executed within a transaction. If you do not explicitly issue a `BEGIN` command, each individual statement has an implicit `BEGIN` and, if successful, an implicit `COMMIT` wrapped around it. This behavior is often referred to as \"autocommit\" [13994].", "latency_ms": 6217, "tokens_in": 1557, "tokens_out": 210, "cost_estimate_usd": 0.00035955, "retrieved_chunks": [{"chunk_id": 40, "source": "domains/postgresql_docs/data/advanced.sgml", "text_preview": "ra>\n\n   <para>\n    <productname>PostgreSQL</productname> actually treats every SQL statement as being\n    executed within a transaction.  If you do not issue a <command>BEGIN</command>\n    command,\n    then each individual statement has an implicit <command>BEGIN</command> and\n    (if successful) <command>COMMIT</command> wrapped around it.  A group of\n    statements surrounded by <command>BEGIN</command> and <command>COMMIT</command>\n    is sometimes called a <firstterm>transaction block</firstterm>.\n   </para>\n\n   <note>\n    <para>\n     Some client libraries issue <command>BEGIN</command> and <command>COMMIT</command>\n     commands automatically, so that you might get the effect of transaction\n     blocks without asking.  Check the documentation for the interface\n     you are using.\n    </para>\n   </note>\n\n   <para>\n    It's possible to control the statements in a transaction in a more", "score": 0.7019891738891602}, {"chunk_id": 10852, "source": "domains/postgresql_docs/data/ref/commit.sgml", "text_preview": "<para>\n   The command <command>COMMIT</command> conforms to the SQL standard.  The\n   form <literal>COMMIT TRANSACTION</literal> is a PostgreSQL extension.\n  </para>\n </refsect1>\n\n <refsect1>\n  <title>See Also</title>\n\n  <simplelist type=\"inline\">\n   <member><xref linkend=\"sql-begin\"/></member>\n   <member><xref linkend=\"sql-rollback\"/></member>\n  </simplelist>\n </refsect1>\n</refentry>", "score": 0.6939509510993958}, {"chunk_id": 9266, "source": "domains/postgresql_docs/data/plpgsql.sgml", "text_preview": "ctions\">\n   <title>Transaction Management</title>\n\n   <para>\n    In procedures invoked by the <command>CALL</command> command\n    as well as in anonymous code blocks (<command>DO</command> command),\n    it is possible to end transactions using the\n    commands <command>COMMIT</command> and <command>ROLLBACK</command>.  A new\n    transaction is started automatically after a transaction is ended using\n    these commands, so there is no separate <command>START\n    TRANSACTION</command> command.  (Note that <command>BEGIN</command> and\n    <command>END</command> have different meanings in PL/pgSQL.)\n   </para>\n\n   <para>\n    Here is a simple example:\n<programlisting>\nCREATE PROCEDURE transaction_test1()\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    FOR i IN 0..9 LOOP\n        INSERT INTO test1 (a) VALUES (i);\n        IF i % 2 = 0 THEN\n            COMMIT;\n        ELSE\n            ROLLBACK;\n        END IF;", "score": 0.6724060773849487}, {"chunk_id": 10851, "source": "domains/postgresql_docs/data/ref/commit.sgml", "text_preview": "saction\"/>) as the just finished one.  Otherwise,\n      no new transaction is started.\n     </para>\n    </listitem>\n   </varlistentry>\n  </variablelist>\n </refsect1>\n\n <refsect1>\n  <title>Notes</title>\n\n  <para>\n   Use <xref linkend=\"sql-rollback\"/> to\n   abort a transaction.\n  </para>\n\n  <para>\n   Issuing <command>COMMIT</command> when not inside a transaction does\n   no harm, but it will provoke a warning message.  <command>COMMIT AND\n   CHAIN</command> when not inside a transaction is an error.\n  </para>\n </refsect1>\n\n <refsect1>\n  <title>Examples</title>\n\n  <para>\n   To commit the current transaction and make all changes permanent:\n<programlisting>\nCOMMIT;\n</programlisting></para>\n </refsect1>\n\n <refsect1>\n  <title>Compatibility</title>\n\n  <para>\n   The command <command>COMMIT</command> conforms to the SQL standard.  The\n   form <literal>COMMIT TRANSACTION</literal> is a PostgreSQL e", "score": 0.6654769778251648}, {"chunk_id": 39, "source": "domains/postgresql_docs/data/advanced.sgml", "text_preview": "ible simultaneously.\n   </para>\n\n   <para>\n    In <productname>PostgreSQL</productname>, a transaction is set up by surrounding\n    the SQL commands of the transaction with\n    <command>BEGIN</command> and <command>COMMIT</command> commands.  So our banking\n    transaction would actually look like:\n\n<programlisting>\nBEGIN;\nUPDATE accounts SET balance = balance - 100.00\n    WHERE name = 'Alice';\n-- etc etc\nCOMMIT;\n</programlisting>\n   </para>\n\n   <para>\n    If, partway through the transaction, we decide we do not want to\n    commit (perhaps we just noticed that Alice's balance went negative),\n    we can issue the command <command>ROLLBACK</command> instead of\n    <command>COMMIT</command>, and all our updates so far will be canceled.\n   </para>\n\n   <para>\n    <productname>PostgreSQL</productname> actually treats every SQL statement as being\n    executed within a transaction.  If you do no", "score": 0.662121057510376}, {"chunk_id": 13994, "source": "domains/postgresql_docs/data/ref/start_transaction.sgml", "text_preview": "a>\n </refsect1>\n\n <refsect1>\n  <title>Compatibility</title>\n\n  <para>\n   In the standard, it is not necessary to issue <command>START TRANSACTION</command>\n   to start a transaction block: any SQL command implicitly begins a block.\n   <productname>PostgreSQL</productname>'s behavior can be seen as implicitly\n   issuing a <command>COMMIT</command> after each command that does not\n   follow <command>START TRANSACTION</command> (or <command>BEGIN</command>),\n   and it is therefore often called <quote>autocommit</quote>.\n   Other relational database systems might offer an autocommit feature\n   as a convenience.\n  </para>\n\n  <para>\n   The <literal>DEFERRABLE</literal>\n   <replaceable class=\"parameter\">transaction_mode</replaceable>\n   is a <productname>PostgreSQL</productname> language extension.\n  </para>\n\n  <para>\n   The SQL standard requires commas between successive <replaceable\n   class=", "score": 0.6581293344497681}], "flags": {}, "error": null}, "finetune": {"pipeline": "finetune", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "", "latency_ms": 0, "tokens_in": null, "tokens_out": null, "cost_estimate_usd": null, "retrieved_chunks": null, "flags": {}, "error": "MISSING_FINETUNED_MODEL: set OPENAI_FINETUNED_MODEL or domains/<domain>/config.yaml finetuned_model"}}, "evaluations": {"prompt": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}, "rag": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}, "finetune": {"quality_score": null, "penalty_total": null, "rule_breakdown": [], "expect_score": null, "expect_details": null, "abstained": null, "abstention_expected": null, "abstention_correct": null, "abstention_score": null, "hallucination_flags": [], "grounding_flags": [], "notes": null}}, "summary_metrics": {"winner_by_quality": null, "winner_by_quality_ties": ["prompt", "rag"], "winner_by_latency": "rag", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": null, "winner_by_expect_ties": ["prompt", "rag"]}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251229T232339Z:005:create_index", "timestamp": "2025-12-29T23:24:05.790990Z", "domain": "postgresql_docs", "mode": "docs", "query": "How do I create an index in PostgreSQL and when would I use one?", "case": {"id": "create_index", "tags": ["indexing"], "answerable_from_general_knowledge": true, "requires_docs": false, "expected_abstain_in_docs": null}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "To create an index in PostgreSQL, you can use the `CREATE INDEX` statement. The basic syntax is as follows:\n\n```sql\nCREATE INDEX index_name ON table_name (column_name);\n```\n\nFor example, if you have a table called `employees` and you want to create an index on the `last_name` column, you would use:\n\n```sql\nCREATE INDEX idx_last_name ON employees (last_name);\n```\n\nYou can also create more complex indexes, such as multi-column indexes or unique indexes. For example:\n\n```sql\nCREATE INDEX idx_full_name ON employees (first_name, last_name);\n```\n\n### When to Use an Index\n\nYou would typically use an index in PostgreSQL to improve the performance of queries that involve searching, filtering, or sorting data. Here are some scenarios where indexes are beneficial:\n\n1. **Frequent Searches**: If you frequently query a table based on a specific column or set of columns, an index can speed up those queries.\n\n2. **Join Operations**: Indexes can improve the performance of join operations between tables.\n\n3. **Sorting**: If you often sort results based on a particular column, an index on that column can help.\n\n4. **Unique Constraints**: If you need to enforce uniqueness on a column, creating a unique index is a way to do that.\n\nHowever, it's important to note that while indexes can improve read performance, they can also slow down write operations (INSERT, UPDATE, DELETE) because the index needs to be updated whenever the data changes. Therefore, it's essential to balance the use of indexes based on your application's specific query patterns and performance requirements.\n\nFor more detailed information, you can refer to the official PostgreSQL documentation on [Indexes](https://www.postgresql.org/docs/current/sql-createindex.html).", "latency_ms": 7463, "tokens_in": 150, "tokens_out": 364, "cost_estimate_usd": 0.0002409, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "To create an index in PostgreSQL, you can use the `CREATE INDEX` statement. The basic syntax is as follows:\n\n```\nCREATE [ UNIQUE ] INDEX [ CONCURRENTLY ] [ [ IF NOT EXISTS ] name ] ON [ ONLY ] table_name [ USING method ] ( { column_name | ( expression ) } [ COLLATE collation ] [ opclass ] [ ASC | DESC | USING operator ] [, ...] )\n```\n\nThis command allows you to define a new index on one or more columns of a table. You can also specify options such as whether the index should be unique or created concurrently [11178].\n\nIndexes are used to optimize queries that contain `WHERE` or `JOIN` clauses. They can significantly speed up data retrieval operations by allowing the database to find rows more efficiently. For example, if you have a query that frequently searches for specific values in a column, creating an index on that column can improve performance [5993]. Additionally, indexes can also benefit `UPDATE` and `DELETE` commands that include search conditions [5993].\n\nIn general, you would use an index when you want to enhance the performance of queries that involve searching, filtering, or joining data based on specific columns. However, it's important to note that maintaining indexes incurs overhead during data manipulation operations, so they should be used judiciously, especially for columns that are frequently queried [5996].", "latency_ms": 7529, "tokens_in": 1697, "tokens_out": 281, "cost_estimate_usd": 0.00042314999999999996, "retrieved_chunks": [{"chunk_id": 5996, "source": "domains/postgresql_docs/data/indices.sgml", "text_preview": "In production environments this is often unacceptable.\n   It is possible to allow writes to occur in parallel with index\n   creation, but there are several caveats to be aware of &mdash;\n   for more information see <xref linkend=\"sql-createindex-concurrently\"/>.\n  </para>\n\n  <para>\n   After an index is created, the system has to keep it synchronized with the\n   table.  This adds overhead to data manipulation operations.  Indexes can\n   also prevent the creation of <link linkend=\"storage-hot\">heap-only\n   tuples</link>.\n   Therefore indexes that are seldom or never used in queries\n   should be removed.\n  </para>\n </sect1>\n\n\n <sect1 id=\"indexes-types\">\n  <title>Index Types</title>\n\n  <para>\n   <productname>PostgreSQL</productname> provides several index types:\n   B-tree, Hash, GiST, SP-GiST, GIN, BRIN, and the extension <link\n   linkend=\"bloom\">bloom</link>.\n   Each index type uses a di", "score": 0.6706646084785461}, {"chunk_id": 5993, "source": "domains/postgresql_docs/data/indices.sgml", "text_preview": "nd=\"performance-tips\"/> for information about\n   how to find out whether an index is used and when and why the\n   planner might choose <emphasis>not</emphasis> to use an index.\n  </para>\n\n  <para>\n   Indexes can also benefit <command>UPDATE</command> and\n   <command>DELETE</command> commands with search conditions.\n   Indexes can moreover be used in join searches.  Thus,\n   an index defined on a column that is part of a join condition can\n   also significantly speed up queries with joins.\n  </para>\n\n  <para>\n   In general, <productname>PostgreSQL</productname> indexes can be used\n   to optimize queries that contain one or more <literal>WHERE</literal>\n   or <literal>JOIN</literal> clauses of the form\n\n<synopsis>\n<replaceable>indexed-column</replaceable> <replaceable>indexable-operator</replaceable> <replaceable>comparison-value</replaceable>\n</synopsis>\n\n   Here, the <replaceable>indexed", "score": 0.6317334175109863}, {"chunk_id": 11221, "source": "domains/postgresql_docs/data/ref/create_index.sgml", "text_preview": "an index's usefulness.\n   For new expression indexes, it is necessary to run <link\n   linkend=\"sql-analyze\"><command>ANALYZE</command></link> or wait for\n   the <link linkend=\"autovacuum\">autovacuum daemon</link> to analyze\n   the table to generate statistics for these indexes.\n  </para>\n\n  <para>\n   While <command>CREATE INDEX</command> is running, the <xref\n   linkend=\"guc-search-path\"/> is temporarily changed to <literal>pg_catalog,\n   pg_temp</literal>.\n  </para>\n\n  <para>\n   For most index methods, the speed of creating an index is\n   dependent on the setting of <xref linkend=\"guc-maintenance-work-mem\"/>.\n   Larger values will reduce the time needed for index creation, so long\n   as you don't make it larger than the amount of memory really available,\n   which would drive the machine into swapping.\n  </para>\n\n  <para>\n   <productname>PostgreSQL</productname> can build indexes while", "score": 0.6033602356910706}, {"chunk_id": 11178, "source": "domains/postgresql_docs/data/ref/create_index.sgml", "text_preview": "<!--\ndoc/src/sgml/ref/create_index.sgml\nPostgreSQL documentation\n-->\n\n<refentry id=\"sql-createindex\">\n <indexterm zone=\"sql-createindex\">\n  <primary>CREATE INDEX</primary>\n </indexterm>\n\n <refmeta>\n  <refentrytitle>CREATE INDEX</refentrytitle>\n  <manvolnum>7</manvolnum>\n  <refmiscinfo>SQL - Language Statements</refmiscinfo>\n </refmeta>\n\n <refnamediv>\n  <refname>CREATE INDEX</refname>\n  <refpurpose>define a new index</refpurpose>\n </refnamediv>\n\n <refsynopsisdiv>\n<synopsis>\nCREATE [ UNIQUE ] INDEX [ CONCURRENTLY ] [ [ IF NOT EXISTS ] <replaceable class=\"parameter\">name</replaceable> ] ON [ ONLY ] <replaceable class=\"parameter\">table_name</replaceable> [ USING <replaceable class=\"parameter\">method</replaceable> ]\n    ( { <replaceable class=\"parameter\">column_name</replaceable> | ( <replaceable class=\"parameter\">expression</replaceable> ) } [ COLLATE <replaceable class=\"parameter\">collation", "score": 0.5934208631515503}, {"chunk_id": 11181, "source": "domains/postgresql_docs/data/ref/create_index.sgml", "text_preview": "of\n   one or more columns of the table row.  This feature can be used\n   to obtain fast access to data based on some transformation of\n   the basic data. For example, an index computed on\n   <literal>upper(col)</literal> would allow the clause\n   <literal>WHERE upper(col) = 'JIM'</literal> to use an index.\n  </para>\n\n  <para>\n   <productname>PostgreSQL</productname> provides the index methods\n   B-tree, hash, GiST, SP-GiST, GIN, and BRIN.  Users can also define their own\n   index methods, but that is fairly complicated.\n  </para>\n\n  <para>\n    When the <literal>WHERE</literal> clause is present, a\n    <firstterm>partial index</firstterm> is created.\n    A partial index is an index that contains entries for only a portion of\n    a table, usually a portion that is more useful for indexing than the\n    rest of the table. For example, if you have a table that contains both\n    billed and un", "score": 0.5660547614097595}, {"chunk_id": 6048, "source": "domains/postgresql_docs/data/indices.sgml", "text_preview": "an index might be profitable.  Forming this knowledge\n   requires experience and understanding of how indexes in\n   <productname>PostgreSQL</productname> work.  In most cases, the\n   advantage of a partial index over a regular index will be minimal.\n   There are cases where they are quite counterproductive, as in <xref\n   linkend=\"indexes-partial-ex4\"/>.\n  </para>\n\n  <example id=\"indexes-partial-ex4\">\n   <title>Do Not Use Partial Indexes as a Substitute for Partitioning</title>\n\n   <para>\n    You might be tempted to create a large set of non-overlapping partial\n    indexes, for example\n\n<programlisting>\nCREATE INDEX mytable_cat_1 ON mytable (data) WHERE category = 1;\nCREATE INDEX mytable_cat_2 ON mytable (data) WHERE category = 2;\nCREATE INDEX mytable_cat_3 ON mytable (data) WHERE category = 3;\n...\nCREATE INDEX mytable_cat_<replaceable>N</replaceable> ON mytable (data) WHERE category = <", "score": 0.5651172399520874}], "flags": {}, "error": null}, "finetune": {"pipeline": "finetune", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "", "latency_ms": 0, "tokens_in": null, "tokens_out": null, "cost_estimate_usd": null, "retrieved_chunks": null, "flags": {}, "error": "MISSING_FINETUNED_MODEL: set OPENAI_FINETUNED_MODEL or domains/<domain>/config.yaml finetuned_model"}}, "evaluations": {"prompt": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}, "rag": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}, "finetune": {"quality_score": null, "penalty_total": null, "rule_breakdown": [], "expect_score": null, "expect_details": null, "abstained": null, "abstention_expected": null, "abstention_correct": null, "abstention_score": null, "hallucination_flags": [], "grounding_flags": [], "notes": null}}, "summary_metrics": {"winner_by_quality": null, "winner_by_quality_ties": ["prompt", "rag"], "winner_by_latency": "prompt", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": null, "winner_by_expect_ties": ["prompt", "rag"]}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251229T232339Z:006:explain_analyze", "timestamp": "2025-12-29T23:24:14.557203Z", "domain": "postgresql_docs", "mode": "docs", "query": "How do I use EXPLAIN (ANALYZE) to understand query performance?", "case": {"id": "explain_analyze", "tags": ["performance"], "answerable_from_general_knowledge": true, "requires_docs": true, "expected_abstain_in_docs": null}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "To use `EXPLAIN (ANALYZE)` in PostgreSQL to understand query performance, you can follow these steps:\n\n1. **Basic Usage**: You can run the `EXPLAIN (ANALYZE, BUFFERS)` command followed by your SQL query. For example:\n   ```sql\n   EXPLAIN (ANALYZE, BUFFERS) SELECT * FROM your_table WHERE your_condition;\n   ```\n\n2. **Understanding the Output**: The output will provide detailed information about how PostgreSQL executes the query, including:\n   - **Execution Time**: The total time taken to execute the query.\n   - **Planning Time**: The time taken to plan the query.\n   - **Node Types**: Information about the different operations performed (e.g., Seq Scan, Index Scan, Join types).\n   - **Rows**: The number of rows processed at each step.\n   - **Buffers**: Information about buffer usage, which can help identify I/O performance issues.\n\n3. **Analyzing the Plan**: Look for:\n   - **Cost Estimates**: The estimated cost of executing the query versus the actual time taken.\n   - **Row Estimates**: Compare the estimated number of rows with the actual number of rows processed.\n   - **Execution Steps**: Identify any steps that take significantly longer than expected, which may indicate a performance bottleneck.\n\n4. **Identifying Improvements**: Based on the output, you can identify areas for optimization, such as:\n   - Adding indexes to speed up searches.\n   - Rewriting queries for better performance.\n   - Analyzing and adjusting database configuration settings.\n\n5. **Documentation Reference**: For more detailed information, you can refer to the official PostgreSQL documentation on `EXPLAIN` and `ANALYZE`, which provides comprehensive guidance on interpreting the output and understanding query performance.\n\nBy using `EXPLAIN (ANALYZE)`, you can gain insights into how your queries are executed and identify opportunities for optimization.", "latency_ms": 8759, "tokens_in": 152, "tokens_out": 413, "cost_estimate_usd": 0.0002706, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "To use `EXPLAIN (ANALYZE)` for understanding query performance in PostgreSQL, you can execute the command followed by your SQL query. This option not only shows the estimated execution plan but also executes the query and provides actual run times and row counts for each plan node. For example, you might run a command like:\n\n```sql\nEXPLAIN ANALYZE SELECT * FROM tenk1 t1, tenk2 t2 WHERE t1.unique1 < 10 AND t1.unique2 = t2.unique2;\n```\n\nThe output will include both the estimated costs and the actual performance metrics, such as the time taken and the number of rows processed at each step of the query execution plan [8583]. \n\nThe structure of the output is a tree of plan nodes, where the bottom nodes are scan nodes that retrieve raw rows from tables, and higher nodes perform operations like joining or aggregating those rows [8545]. This detailed information helps you identify performance bottlenecks and optimize your queries accordingly.", "latency_ms": 6894, "tokens_in": 1703, "tokens_out": 208, "cost_estimate_usd": 0.00038025, "retrieved_chunks": [{"chunk_id": 8583, "source": "domains/postgresql_docs/data/perform.sgml", "text_preview": "command>'s <literal>ANALYZE</literal> option.  With this\n    option, <command>EXPLAIN</command> actually executes the query, and then displays\n    the true row counts and true run time accumulated within each plan node,\n    along with the same estimates that a plain <command>EXPLAIN</command>\n    shows.  For example, we might get a result like this:\n\n<screen>\nEXPLAIN ANALYZE SELECT *\nFROM tenk1 t1, tenk2 t2\nWHERE t1.unique1 &lt; 10 AND t1.unique2 = t2.unique2;\n\n                                                           QUERY PLAN\n-------------------------------------------------------------------&zwsp;--------------------------------------------------------------\n Nested Loop  (cost=4.65..118.50 rows=10 width=488) (actual time=0.017..0.051 rows=10.00 loops=1)\n   Buffers: shared hit=36 read=6\n   -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=4.36..39.38 rows=10 width=244) (actual time=0.009..", "score": 0.6470448970794678}, {"chunk_id": 8545, "source": "domains/postgresql_docs/data/perform.sgml", "text_preview": "ct2 id=\"using-explain-basics\">\n   <title><command>EXPLAIN</command> Basics</title>\n\n   <para>\n    The structure of a query plan is a tree of <firstterm>plan nodes</firstterm>.\n    Nodes at the bottom level of the tree are scan nodes: they return raw rows\n    from a table.  There are different types of scan nodes for different\n    table access methods: sequential scans, index scans, and bitmap index\n    scans.  There are also non-table row sources, such as <literal>VALUES</literal>\n    clauses and set-returning functions in <literal>FROM</literal>, which have their\n    own scan node types.\n    If the query requires joining, aggregation, sorting, or other\n    operations on the raw rows, then there will be additional nodes\n    above the scan nodes to perform these operations.  Again,\n    there is usually more than one possible way to do these operations,\n    so different node types can appe", "score": 0.6208587884902954}, {"chunk_id": 8544, "source": "domains/postgresql_docs/data/perform.sgml", "text_preview": "ng a <command>VACUUM ANALYZE</command>, using v18 development sources.\n    You should be able to get similar results if you try the examples\n    yourself, but your estimated costs and row counts might vary slightly\n    because <command>ANALYZE</command>'s statistics are random samples rather\n    than exact, and because costs are inherently somewhat platform-dependent.\n   </para>\n\n   <para>\n    The examples use <command>EXPLAIN</command>'s default <quote>text</quote> output\n    format, which is compact and convenient for humans to read.\n    If you want to feed <command>EXPLAIN</command>'s output to a program for further\n    analysis, you should use one of its machine-readable output formats\n    (XML, JSON, or YAML) instead.\n   </para>\n\n  <sect2 id=\"using-explain-basics\">\n   <title><command>EXPLAIN</command> Basics</title>\n\n   <para>\n    The structure of a query plan is a tree of <firstter", "score": 0.6203147172927856}, {"chunk_id": 8542, "source": "domains/postgresql_docs/data/perform.sgml", "text_preview": "<!-- doc/src/sgml/perform.sgml -->\n\n <chapter id=\"performance-tips\">\n  <title>Performance Tips</title>\n\n  <indexterm zone=\"performance-tips\">\n   <primary>performance</primary>\n  </indexterm>\n\n  <para>\n   Query performance can be affected by many things. Some of these can\n   be controlled by the user, while others are fundamental to the underlying\n   design of the system.  This chapter provides some hints about understanding\n   and tuning <productname>PostgreSQL</productname> performance.\n  </para>\n\n <sect1 id=\"using-explain\">\n  <title>Using <command>EXPLAIN</command></title>\n\n   <indexterm zone=\"using-explain\">\n    <primary>EXPLAIN</primary>\n   </indexterm>\n\n   <indexterm zone=\"using-explain\">\n    <primary>query plan</primary>\n   </indexterm>\n\n   <para>\n    <productname>PostgreSQL</productname> devises a <firstterm>query\n    plan</firstterm> for each query it receives.  Choosing the righ", "score": 0.6131941080093384}, {"chunk_id": 12206, "source": "domains/postgresql_docs/data/ref/explain.sgml", "text_preview": "<!--\ndoc/src/sgml/ref/explain.sgml\nPostgreSQL documentation\n-->\n\n<refentry id=\"sql-explain\">\n <indexterm zone=\"sql-explain\">\n  <primary>EXPLAIN</primary>\n </indexterm>\n\n <indexterm zone=\"sql-explain\">\n  <primary>prepared statements</primary>\n  <secondary>showing the query plan</secondary>\n </indexterm>\n\n <indexterm zone=\"sql-explain\">\n  <primary>cursor</primary>\n  <secondary>showing the query plan</secondary>\n </indexterm>\n\n <refmeta>\n  <refentrytitle>EXPLAIN</refentrytitle>\n  <manvolnum>7</manvolnum>\n  <refmiscinfo>SQL - Language Statements</refmiscinfo>\n </refmeta>\n\n <refnamediv>\n  <refname>EXPLAIN</refname>\n  <refpurpose>show the execution plan of a statement</refpurpose>\n </refnamediv>\n\n <refsynopsisdiv>\n<synopsis>\nEXPLAIN [ ( <replaceable class=\"parameter\">option</replaceable> [, ...] ) ] <replaceable class=\"parameter\">statement</replaceable>\n\n<phrase>where <replaceable class=\"param", "score": 0.5846108794212341}, {"chunk_id": 12228, "source": "domains/postgresql_docs/data/ref/explain.sgml", "text_preview": "condition, <command>EXPLAIN</command>\n   might show a different plan:\n\n<programlisting>\nEXPLAIN SELECT * FROM foo WHERE i = 4;\n\n                         QUERY PLAN\n--------------------------------------------------------------\n Index Scan using fi on foo  (cost=0.00..5.98 rows=1 width=4)\n   Index Cond: (i = 4)\n(2 rows)\n</programlisting>\n  </para>\n\n  <para>\n  Here is the same query, but in YAML format:\n<programlisting>\nEXPLAIN (FORMAT YAML) SELECT * FROM foo WHERE i='4';\n          QUERY PLAN\n-------------------------------\n - Plan:                      +\n     Node Type: \"Index Scan\"  +\n     Scan Direction: \"Forward\"+\n     Index Name: \"fi\"         +\n     Relation Name: \"foo\"     +\n     Alias: \"foo\"             +\n     Startup Cost: 0.00       +\n     Total Cost: 5.98         +\n     Plan Rows: 1             +\n     Plan Width: 4            +\n     Index Cond: \"(i = 4)\"\n(1 row)\n</programlisting", "score": 0.5782298445701599}], "flags": {}, "error": null}, "finetune": {"pipeline": "finetune", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "", "latency_ms": 0, "tokens_in": null, "tokens_out": null, "cost_estimate_usd": null, "retrieved_chunks": null, "flags": {}, "error": "MISSING_FINETUNED_MODEL: set OPENAI_FINETUNED_MODEL or domains/<domain>/config.yaml finetuned_model"}}, "evaluations": {"prompt": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}, "rag": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}, "finetune": {"quality_score": null, "penalty_total": null, "rule_breakdown": [], "expect_score": null, "expect_details": null, "abstained": null, "abstention_expected": null, "abstention_correct": null, "abstention_score": null, "hallucination_flags": [], "grounding_flags": [], "notes": null}}, "summary_metrics": {"winner_by_quality": null, "winner_by_quality_ties": ["prompt", "rag"], "winner_by_latency": "rag", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": null, "winner_by_expect_ties": ["prompt", "rag"]}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251229T232339Z:007:vacuum_basics", "timestamp": "2025-12-29T23:24:20.025699Z", "domain": "postgresql_docs", "mode": "docs", "query": "What does VACUUM do in PostgreSQL?", "case": {"id": "vacuum_basics", "tags": ["maintenance"], "answerable_from_general_knowledge": true, "requires_docs": true, "expected_abstain_in_docs": null}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "In PostgreSQL, the `VACUUM` command is used to reclaim storage occupied by dead tuples. When rows are updated or deleted in PostgreSQL, the old versions of these rows are not immediately removed from the disk; instead, they are marked as dead. Over time, these dead tuples can accumulate and lead to wasted space and degraded performance.\n\nThe main functions of `VACUUM` are:\n\n1. **Reclaiming Space**: It removes dead tuples from the database, allowing the space to be reused for future inserts and updates.\n\n2. **Preventing Transaction ID Wraparound**: PostgreSQL uses a transaction ID (XID) system to manage visibility of rows. If old tuples are not vacuumed, the transaction IDs can wrap around, leading to potential data corruption. `VACUUM` helps to prevent this by cleaning up old tuples.\n\n3. **Updating Statistics**: While `VACUUM` itself does not update statistics, it can be followed by `ANALYZE`, which collects statistics about the distribution of data in the table, helping the query planner make better decisions.\n\nThere are two types of `VACUUM`:\n\n- **Standard VACUUM**: Reclaims space and marks dead tuples for reuse.\n- **VACUUM FULL**: Reclaims space by rewriting the entire table and can return space to the operating system, but it requires an exclusive lock on the table.\n\nIn summary, `VACUUM` is an essential maintenance operation in PostgreSQL to manage storage and maintain performance.", "latency_ms": 5450, "tokens_in": 144, "tokens_out": 311, "cost_estimate_usd": 0.00020820000000000002, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "The VACUUM command in PostgreSQL is used to garbage-collect and optionally analyze a database. It processes each table to recover or reuse disk space occupied by updated or deleted rows, and it can also analyze the database to update statistics for the query planner [14041][7793]. Additionally, VACUUM can complete any pending index insertions for tables with GIN indexes [14067]. Regular vacuuming is recommended to maintain database performance, and PostgreSQL includes an autovacuum facility to automate this maintenance [14067].", "latency_ms": 4135, "tokens_in": 1760, "tokens_out": 107, "cost_estimate_usd": 0.0003282, "retrieved_chunks": [{"chunk_id": 14041, "source": "domains/postgresql_docs/data/ref/vacuum.sgml", "text_preview": "<!--\ndoc/src/sgml/ref/vacuum.sgml\nPostgreSQL documentation\n-->\n\n<refentry id=\"sql-vacuum\">\n <indexterm zone=\"sql-vacuum\">\n  <primary>VACUUM</primary>\n </indexterm>\n\n <refmeta>\n  <refentrytitle>VACUUM</refentrytitle>\n  <manvolnum>7</manvolnum>\n  <refmiscinfo>SQL - Language Statements</refmiscinfo>\n </refmeta>\n\n <refnamediv>\n  <refname>VACUUM</refname>\n  <refpurpose>garbage-collect and optionally analyze a database</refpurpose>\n </refnamediv>\n\n <refsynopsisdiv>\n<synopsis>\nVACUUM [ ( <replaceable class=\"parameter\">option</replaceable> [, ...] ) ] [ <replaceable class=\"parameter\">table_and_columns</replaceable> [, ...] ]\n\n<phrase>where <replaceable class=\"parameter\">option</replaceable> can be one of:</phrase>\n\n    FULL [ <replaceable class=\"parameter\">boolean</replaceable> ]\n    FREEZE [ <replaceable class=\"parameter\">boolean</replaceable> ]\n    VERBOSE [ <replaceable class=\"parameter\">bool", "score": 0.6652467250823975}, {"chunk_id": 14067, "source": "domains/postgresql_docs/data/ref/vacuum.sgml", "text_preview": "UM</command> is running, the <xref\n    linkend=\"guc-search-path\"/> is temporarily changed to <literal>pg_catalog,\n    pg_temp</literal>.\n   </para>\n\n   <para>\n    <command>VACUUM</command> cannot be executed inside a transaction block.\n   </para>\n\n   <para>\n    For tables with <acronym>GIN</acronym> indexes, <command>VACUUM</command> (in\n    any form) also completes any pending index insertions, by moving pending\n    index entries to the appropriate places in the main <acronym>GIN</acronym> index\n    structure.  See <xref linkend=\"gin-fast-update\"/> for details.\n   </para>\n\n   <para>\n    We recommend that all databases be vacuumed regularly in\n    order to remove dead rows.  <productname>PostgreSQL</productname> includes\n    an <quote>autovacuum</quote> facility which can automate routine vacuum\n    maintenance.  For more information about automatic and manual vacuuming,\n    see <xref li", "score": 0.6505804061889648}, {"chunk_id": 7793, "source": "domains/postgresql_docs/data/maintenance.sgml", "text_preview": "to\n   supplement or replace the daemon's activities with manually-managed\n   <command>VACUUM</command> commands, which typically are executed according to a\n   schedule by <application>cron</application> or <application>Task\n   Scheduler</application> scripts.  To set up manually-managed vacuuming properly,\n   it is essential to understand the issues discussed in the next few\n   subsections.  Administrators who rely on autovacuuming may still wish\n   to skim this material to help them understand and adjust autovacuuming.\n  </para>\n\n  <sect2 id=\"vacuum-basics\">\n   <title>Vacuuming Basics</title>\n\n   <para>\n    <productname>PostgreSQL</productname>'s\n    <link linkend=\"sql-vacuum\"><command>VACUUM</command></link> command has to\n    process each table on a regular basis for several reasons:\n\n    <orderedlist>\n     <listitem>\n      <simpara>To recover or reuse disk space occupied by updated", "score": 0.6441094875335693}, {"chunk_id": 14072, "source": "domains/postgresql_docs/data/ref/vacuumdb.sgml", "text_preview": "<!--\ndoc/src/sgml/ref/vacuumdb.sgml\nPostgreSQL documentation\n-->\n\n<refentry id=\"app-vacuumdb\">\n <indexterm zone=\"app-vacuumdb\">\n  <primary>vacuumdb</primary>\n </indexterm>\n\n <refmeta>\n  <refentrytitle><application>vacuumdb</application></refentrytitle>\n  <manvolnum>1</manvolnum>\n  <refmiscinfo>Application</refmiscinfo>\n </refmeta>\n\n <refnamediv>\n  <refname>vacuumdb</refname>\n  <refpurpose>garbage-collect and analyze a <productname>PostgreSQL</productname> database</refpurpose>\n </refnamediv>\n\n <refsynopsisdiv>\n  <cmdsynopsis>\n   <command>vacuumdb</command>\n   <arg rep=\"repeat\"><replaceable>connection-option</replaceable></arg>\n   <arg rep=\"repeat\"><replaceable>option</replaceable></arg>\n\n   <arg choice=\"plain\" rep=\"repeat\">\n    <arg choice=\"opt\">\n     <group choice=\"plain\">\n      <arg choice=\"plain\"><option>-t</option></arg>\n      <arg choice=\"plain\"><option>--table</option></arg>\n     <", "score": 0.6368889808654785}, {"chunk_id": 14070, "source": "domains/postgresql_docs/data/ref/vacuum.sgml", "text_preview": "command>VACUUM FULL</command> will instead report their progress in the\n    <structname>pg_stat_progress_cluster</structname> view. See\n    <xref linkend=\"vacuum-progress-reporting\"/> and\n    <xref linkend=\"cluster-progress-reporting\"/> for details.\n   </para>\n </refsect1>\n\n <refsect1>\n  <title>Examples</title>\n\n  <para>\n   To clean a single table <structname>onek</structname>, analyze it for\n   the optimizer and print a detailed vacuum activity report:\n\n<programlisting>\nVACUUM (VERBOSE, ANALYZE) onek;\n</programlisting></para>\n </refsect1>\n\n <refsect1>\n  <title>Compatibility</title>\n\n  <para>\n   There is no <command>VACUUM</command> statement in the SQL standard.\n  </para>\n\n  <para>\n   The following syntax was used before <productname>PostgreSQL</productname>\n   version 9.0 and is still supported:\n<synopsis>\nVACUUM [ FULL ] [ FREEZE ] [ VERBOSE ] [ ANALYZE ] [ <replaceable class=\"paramet", "score": 0.6349263787269592}, {"chunk_id": 7838, "source": "domains/postgresql_docs/data/maintenance.sgml", "text_preview": "arlier versions, it was sometimes necessary to stop the postmaster and\n     <command>VACUUM</command> the database in a single-user mode. In typical scenarios, this\n     is no longer necessary, and should be avoided whenever possible, since it involves taking\n     the system down. It is also riskier, since it disables transaction ID wraparound safeguards\n     that are designed to prevent data loss.  The only reason to use single-user mode in this\n     scenario is if you wish to <command>TRUNCATE</command> or <command>DROP</command> unneeded\n     tables to avoid needing to <command>VACUUM</command> them.  The three-million-transaction\n     safety margin exists to let the administrator do this. See the\n     <xref linkend=\"app-postgres\"/> reference page for details about using single-user mode.\n    </para>\n   </note>\n\n   <sect3 id=\"vacuum-for-multixact-wraparound\">\n    <title>Multixacts and", "score": 0.6136733293533325}], "flags": {}, "error": null}, "finetune": {"pipeline": "finetune", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "", "latency_ms": 0, "tokens_in": null, "tokens_out": null, "cost_estimate_usd": null, "retrieved_chunks": null, "flags": {}, "error": "MISSING_FINETUNED_MODEL: set OPENAI_FINETUNED_MODEL or domains/<domain>/config.yaml finetuned_model"}}, "evaluations": {"prompt": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}, "rag": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}, "finetune": {"quality_score": null, "penalty_total": null, "rule_breakdown": [], "expect_score": null, "expect_details": null, "abstained": null, "abstention_expected": null, "abstention_correct": null, "abstention_score": null, "hallucination_flags": [], "grounding_flags": [], "notes": null}}, "summary_metrics": {"winner_by_quality": null, "winner_by_quality_ties": ["prompt", "rag"], "winner_by_latency": "rag", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": null, "winner_by_expect_ties": ["prompt", "rag"]}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251229T232339Z:008:jsonb_basics", "timestamp": "2025-12-29T23:24:25.826442Z", "domain": "postgresql_docs", "mode": "docs", "query": "What is JSONB in PostgreSQL and how is it different from JSON?", "case": {"id": "jsonb_basics", "tags": ["json"], "answerable_from_general_knowledge": true, "requires_docs": false, "expected_abstain_in_docs": null}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "In PostgreSQL, `JSONB` is a binary representation of JSON data. It is designed to be more efficient for storage and processing compared to the plain `JSON` type. Here are the key differences between `JSON` and `JSONB` as per the official PostgreSQL documentation:\n\n1. **Storage Format**:\n   - `JSON` stores data as plain text, which means it retains the original formatting and whitespace.\n   - `JSONB` stores data in a binary format, which is more efficient for storage and allows for faster processing.\n\n2. **Performance**:\n   - `JSONB` is generally faster for operations like searching and indexing because it is stored in a format that allows for efficient access and manipulation.\n   - `JSON` may be slower for these operations since it requires parsing the text representation.\n\n3. **Indexing**:\n   - `JSONB` supports indexing, which can significantly improve query performance. You can create GIN (Generalized Inverted Index) or BTREE indexes on `JSONB` data.\n   - `JSON` does not support indexing in the same way.\n\n4. **Functionality**:\n   - `JSONB` supports a wider range of functions and operators for querying and manipulating the data.\n   - While `JSON` has some functions available, they are more limited compared to those available for `JSONB`.\n\n5. **Duplication of Keys**:\n   - In `JSON`, duplicate keys are allowed, and they will be preserved in the order they appear.\n   - In `JSONB`, duplicate keys are not allowed; if they occur, the last key-value pair will overwrite the previous ones.\n\nIn summary, `JSONB` is a more efficient and feature-rich option for storing JSON data in PostgreSQL compared to the `JSON` type.", "latency_ms": 5785, "tokens_in": 149, "tokens_out": 367, "cost_estimate_usd": 0.00024255, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "In PostgreSQL, `jsonb` is a data type for storing JSON data in a decomposed binary format. This format allows for efficient processing of JSON data, making `jsonb` significantly faster to process compared to the `json` type, which stores an exact copy of the input text and requires reparsing on each execution [6747]. \n\nThe main differences between `json` and `jsonb` include:\n\n1. **Storage Format**: `json` stores the data as plain text, while `jsonb` stores it in a binary format that is optimized for performance [6748].\n\n2. **Processing Speed**: `jsonb` is faster to process because it does not require reparsing, although it may be slightly slower to input due to the conversion overhead [6748].\n\n3. **Data Integrity**: `jsonb` enforces additional constraints on the data, such as rejecting numbers that are outside the range of the PostgreSQL `numeric` data type, which `json` does not enforce [6753]. \n\n4. **Handling of Duplicates and Order**: `json` preserves the order of keys and allows duplicate keys within JSON objects, while `jsonb` does not preserve order and only keeps the last value for duplicate keys [6752].\n\n5. **Indexing**: `jsonb` supports indexing, which can enhance query performance, whereas `json` does not [6748]. \n\nOverall, `jsonb` is generally preferred for applications that require efficient querying and processing of JSON data.", "latency_ms": 4264, "tokens_in": 1652, "tokens_out": 314, "cost_estimate_usd": 0.0004362, "retrieved_chunks": [{"chunk_id": 6747, "source": "domains/postgresql_docs/data/json.sgml", "text_preview": "s-json\"/>.\n </para>\n\n <para>\n  <productname>PostgreSQL</productname> offers two types for storing JSON\n  data: <type>json</type> and <type>jsonb</type>. To implement efficient query\n  mechanisms for these data types, <productname>PostgreSQL</productname>\n  also provides the <type>jsonpath</type> data type described in\n  <xref linkend=\"datatype-jsonpath\"/>.\n </para>\n\n <para>\n  The <type>json</type> and <type>jsonb</type> data types\n  accept <emphasis>almost</emphasis> identical sets of values as\n  input.  The major practical difference is one of efficiency.  The\n  <type>json</type> data type stores an exact copy of the input text,\n  which processing functions must reparse on each execution; while\n  <type>jsonb</type> data is stored in a decomposed binary format that\n  makes it slightly slower to input due to added conversion\n  overhead, but significantly faster to process, since no repars", "score": 0.6785038709640503}, {"chunk_id": 6752, "source": "domains/postgresql_docs/data/json.sgml", "text_preview": "y be considered a historical artifact, although\n   it does allow for simple storage (without processing) of JSON Unicode\n   escapes in a database encoding that does not support the represented\n   characters.\n  </para>\n </note>\n\n <para>\n  When converting textual JSON input into <type>jsonb</type>, the primitive\n  types described by <acronym>RFC</acronym> 7159 are effectively mapped onto\n  native <productname>PostgreSQL</productname> types, as shown\n  in <xref linkend=\"json-type-mapping-table\"/>.\n  Therefore, there are some minor additional constraints on what\n  constitutes valid <type>jsonb</type> data that do not apply to\n  the <type>json</type> type, nor to JSON in the abstract, corresponding\n  to limits on what can be represented by the underlying data type.\n  Notably, <type>jsonb</type> will reject numbers that are outside the\n  range of the <productname>PostgreSQL</productname> <type", "score": 0.6530728340148926}, {"chunk_id": 6746, "source": "domains/postgresql_docs/data/json.sgml", "text_preview": "<!-- doc/src/sgml/json.sgml -->\n\n<sect1 id=\"datatype-json\">\n <title><acronym>JSON</acronym> Types</title>\n\n <indexterm zone=\"datatype-json\">\n  <primary>JSON</primary>\n </indexterm>\n\n <indexterm zone=\"datatype-json\">\n  <primary>JSONB</primary>\n </indexterm>\n\n <para>\n  JSON data types are for storing JSON (JavaScript Object Notation)\n  data, as specified in <ulink url=\"https://datatracker.ietf.org/doc/html/rfc7159\">RFC\n  7159</ulink>. Such data can also be stored as <type>text</type>, but\n  the JSON data types have the advantage of enforcing that each\n  stored value is valid according to the JSON rules.  There are also\n  assorted JSON-specific functions and operators available for data stored\n  in these data types; see <xref linkend=\"functions-json\"/>.\n </para>\n\n <para>\n  <productname>PostgreSQL</productname> offers two types for storing JSON\n  data: <type>json</type> and <type>jsonb</type", "score": 0.6248845458030701}, {"chunk_id": 6748, "source": "domains/postgresql_docs/data/json.sgml", "text_preview": "mposed binary format that\n  makes it slightly slower to input due to added conversion\n  overhead, but significantly faster to process, since no reparsing\n  is needed.  <type>jsonb</type> also supports indexing, which can be a\n  significant advantage.\n </para>\n\n <para>\n  Because the <type>json</type> type stores an exact copy of the input text, it\n  will preserve semantically-insignificant white space between tokens, as\n  well as the order of keys within JSON objects. Also, if a JSON object\n  within the value contains the same key more than once, all the key/value\n  pairs are kept.  (The processing functions consider the last value as the\n  operative one.)  By contrast, <type>jsonb</type> does not preserve white\n  space, does not preserve the order of object keys, and does not keep\n  duplicate object keys.  If duplicate keys are specified in the input,\n  only the last value is kept.\n </pa", "score": 0.6096411943435669}, {"chunk_id": 6759, "source": "domains/postgresql_docs/data/json.sgml", "text_preview": "jsonb\n-----------------------+-------------------------\n {\"reading\": 1.230e-5} | {\"reading\": 0.00001230}\n(1 row)\n</programlisting>\n   However, <type>jsonb</type> will preserve trailing fractional zeroes, as seen\n   in this example, even though those are semantically insignificant for\n   purposes such as equality checks.\n  </para>\n\n  <para>\n    For the list of built-in functions and operators available for\n    constructing and processing JSON values, see <xref linkend=\"functions-json\"/>.\n  </para>\n </sect2>\n\n <sect2 id=\"json-doc-design\">\n  <title>Designing JSON Documents</title>\n  <para>\n   Representing data as JSON can be considerably more flexible than\n   the traditional relational data model, which is compelling in\n   environments where requirements are fluid.  It is quite possible\n   for both approaches to co-exist and complement each other within\n   the same application.  Howe", "score": 0.6079476475715637}, {"chunk_id": 6753, "source": "domains/postgresql_docs/data/json.sgml", "text_preview": "nderlying data type.\n  Notably, <type>jsonb</type> will reject numbers that are outside the\n  range of the <productname>PostgreSQL</productname> <type>numeric</type> data\n  type, while <type>json</type> will not.  Such implementation-defined\n  restrictions are permitted by <acronym>RFC</acronym> 7159.  However, in\n  practice such problems are far more likely to occur in other\n  implementations, as it is common to represent JSON's <type>number</type>\n  primitive type as IEEE 754 double precision floating point\n  (which <acronym>RFC</acronym> 7159 explicitly anticipates and allows for).\n  When using JSON as an interchange format with such systems, the danger\n  of losing numeric precision compared to data originally stored\n  by <productname>PostgreSQL</productname> should be considered.\n </para>\n\n <para>\n  Conversely, as noted in the table there are some minor restrictions on\n  the input fo", "score": 0.6052520275115967}], "flags": {}, "error": null}, "finetune": {"pipeline": "finetune", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "", "latency_ms": 0, "tokens_in": null, "tokens_out": null, "cost_estimate_usd": null, "retrieved_chunks": null, "flags": {}, "error": "MISSING_FINETUNED_MODEL: set OPENAI_FINETUNED_MODEL or domains/<domain>/config.yaml finetuned_model"}}, "evaluations": {"prompt": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}, "rag": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}, "finetune": {"quality_score": null, "penalty_total": null, "rule_breakdown": [], "expect_score": null, "expect_details": null, "abstained": null, "abstention_expected": null, "abstention_correct": null, "abstention_score": null, "hallucination_flags": [], "grounding_flags": [], "notes": null}}, "summary_metrics": {"winner_by_quality": null, "winner_by_quality_ties": ["prompt", "rag"], "winner_by_latency": "rag", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": null, "winner_by_expect_ties": ["prompt", "rag"]}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251229T232339Z:009:psql_connect", "timestamp": "2025-12-29T23:24:29.451134Z", "domain": "postgresql_docs", "mode": "docs", "query": "How do I connect to a PostgreSQL database using psql? Give a minimal example.", "case": {"id": "psql_connect", "tags": ["psql"], "answerable_from_general_knowledge": true, "requires_docs": true, "expected_abstain_in_docs": null}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "To connect to a PostgreSQL database using `psql`, you can use the following command in your terminal:\n\n```bash\npsql -h hostname -U username -d database_name\n```\n\nHere's a breakdown of the options:\n\n- `-h hostname`: The hostname of the database server (use `localhost` if it's on your local machine).\n- `-U username`: The username you want to connect with.\n- `-d database_name`: The name of the database you want to connect to.\n\nFor example, if you want to connect to a database named `mydb` on your local machine with the username `myuser`, you would run:\n\n```bash\npsql -h localhost -U myuser -d mydb\n```\n\nIf you are connecting to the default database with the same name as your username, you can simplify it to:\n\n```bash\npsql -U myuser\n```\n\nThis will connect to the database named `myuser` on the local machine.", "latency_ms": 3617, "tokens_in": 152, "tokens_out": 203, "cost_estimate_usd": 0.0001446, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "To connect to a PostgreSQL database using `psql`, you can use the command line with the `-d` option for the database name, and optionally specify the host and user. A minimal example would be:\n\n```bash\npsql -d your_database_name\n```\n\nIf you want to specify a user and host, you could use:\n\n```bash\npsql -h localhost -U your_username -d your_database_name\n```\n\nThis allows you to connect to the specified database on the local host as the given user [13373].", "latency_ms": 2448, "tokens_in": 1591, "tokens_out": 112, "cost_estimate_usd": 0.00030585, "retrieved_chunks": [{"chunk_id": 3307, "source": "domains/postgresql_docs/data/ecpg.sgml", "text_preview": "CONNECT TO connectdb AS :id;\nEXEC SQL CONNECT TO connectdb AS main USER connectuser/connectdb;\nEXEC SQL CONNECT TO connectdb AS main;\nEXEC SQL CONNECT TO connectdb@localhost AS main;\nEXEC SQL CONNECT TO tcp:postgresql://localhost/ USER connectdb;\nEXEC SQL CONNECT TO tcp:postgresql://localhost/connectdb USER connectuser IDENTIFIED BY connectpw;\nEXEC SQL CONNECT TO tcp:postgresql://localhost:20/connectdb USER connectuser IDENTIFIED BY connectpw;\nEXEC SQL CONNECT TO unix:postgresql://localhost/ AS main USER connectdb;\nEXEC SQL CONNECT TO unix:postgresql://localhost/connectdb AS main USER connectuser;\nEXEC SQL CONNECT TO unix:postgresql://localhost/connectdb USER connectuser IDENTIFIED BY \"connectpw\";\nEXEC SQL CONNECT TO unix:postgresql://localhost/connectdb USER connectuser USING \"connectpw\";\nEXEC SQL CONNECT TO unix:postgresql://localhost/connectdb?connect_timeout=14 USER connectuser;\n</p", "score": 0.5892574787139893}, {"chunk_id": 12822, "source": "domains/postgresql_docs/data/ref/pg_dumpall.sgml", "text_preview": "ut>psql -X -f db.out -d postgres</userinput>\n</screen>\n   It is not important which database you connect to here since the\n   script file created by <application>pg_dumpall</application> will\n   contain the appropriate commands to create and connect to the saved\n   databases.  An exception is that if you specified <option>--clean</option>,\n   you must connect to the <literal>postgres</literal> database initially;\n   the script will attempt to drop other databases immediately, and that\n   will fail for the database you are connected to.\n  </para>\n </refsect1>\n\n <refsect1>\n  <title>See Also</title>\n\n  <para>\n    Check <xref linkend=\"app-pgdump\"/> for details on possible\n    error conditions.\n  </para>\n </refsect1>\n\n</refentry>", "score": 0.581708550453186}, {"chunk_id": 13373, "source": "domains/postgresql_docs/data/ref/psql-ref.sgml", "text_preview": "database user name you want to connect as. <application>psql</application>\n    can be told about those parameters via command line options, namely\n    <option>-d</option>, <option>-h</option>, <option>-p</option>, and\n    <option>-U</option> respectively. If an argument is found that does\n    not belong to any option it will be interpreted as the database name\n    (or the database user name, if the database name is already given). Not all\n    of these options are required; there are useful defaults. If you omit the host\n    name, <application>psql</application> will connect via a Unix-domain socket\n    to a server on the local host, or via TCP/IP to <literal>localhost</literal> on\n    Windows. The default port number is\n    determined at compile time.\n    Since the database server uses the same default, you will not have\n    to specify the port in most cases. The default database user na", "score": 0.5616745948791504}, {"chunk_id": 14502, "source": "domains/postgresql_docs/data/runtime.sgml", "text_preview": "nused port.  (IANA\n   reserves ports 49152 through 65535 for private use.)  The name or IP\n   address after this is the remote bind address you are connecting to,\n   i.e., <literal>localhost</literal>, which is the default.  The second\n   number, 5432, is the remote end of the tunnel, e.g., the port number\n   your database server is using.  In order to connect to the database\n   server using this tunnel, you connect to port 63333 on the local\n   machine:\n<programlisting>\npsql -h localhost -p 63333 postgres\n</programlisting>\n   To the database server it will then look as though you are\n   user <literal>joe</literal> on host <literal>foo.com</literal>\n   connecting to the <literal>localhost</literal> bind address, and it\n   will use whatever authentication procedure was configured for\n   connections by that user to that bind address.  Note that the server will not\n   think the connection i", "score": 0.5512397289276123}, {"chunk_id": 14926, "source": "domains/postgresql_docs/data/start.sgml", "text_preview": "le>\n\n   <indexterm zone=\"tutorial-accessdb\">\n    <primary>psql</primary>\n   </indexterm>\n\n   <para>\n    Once you have created a database, you can access it by:\n\n    <itemizedlist spacing=\"compact\" mark=\"bullet\">\n     <listitem>\n      <para>\n       Running the <productname>PostgreSQL</productname> interactive\n       terminal program, called <application><firstterm>psql</firstterm></application>, which allows you\n       to interactively enter, edit, and execute\n       <acronym>SQL</acronym> commands.\n      </para>\n     </listitem>\n\n     <listitem>\n      <para>\n       Using an existing graphical frontend tool like\n       <application>pgAdmin</application> or an office suite with\n       <acronym>ODBC</acronym> or <acronym>JDBC</acronym> support to create and manipulate a\n       database.  These possibilities are not covered in this\n       tutorial.\n      </para>\n     </listitem>\n\n     <listi", "score": 0.5378507375717163}, {"chunk_id": 13391, "source": "domains/postgresql_docs/data/ref/psql-ref.sgml", "text_preview": "d\n         query protocol from <application>psql</application>.\n        </para>\n\n       </listitem>\n      </varlistentry>\n\n      <varlistentry id=\"app-psql-meta-command-c-lc\">\n        <term><literal>\\c</literal> or <literal>\\connect [ -reuse-previous=<replaceable class=\"parameter\">on|off</replaceable> ] [ <replaceable class=\"parameter\">dbname</replaceable> [ <replaceable class=\"parameter\">username</replaceable> ] [ <replaceable class=\"parameter\">host</replaceable> ] [ <replaceable class=\"parameter\">port</replaceable> ] | <replaceable class=\"parameter\">conninfo</replaceable> ]</literal></term>\n        <listitem>\n        <para>\n        Establishes a new connection to a <productname>PostgreSQL</productname>\n        server.  The connection parameters to use can be specified either\n        using a positional syntax (one or more of database name, user,\n        host, and port), or using a <repl", "score": 0.5368902683258057}], "flags": {}, "error": null}, "finetune": {"pipeline": "finetune", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "", "latency_ms": 0, "tokens_in": null, "tokens_out": null, "cost_estimate_usd": null, "retrieved_chunks": null, "flags": {}, "error": "MISSING_FINETUNED_MODEL: set OPENAI_FINETUNED_MODEL or domains/<domain>/config.yaml finetuned_model"}}, "evaluations": {"prompt": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}, "rag": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}, "finetune": {"quality_score": null, "penalty_total": null, "rule_breakdown": [], "expect_score": null, "expect_details": null, "abstained": null, "abstention_expected": null, "abstention_correct": null, "abstention_score": null, "hallucination_flags": [], "grounding_flags": [], "notes": null}}, "summary_metrics": {"winner_by_quality": null, "winner_by_quality_ties": ["prompt", "rag"], "winner_by_latency": "rag", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": null, "winner_by_expect_ties": ["prompt", "rag"]}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251229T232339Z:010:trap_capital_france", "timestamp": "2025-12-29T23:24:30.071834Z", "domain": "postgresql_docs", "mode": "docs", "query": "What is the capital of France? Answer only if the PostgreSQL docs explicitly say so.", "case": {"id": "trap_capital_france", "tags": ["trap", "edge_case", "unsupported_claim"], "answerable_from_general_knowledge": true, "requires_docs": false, "expected_abstain_in_docs": true}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "I don't know.", "latency_ms": 465, "tokens_in": 152, "tokens_out": 4, "cost_estimate_usd": 2.5200000000000003e-05, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "I don't know.", "latency_ms": 598, "tokens_in": 1713, "tokens_out": 4, "cost_estimate_usd": 0.00025935, "retrieved_chunks": [{"chunk_id": 13276, "source": "domains/postgresql_docs/data/ref/postgres-ref.sgml", "text_preview": "<!--\ndoc/src/sgml/ref/postgres-ref.sgml\nPostgreSQL documentation\n-->\n\n<refentry id=\"app-postgres\">\n <indexterm zone=\"app-postgres\">\n  <primary>postgres</primary>\n </indexterm>\n\n <refmeta>\n  <refentrytitle><application>postgres</application></refentrytitle>\n  <manvolnum>1</manvolnum>\n  <refmiscinfo>Application</refmiscinfo>\n </refmeta>\n\n <refnamediv>\n  <refname>postgres</refname>\n  <refpurpose><productname>PostgreSQL</productname> database server</refpurpose>\n </refnamediv>\n\n <refsynopsisdiv>\n  <cmdsynopsis>\n   <command>postgres</command>\n   <arg rep=\"repeat\"><replaceable>option</replaceable></arg>\n  </cmdsynopsis>\n </refsynopsisdiv>\n\n <refsect1>\n  <title>Description</title>\n\n  <para>\n   <command>postgres</command> is the\n   <productname>PostgreSQL</productname> database server.  In order\n   for a client application to access a database it connects (over a\n   network or locally) to a runn", "score": 0.426818311214447}, {"chunk_id": 9621, "source": "domains/postgresql_docs/data/problems.sgml", "text_preview": "d <quote>PostgreSQL</quote>,\n   sometimes <quote>Postgres</quote> for short. If you\n   are specifically talking about the backend process, mention that, do not\n   just say <quote>PostgreSQL crashes</quote>.  A crash of a single\n   backend process is quite different from crash of the parent\n   <quote>postgres</quote> process; please don't say <quote>the server\n   crashed</quote> when you mean a single backend process went down, nor vice versa.\n   Also, client programs such as the interactive frontend <quote><application>psql</application></quote>\n   are completely separate from the backend.  Please try to be specific\n   about whether the problem is on the client or server side.\n  </para>\n </sect2>\n\n <sect2 id=\"bug-reporting-where-to-report-bugs\">\n  <title>Where to Report Bugs</title>\n\n  <para>\n   In general, send bug reports to the bug report mailing list at\n   <email>pgsql-bugs@lists.pos", "score": 0.4207918047904968}, {"chunk_id": 6646, "source": "domains/postgresql_docs/data/installation.sgml", "text_preview": "n current\n   versions of these operating systems: Linux, Windows,\n   FreeBSD, OpenBSD, NetBSD, DragonFlyBSD, macOS, Solaris, and illumos.\n   Other Unix-like systems may also work but are not currently\n   being tested.  In most cases, all CPU architectures supported by\n   a given operating system will work.  Look in\n   <xref linkend=\"installation-platform-notes\"/> below to see if\n   there is information\n   specific to your operating system, particularly if using an older system.\n  </para>\n\n  <para>\n   If you have installation problems on a platform that is known\n   to be supported according to recent build farm results, please report\n   it to <email>pgsql-bugs@lists.postgresql.org</email>.  If you are interested\n   in porting <productname>PostgreSQL</productname> to a new platform,\n   <email>pgsql-hackers@lists.postgresql.org</email> is the appropriate place\n   to discuss that.\n  </para>", "score": 0.4104219079017639}, {"chunk_id": 15011, "source": "domains/postgresql_docs/data/syntax.sgml", "text_preview": "ctname>PostgreSQL</productname> is\n     following the standard.)\n    </para>\n   </sect3>\n\n   <sect3 id=\"sql-syntax-strings-escape\">\n    <title>String Constants with C-Style Escapes</title>\n\n     <indexterm zone=\"sql-syntax-strings-escape\">\n      <primary>escape string syntax</primary>\n     </indexterm>\n     <indexterm zone=\"sql-syntax-strings-escape\">\n      <primary>backslash escapes</primary>\n     </indexterm>\n\n    <para>\n     <productname>PostgreSQL</productname> also accepts <quote>escape</quote>\n     string constants, which are an extension to the SQL standard.\n     An escape string constant is specified by writing the letter\n     <literal>E</literal> (upper or lower case) just before the opening single\n     quote, e.g., <literal>E'foo'</literal>.  (When continuing an escape string\n     constant across lines, write <literal>E</literal> only before the first opening\n     quote.)", "score": 0.40709689259529114}, {"chunk_id": 59, "source": "domains/postgresql_docs/data/advanced.sgml", "text_preview": "name>capitals</structname>\n    <firstterm>inherits</firstterm> all columns (<structfield>name</structfield>,\n    <structfield>population</structfield>, and <structfield>elevation</structfield>) from its\n    <firstterm>parent</firstterm>, <structname>cities</structname>.  The\n    type of the column <structfield>name</structfield> is\n    <type>text</type>, a native <productname>PostgreSQL</productname>\n    type for variable length character strings.  The\n    <structname>capitals</structname> table has\n    an additional column, <structfield>state</structfield>, which shows its\n    state abbreviation.  In\n    <productname>PostgreSQL</productname>, a table can inherit from\n    zero or more other tables.\n   </para>\n\n   <para>\n    For example, the  following  query finds the  names  of  all  cities,\n    including  state capitals, that are located at an elevation\n    over 500 feet:\n\n<programlist", "score": 0.4068037271499634}, {"chunk_id": 9594, "source": "domains/postgresql_docs/data/postgres.sgml", "text_preview": "<!-- doc/src/sgml/postgres.sgml -->\n\n<!DOCTYPE book PUBLIC \"-//OASIS//DTD DocBook XML V4.5//EN\"\n          \"http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd\"\n[\n\n<!ENTITY % version SYSTEM \"version.sgml\">\n%version;\n<!ENTITY % filelist SYSTEM \"filelist.sgml\">\n%filelist;\n\n<!ENTITY commit_baseurl \"https://postgr.es/c/\">\n<!ENTITY reference  SYSTEM \"reference.sgml\">\n\n<!--\nZero-width space.  Use this to allow line breaks at desirable places in\ntable cells, examples, etc. without causing an unwanted space when the\nbreak is not needed in a wider output rendering.\n-->\n<!ENTITY zwsp \"&#x200B;\">\n\n]>\n\n<book id=\"postgres\">\n <title>PostgreSQL &version; Documentation</title>\n\n <bookinfo>\n  <corpauthor>The PostgreSQL Global Development Group</corpauthor>\n  <productname>PostgreSQL</productname>\n  <productnumber>&version;</productnumber>\n  &legal;\n </bookinfo>\n\n &intro;\n\n <part id=\"tutorial\">\n  <title>", "score": 0.4064069986343384}], "flags": {}, "error": null}, "finetune": {"pipeline": "finetune", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "", "latency_ms": 0, "tokens_in": null, "tokens_out": null, "cost_estimate_usd": null, "retrieved_chunks": null, "flags": {}, "error": "MISSING_FINETUNED_MODEL: set OPENAI_FINETUNED_MODEL or domains/<domain>/config.yaml finetuned_model"}}, "evaluations": {"prompt": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": true, "abstention_expected": true, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}, "rag": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": true, "abstention_expected": true, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}, "finetune": {"quality_score": null, "penalty_total": null, "rule_breakdown": [], "expect_score": null, "expect_details": null, "abstained": null, "abstention_expected": null, "abstention_correct": null, "abstention_score": null, "hallucination_flags": [], "grounding_flags": [], "notes": null}}, "summary_metrics": {"winner_by_quality": null, "winner_by_quality_ties": ["prompt", "rag"], "winner_by_latency": "prompt", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": null, "winner_by_expect_ties": ["prompt", "rag"]}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251230T011239Z:001:what_is_postgresql", "timestamp": "2025-12-30T01:12:45.886952Z", "domain": "postgresql_docs", "mode": "docs", "query": "What is PostgreSQL and what is it commonly used for?", "case": {"id": "what_is_postgresql", "tags": ["intro"], "answerable_from_general_knowledge": true, "requires_docs": false, "expected_abstain_in_docs": null}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "PostgreSQL is an open-source relational database management system (RDBMS) that is known for its robustness, extensibility, and standards compliance. It is designed to handle a wide range of workloads, from single-machine applications to large-scale data warehousing and web applications.\n\nCommon uses of PostgreSQL include:\n\n1. **Web Applications**: Many web applications use PostgreSQL as their backend database due to its reliability and support for complex queries.\n\n2. **Data Warehousing**: PostgreSQL can be used for data warehousing solutions, allowing for the storage and analysis of large volumes of data.\n\n3. **Geospatial Applications**: With the PostGIS extension, PostgreSQL is widely used for geographic information systems (GIS) and geospatial data processing.\n\n4. **Business Applications**: It is often used in enterprise applications for managing business data and transactions.\n\n5. **Data Analysis**: PostgreSQL supports advanced data types and indexing, making it suitable for analytical queries and reporting.\n\n6. **Application Development**: Developers use PostgreSQL for building applications that require a reliable and scalable database solution.\n\nOverall, PostgreSQL is favored for its advanced features, such as support for JSON data types, full-text search, and custom extensions, making it versatile for various use cases.", "latency_ms": 6027, "tokens_in": 146, "tokens_out": 256, "cost_estimate_usd": 0.00017549999999999998, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "PostgreSQL is an open-source descendant of the original Berkeley code from the POSTGRES project, which supports a large part of the SQL standard and offers many modern features. It is commonly used for complex queries, foreign keys, triggers, updatable views, transactional integrity, and multiversion concurrency control (MVCC) among other functionalities [6708]. \n\nIt is designed to handle a wide range of workloads, from single machines to data warehouses or web services with many concurrent users [6708].", "latency_ms": 2222, "tokens_in": 1394, "tokens_out": 100, "cost_estimate_usd": 0.00026910000000000004, "retrieved_chunks": [{"chunk_id": 5837, "source": "domains/postgresql_docs/data/history.sgml", "text_preview": "k at Postgres</quote>\n  <xref linkend=\"hell18\"/>.\n </para>\n\n <sect2 id=\"history-berkeley\">\n  <title>The Berkeley <productname>POSTGRES</productname> Project</title>\n\n  <indexterm zone=\"history-berkeley\">\n   <primary>POSTGRES</primary>\n  </indexterm>\n\n  <para>\n   The <productname>POSTGRES</productname> project, led by Professor\n   Michael Stonebraker, was sponsored by the Defense Advanced Research\n   Projects Agency (<acronym>DARPA</acronym>), the Army Research\n   Office (<acronym>ARO</acronym>), the National Science Foundation\n   (<acronym>NSF</acronym>), and ESL, Inc.  The implementation of\n   <productname>POSTGRES</productname> began in 1986.  The initial\n   concepts for the system were presented in <xref linkend=\"ston86\"/>,\n   and the definition of the initial data model appeared in <xref\n   linkend=\"rowe87\"/>.  The design of the rule system at that time was\n   described in <xref link", "score": 0.554345965385437}, {"chunk_id": 6708, "source": "domains/postgresql_docs/data/intro.sgml", "text_preview": "ble in some commercial database systems much later.\n  </para>\n\n  <para>\n   <productname>PostgreSQL</productname> is an open-source descendant\n   of this original Berkeley code.  It supports a large part of the SQL\n   standard and offers many modern features:\n\n   <itemizedlist spacing=\"compact\">\n    <listitem>\n     <simpara><link linkend=\"sql\">complex queries</link></simpara>\n    </listitem>\n    <listitem>\n     <simpara><link linkend=\"ddl-constraints-fk\">foreign keys</link></simpara>\n    </listitem>\n    <listitem>\n     <simpara><link linkend=\"triggers\">triggers</link></simpara>\n    </listitem>\n    <listitem>\n     <simpara><link linkend=\"sql-createview-updatable-views\">updatable views</link></simpara>\n    </listitem>\n    <listitem>\n     <simpara><link linkend=\"transaction-iso\">transactional integrity</link></simpara>\n    </listitem>\n    <listitem>\n     <simpara><link linkend=\"mvcc\">multive", "score": 0.5531245470046997}, {"chunk_id": 10690, "source": "domains/postgresql_docs/data/ref/alter_trigger.sgml", "text_preview": "e>PostgreSQL</productname>\n   extension of the SQL standard.\n  </para>\n </refsect1>\n\n <refsect1>\n  <title>See Also</title>\n\n  <simplelist type=\"inline\">\n   <member><xref linkend=\"sql-altertable\"/></member>\n  </simplelist>\n </refsect1>\n</refentry>", "score": 0.5431632399559021}, {"chunk_id": 9080, "source": "domains/postgresql_docs/data/plpgsql.sgml", "text_preview": "putation functions and later use\n    them to define operators or use them in index expressions.\n   </para>\n\n   <para>\n    In <productname>PostgreSQL</productname> 9.0 and later,\n    <application>PL/pgSQL</application> is installed by default.\n    However it is still a loadable module, so especially security-conscious\n    administrators could choose to remove it.\n   </para>\n\n  <sect2 id=\"plpgsql-advantages\">\n   <title>Advantages of Using <application>PL/pgSQL</application></title>\n\n    <para>\n     <acronym>SQL</acronym> is the language <productname>PostgreSQL</productname>\n     and most other relational databases use as query language. It's\n     portable and easy to learn. But every <acronym>SQL</acronym>\n     statement must be executed individually by the database server.\n    </para>\n\n    <para>\n     That means that your client application must send each query to\n     the database server", "score": 0.5362441539764404}, {"chunk_id": 7420, "source": "domains/postgresql_docs/data/lobj.sgml", "text_preview": "ge object data.  We use the <application>libpq</application> C\n    library for the examples in this chapter, but most programming\n    interfaces native to <productname>PostgreSQL</productname> support\n    equivalent functionality.  Other interfaces might use the large\n    object interface internally to provide generic support for large\n    values.  This is not described here.\n   </para>\n\n  <sect1 id=\"lo-intro\">\n   <title>Introduction</title>\n\n   <indexterm>\n    <primary>TOAST</primary>\n    <secondary>versus large objects</secondary>\n   </indexterm>\n\n   <para>\n    All large objects are stored in a single system table named <link\n    linkend=\"catalog-pg-largeobject\"><structname>pg_largeobject</structname></link>.\n    Each large object also has an entry in the system table <link\n    linkend=\"catalog-pg-largeobject-metadata\"><structname>pg_largeobject_metadata</structname></link>.\n    Large", "score": 0.5288234353065491}, {"chunk_id": 11435, "source": "domains/postgresql_docs/data/ref/create_schema.sgml", "text_preview": ">PostgreSQL</productname> extension.\n  </para>\n </refsect1>\n\n <refsect1>\n  <title>See Also</title>\n\n  <simplelist type=\"inline\">\n   <member><xref linkend=\"sql-alterschema\"/></member>\n   <member><xref linkend=\"sql-dropschema\"/></member>\n </simplelist>\n </refsect1>\n\n</refentry>", "score": 0.5239441394805908}], "flags": {}, "error": null}}, "evaluations": {"prompt": {"quality_score": 0.5, "penalty_total": 0.5, "rule_breakdown": [{"rule": "prompt_docs_evidence_check", "penalty": 0.5, "hallucination_flags": [], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "note": "Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "notes": "Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}, "rag": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 0.5, "expect_details": {"missing": ["database | relational"]}, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}}, "summary_metrics": {"winner_by_quality": "rag", "winner_by_latency": "rag", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": "prompt"}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251230T011239Z:002:create_table_basics", "timestamp": "2025-12-30T01:12:49.061011Z", "domain": "postgresql_docs", "mode": "docs", "query": "How do I create a table in PostgreSQL? Show a minimal example.", "case": {"id": "create_table_basics", "tags": ["sql", "ddl"], "answerable_from_general_knowledge": true, "requires_docs": false, "expected_abstain_in_docs": null}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "To create a table in PostgreSQL, you use the `CREATE TABLE` statement. Here is a minimal example of creating a table named `employees` with two columns: `id` (an integer) and `name` (a text string).\n\n```sql\nCREATE TABLE employees (\n    id SERIAL PRIMARY KEY,\n    name TEXT NOT NULL\n);\n```\n\nIn this example:\n- `id` is defined as a `SERIAL` type, which automatically generates a unique identifier for each row.\n- `name` is defined as `TEXT` and is marked as `NOT NULL`, meaning it cannot be empty.\n\nThis is a basic structure to get you started with creating a table in PostgreSQL.", "latency_ms": 3165, "tokens_in": 149, "tokens_out": 141, "cost_estimate_usd": 0.00010695000000000001, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "To create a table in PostgreSQL, you can use the `CREATE TABLE` statement followed by the table name and the definitions of its columns along with their data types. Here is a minimal example:\n\n```sql\nCREATE TABLE weather (\n    city varchar(80),\n    temp_lo int,\n    temp_hi int\n);\n```\n\nIn this example, a table named `weather` is created with three columns: `city` of type `varchar(80)`, `temp_lo` of type `int`, and `temp_hi` of type `int` [10118].", "latency_ms": 2643, "tokens_in": 1671, "tokens_out": 116, "cost_estimate_usd": 0.00032025, "retrieved_chunks": [{"chunk_id": 11524, "source": "domains/postgresql_docs/data/ref/create_table.sgml", "text_preview": "<!--\ndoc/src/sgml/ref/create_table.sgml\nPostgreSQL documentation\n-->\n\n<refentry id=\"sql-createtable\">\n <indexterm zone=\"sql-createtable\">\n  <primary>CREATE TABLE</primary>\n </indexterm>\n\n <refmeta>\n  <refentrytitle>CREATE TABLE</refentrytitle>\n  <manvolnum>7</manvolnum>\n  <refmiscinfo>SQL - Language Statements</refmiscinfo>\n </refmeta>\n\n <refnamediv>\n  <refname>CREATE TABLE</refname>\n  <refpurpose>define a new table</refpurpose>\n </refnamediv>\n\n <refsynopsisdiv>\n<synopsis>\nCREATE [ [ GLOBAL | LOCAL ] { TEMPORARY | TEMP } | UNLOGGED ] TABLE [ IF NOT EXISTS ] <replaceable class=\"parameter\">table_name</replaceable> ( [\n  { <replaceable class=\"parameter\">column_name</replaceable> <replaceable class=\"parameter\">data_type</replaceable> [ STORAGE { PLAIN | EXTERNAL | EXTENDED | MAIN | DEFAULT } ] [ COMPRESSION <replaceable>compression_method</replaceable> ] [ COLLATE <replaceable>collation</rep", "score": 0.6500338912010193}, {"chunk_id": 432, "source": "domains/postgresql_docs/data/bki.sgml", "text_preview": "ill create the table\n   <literal>test_table</literal> with OID 420, having three columns\n   <literal>oid</literal>, <literal>cola</literal> and <literal>colb</literal>\n   of type <type>oid</type>, <type>int4</type> and <type>text</type>,\n   respectively, and insert two rows into the table:\n<programlisting>\ncreate test_table 420 (oid = oid, cola = int4, colb = text)\nopen test_table\ninsert ( 421 1 'value 1' )\ninsert ( 422 2 _null_ )\nclose test_table\n</programlisting>\n  </para>\n </sect1>\n</chapter>", "score": 0.6008813381195068}, {"chunk_id": 11677, "source": "domains/postgresql_docs/data/ref/create_table_as.sgml", "text_preview": "<!--\ndoc/src/sgml/ref/create_table_as.sgml\nPostgreSQL documentation\n-->\n\n<refentry id=\"sql-createtableas\">\n <indexterm zone=\"sql-createtableas\">\n  <primary>CREATE TABLE AS</primary>\n </indexterm>\n\n <refmeta>\n  <refentrytitle>CREATE TABLE AS</refentrytitle>\n  <manvolnum>7</manvolnum>\n  <refmiscinfo>SQL - Language Statements</refmiscinfo>\n </refmeta>\n\n <refnamediv>\n  <refname>CREATE TABLE AS</refname>\n  <refpurpose>define a new table from the results of a query</refpurpose>\n </refnamediv>\n\n <refsynopsisdiv>\n<synopsis>\nCREATE [ [ GLOBAL | LOCAL ] { TEMPORARY | TEMP } | UNLOGGED ] TABLE [ IF NOT EXISTS ] <replaceable>table_name</replaceable>\n    [ (<replaceable>column_name</replaceable> [, ...] ) ]\n    [ USING <replaceable class=\"parameter\">method</replaceable> ]\n    [ WITH ( <replaceable class=\"parameter\">storage_parameter</replaceable> [= <replaceable class=\"parameter\">value</replaceable>]", "score": 0.5858688354492188}, {"chunk_id": 10118, "source": "domains/postgresql_docs/data/query.sgml", "text_preview": "isplay).\n   </para>\n\n   <para>\n    <indexterm><primary>database cluster</primary></indexterm>\n    <indexterm><primary>cluster</primary><secondary>of databases</secondary><see>database cluster</see></indexterm>\n\n    Tables are grouped into databases, and a collection of databases\n    managed by a single <productname>PostgreSQL</productname> server\n    instance constitutes a database <firstterm>cluster</firstterm>.\n   </para>\n  </sect1>\n\n\n  <sect1 id=\"tutorial-table\">\n   <title>Creating a New Table</title>\n\n   <indexterm zone=\"tutorial-table\">\n    <primary>CREATE TABLE</primary>\n   </indexterm>\n\n   <para>\n    You  can  create  a  new  table by specifying the table\n    name, along with all column names and their types:\n\n<programlisting>\nCREATE TABLE weather (\n    city            varchar(80),\n    temp_lo         int,           -- low temperature\n    temp_hi         int,           -- high tem", "score": 0.5616394281387329}, {"chunk_id": 11024, "source": "domains/postgresql_docs/data/ref/create_database.sgml", "text_preview": "[ COLLATION_VERSION = <replaceable>collation_version</replaceable> ]\n           [ TABLESPACE [=] <replaceable class=\"parameter\">tablespace_name</replaceable> ]\n           [ ALLOW_CONNECTIONS [=] <replaceable class=\"parameter\">allowconn</replaceable> ]\n           [ CONNECTION LIMIT [=] <replaceable class=\"parameter\">connlimit</replaceable> ]\n           [ IS_TEMPLATE [=] <replaceable class=\"parameter\">istemplate</replaceable> ]\n           [ OID [=] <replaceable class=\"parameter\">oid</replaceable> ]\n</synopsis>\n </refsynopsisdiv>\n\n <refsect1>\n  <title>Description</title>\n\n  <para>\n   <command>CREATE DATABASE</command> creates a new\n   <productname>PostgreSQL</productname> database.\n  </para>\n\n  <para>\n   To create a database, you must be a superuser or have the special\n   <literal>CREATEDB</literal> privilege.\n   See <xref linkend=\"sql-createrole\"/>.\n  </para>\n\n  <para>\n   By defa", "score": 0.557640790939331}, {"chunk_id": 11093, "source": "domains/postgresql_docs/data/ref/create_foreign_table.sgml", "text_preview": "<!--\ndoc/src/sgml/ref/create_foreign_table.sgml\nPostgreSQL documentation\n-->\n\n<refentry id=\"sql-createforeigntable\">\n <indexterm zone=\"sql-createforeigntable\">\n  <primary>CREATE FOREIGN TABLE</primary>\n </indexterm>\n\n <refmeta>\n  <refentrytitle>CREATE FOREIGN TABLE</refentrytitle>\n  <manvolnum>7</manvolnum>\n  <refmiscinfo>SQL - Language Statements</refmiscinfo>\n </refmeta>\n\n <refnamediv>\n  <refname>CREATE FOREIGN TABLE</refname>\n  <refpurpose>define a new foreign table</refpurpose>\n </refnamediv>\n\n <refsynopsisdiv>\n<synopsis>\nCREATE FOREIGN TABLE [ IF NOT EXISTS ] <replaceable class=\"parameter\">table_name</replaceable> ( [\n  { <replaceable class=\"parameter\">column_name</replaceable> <replaceable class=\"parameter\">data_type</replaceable> [ OPTIONS ( <replaceable class=\"parameter\">option</replaceable> '<replaceable class=\"parameter\">value</replaceable>' [, ... ] ) ] [ COLLATE <replaceable>", "score": 0.5558017492294312}], "flags": {}, "error": null}}, "evaluations": {"prompt": {"quality_score": 0.5, "penalty_total": 0.5, "rule_breakdown": [{"rule": "prompt_docs_evidence_check", "penalty": 0.5, "hallucination_flags": [], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "note": "Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "notes": "Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}, "rag": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}}, "summary_metrics": {"winner_by_quality": "rag", "winner_by_latency": "rag", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": null, "winner_by_expect_ties": ["prompt", "rag"]}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251230T011239Z:003:primary_key", "timestamp": "2025-12-30T01:12:54.851925Z", "domain": "postgresql_docs", "mode": "docs", "query": "How do I define a primary key in PostgreSQL?", "case": {"id": "primary_key", "tags": ["sql", "ddl"], "answerable_from_general_knowledge": true, "requires_docs": false, "expected_abstain_in_docs": null}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "In PostgreSQL, you can define a primary key in several ways, typically when creating a table or altering an existing table. According to the official documentation, a primary key can be defined using the `PRIMARY KEY` constraint.\n\nHere are the common methods to define a primary key:\n\n1. **When Creating a New Table:**\n   You can define a primary key at the time of table creation using the `CREATE TABLE` statement. For example:\n\n   ```sql\n   CREATE TABLE my_table (\n       id SERIAL PRIMARY KEY,\n       name VARCHAR(100)\n   );\n   ```\n\n   In this example, the `id` column is defined as the primary key.\n\n2. **Using a Separate Constraint:**\n   You can also define a primary key constraint separately from the column definitions:\n\n   ```sql\n   CREATE TABLE my_table (\n       id SERIAL,\n       name VARCHAR(100),\n       CONSTRAINT my_table_pkey PRIMARY KEY (id)\n   );\n   ```\n\n3. **Altering an Existing Table:**\n   If you want to add a primary key to an existing table, you can use the `ALTER TABLE` statement:\n\n   ```sql\n   ALTER TABLE my_table\n   ADD CONSTRAINT my_table_pkey PRIMARY KEY (id);\n   ```\n\nIn all cases, the primary key must contain unique values and cannot contain NULLs. \n\nFor more detailed information, you can refer to the official PostgreSQL documentation on constraints and primary keys.", "latency_ms": 5783, "tokens_in": 145, "tokens_out": 293, "cost_estimate_usd": 0.00019755, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "To define a primary key in PostgreSQL, you can specify it when creating a table using the `PRIMARY KEY` constraint. This can be done for a single column or a group of columns. For example, you can create a table with a primary key on a single column like this:\n\n```sql\nCREATE TABLE products (\n    product_no integer PRIMARY KEY,\n    name text,\n    price numeric\n);\n```\n\nAlternatively, you can define a primary key that spans multiple columns, as shown in the following example:\n\n```sql\nCREATE TABLE example (\n    a integer,\n    b integer,\n    c integer,\n    PRIMARY KEY (a, c)\n);\n```\n\nWhen you add a primary key, PostgreSQL automatically creates a unique B-tree index on the column(s) specified and enforces that the values in those columns are both unique and not null [2675][2674].", "latency_ms": 4009, "tokens_in": 1609, "tokens_out": 177, "cost_estimate_usd": 0.00034754999999999996, "retrieved_chunks": [{"chunk_id": 2675, "source": "domains/postgresql_docs/data/ddl.sgml", "text_preview": "b integer,\n    c integer,\n    <emphasis>PRIMARY KEY (a, c)</emphasis>\n);\n</programlisting>\n   </para>\n\n   <para>\n    Adding a primary key will automatically create a unique B-tree index\n    on the column or group of columns listed in the primary key, and will\n    force the column(s) to be marked <literal>NOT NULL</literal>.\n   </para>\n\n   <para>\n    A table can have at most one primary key.  (There can be any number\n    of unique constraints, which combined with not-null constraints are functionally almost the\n    same thing, but only one can be identified as the primary key.)\n    Relational database theory\n    dictates that every table must have a primary key.  This rule is\n    not enforced by <productname>PostgreSQL</productname>, but it is\n    usually best to follow it.\n   </para>\n\n   <para>\n    Primary keys are useful both for\n    documentation purposes and for client applications.", "score": 0.6212462186813354}, {"chunk_id": 2276, "source": "domains/postgresql_docs/data/datatype.sgml", "text_preview": "mary>\n    </indexterm>\n\n    <indexterm>\n     <primary>auto-increment</primary>\n     <see>serial</see>\n    </indexterm>\n\n    <indexterm>\n     <primary>sequence</primary>\n     <secondary>and serial type</secondary>\n    </indexterm>\n\n    <note>\n     <para>\n      This section describes a PostgreSQL-specific way to create an\n      autoincrementing column.  Another way is to use the SQL-standard\n      identity column feature, described at <xref linkend=\"ddl-identity-columns\"/>.\n     </para>\n    </note>\n\n    <para>\n     The data types <type>smallserial</type>, <type>serial</type> and\n     <type>bigserial</type> are not true types, but merely\n     a notational convenience for creating unique identifier columns\n     (similar to the <literal>AUTO_INCREMENT</literal> property\n     supported by some other databases). In the current\n     implementation, specifying:\n\n<programlisting>\nCREATE TABLE <rep", "score": 0.5678392648696899}, {"chunk_id": 2714, "source": "domains/postgresql_docs/data/ddl.sgml", "text_preview": "gn key to our table is:\n\n<programlisting>\nCREATE TABLE variants (\n  id         integer,\n  product_no integer,\n  name       text,\n  valid_at   daterange,\n  PRIMARY KEY (id, valid_at WITHOUT OVERLAPS),\n  <emphasis>FOREIGN KEY (product_no, PERIOD valid_at) REFERENCES products (product_no, PERIOD valid_at)</emphasis>\n);\n</programlisting>\n\n     Note that the keyword <literal>PERIOD</literal> must be used for the\n     application-time column in both the referencing and referenced table.\n    </para>\n\n    <para>\n     A temporal primary key or unique constraint matching the referenced columns\n     must exist on the referenced table.\n    </para>\n\n    <para>\n     <productname>PostgreSQL</productname> supports temporal foreign keys with\n     action <literal>NO ACTION</literal>, but not <literal>RESTRICT</literal>,\n     <literal>CASCADE</literal>, <literal>SET NULL</literal>, or <literal>SET\n     DEF", "score": 0.5378071069717407}, {"chunk_id": 2674, "source": "domains/postgresql_docs/data/ddl.sgml", "text_preview": "erm>\n\n   <para>\n    A primary key constraint indicates that a column, or group of columns,\n    can be used as a unique identifier for rows in the table.  This\n    requires that the values be both unique and not null.  So, the following\n    two table definitions accept the same data:\n<programlisting>\nCREATE TABLE products (\n    product_no integer UNIQUE NOT NULL,\n    name text,\n    price numeric\n);\n</programlisting>\n\n<programlisting>\nCREATE TABLE products (\n    product_no integer <emphasis>PRIMARY KEY</emphasis>,\n    name text,\n    price numeric\n);\n</programlisting>\n   </para>\n\n   <para>\n    Primary keys can span more than one column; the syntax\n    is similar to unique constraints:\n<programlisting>\nCREATE TABLE example (\n    a integer,\n    b integer,\n    c integer,\n    <emphasis>PRIMARY KEY (a, c)</emphasis>\n);\n</programlisting>\n   </para>\n\n   <para>\n    Adding a primary key will automat", "score": 0.5303837060928345}, {"chunk_id": 2622, "source": "domains/postgresql_docs/data/dblink.sgml", "text_preview": "</refsect1>\n\n  <refsect1>\n   <title>Notes</title>\n\n   <para>\n    As of <productname>PostgreSQL</productname> 9.0, the attribute numbers in\n    <parameter>primary_key_attnums</parameter> are interpreted as logical\n    column numbers, corresponding to the column's position in\n    <literal>SELECT * FROM relname</literal>.  Previous versions interpreted the\n    numbers as physical column positions.  There is a difference if any\n    column(s) to the left of the indicated column have been dropped during\n    the lifetime of the table.\n   </para>\n  </refsect1>\n\n  <refsect1>\n   <title>Examples</title>\n\n<screen>\nSELECT dblink_build_sql_update('foo', '1 2', 2, '{\"1\", \"a\"}', '{\"1\", \"b\"}');\n                   dblink_build_sql_update\n-------------------------------------------------------------\n UPDATE foo SET f1='1',f2='b',f3='1' WHERE f1='1' AND f2='b'\n(1 row)\n</screen>\n  </refsect1>\n </refentry>", "score": 0.519985556602478}, {"chunk_id": 6172, "source": "domains/postgresql_docs/data/information_schema.sgml", "text_preview": "ave unlimited maximum cardinality in <productname>PostgreSQL</productname>\n      </para></entry>\n     </row>\n\n     <row>\n      <entry role=\"catalog_table_entry\"><para role=\"column_definition\">\n       <structfield>dtd_identifier</structfield> <type>sql_identifier</type>\n      </para>\n      <para>\n       An identifier of the data type descriptor of the column, unique\n       among the data type descriptors pertaining to the table.  This\n       is mainly useful for joining with other instances of such\n       identifiers.  (The specific format of the identifier is not\n       defined and not guaranteed to remain the same in future\n       versions.)\n      </para></entry>\n     </row>\n\n     <row>\n      <entry role=\"catalog_table_entry\"><para role=\"column_definition\">\n       <structfield>is_self_referencing</structfield> <type>yes_or_no</type>\n      </para>\n      <para>\n       Applies to a feature", "score": 0.5156258344650269}], "flags": {}, "error": null}}, "evaluations": {"prompt": {"quality_score": 0.35, "penalty_total": 0.65, "rule_breakdown": [{"rule": "overconfident_language_check", "penalty": 0.15, "hallucination_flags": ["OVERCONFIDENT_LANGUAGE"], "grounding_flags": [], "note": "Overconfident language detected."}, {"rule": "prompt_docs_evidence_check", "penalty": 0.5, "hallucination_flags": [], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "note": "Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": ["OVERCONFIDENT_LANGUAGE"], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "notes": "Overconfident language detected. Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}, "rag": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}}, "summary_metrics": {"winner_by_quality": "rag", "winner_by_latency": "rag", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": null, "winner_by_expect_ties": ["prompt", "rag"]}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251230T011239Z:004:transactions_basics", "timestamp": "2025-12-30T01:13:04.813664Z", "domain": "postgresql_docs", "mode": "docs", "query": "What is a transaction in PostgreSQL and how do I use BEGIN/COMMIT?", "case": {"id": "transactions_basics", "tags": ["transactions"], "answerable_from_general_knowledge": true, "requires_docs": false, "expected_abstain_in_docs": null}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "In PostgreSQL, a transaction is a sequence of one or more SQL operations that are executed as a single unit of work. A transaction ensures that either all operations are completed successfully, or none are applied at all, maintaining the integrity of the database. This is part of the ACID properties (Atomicity, Consistency, Isolation, Durability) that transactions adhere to.\n\nTo use transactions in PostgreSQL, you typically use the `BEGIN`, `COMMIT`, and `ROLLBACK` commands:\n\n1. **BEGIN**: This command starts a new transaction. After this command is issued, all subsequent operations will be part of this transaction until it is either committed or rolled back.\n\n   ```sql\n   BEGIN;\n   ```\n\n2. **COMMIT**: This command is used to save all the changes made during the transaction to the database. Once you issue a `COMMIT`, all operations performed since the `BEGIN` are permanently applied.\n\n   ```sql\n   COMMIT;\n   ```\n\n3. **ROLLBACK**: This command is used to undo all changes made during the transaction if something goes wrong or if you decide not to apply the changes. It reverts the database to the state it was in before the `BEGIN`.\n\n   ```sql\n   ROLLBACK;\n   ```\n\nHere is a simple example of using these commands:\n\n```sql\nBEGIN;\n\nINSERT INTO accounts (account_id, balance) VALUES (1, 100);\nINSERT INTO accounts (account_id, balance) VALUES (2, 200);\n\n-- If everything is fine, commit the transaction\nCOMMIT;\n\n-- If there was an error, you could instead roll back\n-- ROLLBACK;\n```\n\nIn this example, if the `COMMIT` is executed, both inserts will be saved. If an error occurs before the `COMMIT`, you can use `ROLLBACK` to discard the changes. \n\nThis transactional control allows for safe and reliable database operations.", "latency_ms": 9929, "tokens_in": 151, "tokens_out": 398, "cost_estimate_usd": 0.00026145, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "In PostgreSQL, a transaction is a sequence of SQL statements that are executed as a single unit of work. Transactions are important for maintaining data integrity, as they allow you to group multiple operations together, ensuring that either all of them are executed successfully or none at all. You can start a transaction by using the `BEGIN` command, and you can end it by using the `COMMIT` command if you want to save the changes made during the transaction. If you decide not to save the changes, you can use the `ROLLBACK` command to undo them [40].\n\nTo use `BEGIN` and `COMMIT`, you would typically write your SQL commands like this:\n\n```sql\nBEGIN;\n-- Your SQL statements here\nCOMMIT;\n```\n\nFor example, if you were updating an account balance, you might write:\n\n```sql\nBEGIN;\nUPDATE accounts SET balance = balance - 100.00 WHERE name = 'Alice';\nCOMMIT;\n```\n\nIf you encounter an issue and want to cancel the changes made during the transaction, you would replace `COMMIT` with `ROLLBACK` [39]. This structure allows you to manage your transactions effectively, ensuring that your database remains consistent.", "latency_ms": 7316, "tokens_in": 1557, "tokens_out": 242, "cost_estimate_usd": 0.00037874999999999996, "retrieved_chunks": [{"chunk_id": 40, "source": "domains/postgresql_docs/data/advanced.sgml", "text_preview": "ra>\n\n   <para>\n    <productname>PostgreSQL</productname> actually treats every SQL statement as being\n    executed within a transaction.  If you do not issue a <command>BEGIN</command>\n    command,\n    then each individual statement has an implicit <command>BEGIN</command> and\n    (if successful) <command>COMMIT</command> wrapped around it.  A group of\n    statements surrounded by <command>BEGIN</command> and <command>COMMIT</command>\n    is sometimes called a <firstterm>transaction block</firstterm>.\n   </para>\n\n   <note>\n    <para>\n     Some client libraries issue <command>BEGIN</command> and <command>COMMIT</command>\n     commands automatically, so that you might get the effect of transaction\n     blocks without asking.  Check the documentation for the interface\n     you are using.\n    </para>\n   </note>\n\n   <para>\n    It's possible to control the statements in a transaction in a more", "score": 0.702025294303894}, {"chunk_id": 10852, "source": "domains/postgresql_docs/data/ref/commit.sgml", "text_preview": "<para>\n   The command <command>COMMIT</command> conforms to the SQL standard.  The\n   form <literal>COMMIT TRANSACTION</literal> is a PostgreSQL extension.\n  </para>\n </refsect1>\n\n <refsect1>\n  <title>See Also</title>\n\n  <simplelist type=\"inline\">\n   <member><xref linkend=\"sql-begin\"/></member>\n   <member><xref linkend=\"sql-rollback\"/></member>\n  </simplelist>\n </refsect1>\n</refentry>", "score": 0.6939695477485657}, {"chunk_id": 9266, "source": "domains/postgresql_docs/data/plpgsql.sgml", "text_preview": "ctions\">\n   <title>Transaction Management</title>\n\n   <para>\n    In procedures invoked by the <command>CALL</command> command\n    as well as in anonymous code blocks (<command>DO</command> command),\n    it is possible to end transactions using the\n    commands <command>COMMIT</command> and <command>ROLLBACK</command>.  A new\n    transaction is started automatically after a transaction is ended using\n    these commands, so there is no separate <command>START\n    TRANSACTION</command> command.  (Note that <command>BEGIN</command> and\n    <command>END</command> have different meanings in PL/pgSQL.)\n   </para>\n\n   <para>\n    Here is a simple example:\n<programlisting>\nCREATE PROCEDURE transaction_test1()\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    FOR i IN 0..9 LOOP\n        INSERT INTO test1 (a) VALUES (i);\n        IF i % 2 = 0 THEN\n            COMMIT;\n        ELSE\n            ROLLBACK;\n        END IF;", "score": 0.672443151473999}, {"chunk_id": 10851, "source": "domains/postgresql_docs/data/ref/commit.sgml", "text_preview": "saction\"/>) as the just finished one.  Otherwise,\n      no new transaction is started.\n     </para>\n    </listitem>\n   </varlistentry>\n  </variablelist>\n </refsect1>\n\n <refsect1>\n  <title>Notes</title>\n\n  <para>\n   Use <xref linkend=\"sql-rollback\"/> to\n   abort a transaction.\n  </para>\n\n  <para>\n   Issuing <command>COMMIT</command> when not inside a transaction does\n   no harm, but it will provoke a warning message.  <command>COMMIT AND\n   CHAIN</command> when not inside a transaction is an error.\n  </para>\n </refsect1>\n\n <refsect1>\n  <title>Examples</title>\n\n  <para>\n   To commit the current transaction and make all changes permanent:\n<programlisting>\nCOMMIT;\n</programlisting></para>\n </refsect1>\n\n <refsect1>\n  <title>Compatibility</title>\n\n  <para>\n   The command <command>COMMIT</command> conforms to the SQL standard.  The\n   form <literal>COMMIT TRANSACTION</literal> is a PostgreSQL e", "score": 0.6655136346817017}, {"chunk_id": 39, "source": "domains/postgresql_docs/data/advanced.sgml", "text_preview": "ible simultaneously.\n   </para>\n\n   <para>\n    In <productname>PostgreSQL</productname>, a transaction is set up by surrounding\n    the SQL commands of the transaction with\n    <command>BEGIN</command> and <command>COMMIT</command> commands.  So our banking\n    transaction would actually look like:\n\n<programlisting>\nBEGIN;\nUPDATE accounts SET balance = balance - 100.00\n    WHERE name = 'Alice';\n-- etc etc\nCOMMIT;\n</programlisting>\n   </para>\n\n   <para>\n    If, partway through the transaction, we decide we do not want to\n    commit (perhaps we just noticed that Alice's balance went negative),\n    we can issue the command <command>ROLLBACK</command> instead of\n    <command>COMMIT</command>, and all our updates so far will be canceled.\n   </para>\n\n   <para>\n    <productname>PostgreSQL</productname> actually treats every SQL statement as being\n    executed within a transaction.  If you do no", "score": 0.6621338129043579}, {"chunk_id": 13994, "source": "domains/postgresql_docs/data/ref/start_transaction.sgml", "text_preview": "a>\n </refsect1>\n\n <refsect1>\n  <title>Compatibility</title>\n\n  <para>\n   In the standard, it is not necessary to issue <command>START TRANSACTION</command>\n   to start a transaction block: any SQL command implicitly begins a block.\n   <productname>PostgreSQL</productname>'s behavior can be seen as implicitly\n   issuing a <command>COMMIT</command> after each command that does not\n   follow <command>START TRANSACTION</command> (or <command>BEGIN</command>),\n   and it is therefore often called <quote>autocommit</quote>.\n   Other relational database systems might offer an autocommit feature\n   as a convenience.\n  </para>\n\n  <para>\n   The <literal>DEFERRABLE</literal>\n   <replaceable class=\"parameter\">transaction_mode</replaceable>\n   is a <productname>PostgreSQL</productname> language extension.\n  </para>\n\n  <para>\n   The SQL standard requires commas between successive <replaceable\n   class=", "score": 0.6581746339797974}], "flags": {}, "error": null}}, "evaluations": {"prompt": {"quality_score": 0.5, "penalty_total": 0.5, "rule_breakdown": [{"rule": "prompt_docs_evidence_check", "penalty": 0.5, "hallucination_flags": [], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "note": "Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "notes": "Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}, "rag": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}}, "summary_metrics": {"winner_by_quality": "rag", "winner_by_latency": "rag", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": null, "winner_by_expect_ties": ["prompt", "rag"]}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251230T011239Z:005:create_index", "timestamp": "2025-12-30T01:13:11.448858Z", "domain": "postgresql_docs", "mode": "docs", "query": "How do I create an index in PostgreSQL and when would I use one?", "case": {"id": "create_index", "tags": ["indexing"], "answerable_from_general_knowledge": true, "requires_docs": false, "expected_abstain_in_docs": null}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "To create an index in PostgreSQL, you can use the `CREATE INDEX` statement. The basic syntax is as follows:\n\n```sql\nCREATE INDEX index_name ON table_name (column_name);\n```\n\nYou can also create more complex indexes, such as multi-column indexes or indexes with specific types. For example:\n\n```sql\nCREATE INDEX index_name ON table_name (column1, column2);\n```\n\nYou can specify the index type (e.g., `btree`, `hash`, etc.) and other options as well:\n\n```sql\nCREATE INDEX index_name ON table_name USING btree (column_name);\n```\n\n### When to Use an Index\n\nYou would typically use an index in PostgreSQL to:\n\n1. **Improve Query Performance**: Indexes can significantly speed up data retrieval operations, especially for large tables. They are particularly useful for columns that are frequently used in `WHERE` clauses, join conditions, or as part of an `ORDER BY` clause.\n\n2. **Enforce Uniqueness**: You can create unique indexes to ensure that no two rows have the same value in a specified column or set of columns.\n\n3. **Facilitate Sorting**: Indexes can help speed up sorting operations.\n\n4. **Support Full-Text Search**: Certain types of indexes, like GIN or GiST, can be used to support full-text search capabilities.\n\nHowever, it's important to note that while indexes can improve read performance, they can also slow down write operations (INSERT, UPDATE, DELETE) because the index must be updated whenever the data changes. Therefore, you should carefully consider which columns to index based on your application's query patterns.\n\nFor more detailed information, you can refer to the official PostgreSQL documentation on indexes.", "latency_ms": 6020, "tokens_in": 150, "tokens_out": 354, "cost_estimate_usd": 0.0002349, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "To create an index in PostgreSQL, you can use the `CREATE INDEX` statement. The basic syntax is as follows:\n\n```\nCREATE [ UNIQUE ] INDEX [ CONCURRENTLY ] [ [ IF NOT EXISTS ] name ] ON [ ONLY ] table_name [ USING method ]\n    ( { column_name | ( expression ) } [ COLLATE collation ] [ opclass ] [, ...] )\n    [ WITH ( storage_parameter = value [, ...] ) ]\n    [ TABLESPACE tablespace ]\n    [ WHERE predicate ];\n```\n\nThis command allows you to define a new index on one or more columns of a table, which can optimize query performance, especially for queries that involve `WHERE` or `JOIN` clauses [11178][11221].\n\nYou would use an index when you want to improve the speed of data retrieval operations. Indexes can significantly enhance the performance of queries that filter results based on specific conditions, such as those using `WHERE` clauses or joining tables [5993]. However, it's important to note that while indexes can speed up read operations, they also add overhead to write operations, as the system must keep the index synchronized with the table [5996]. Therefore, you should consider creating indexes on columns that are frequently used in queries to optimize performance.", "latency_ms": 6625, "tokens_in": 1697, "tokens_out": 256, "cost_estimate_usd": 0.00040815, "retrieved_chunks": [{"chunk_id": 5996, "source": "domains/postgresql_docs/data/indices.sgml", "text_preview": "In production environments this is often unacceptable.\n   It is possible to allow writes to occur in parallel with index\n   creation, but there are several caveats to be aware of &mdash;\n   for more information see <xref linkend=\"sql-createindex-concurrently\"/>.\n  </para>\n\n  <para>\n   After an index is created, the system has to keep it synchronized with the\n   table.  This adds overhead to data manipulation operations.  Indexes can\n   also prevent the creation of <link linkend=\"storage-hot\">heap-only\n   tuples</link>.\n   Therefore indexes that are seldom or never used in queries\n   should be removed.\n  </para>\n </sect1>\n\n\n <sect1 id=\"indexes-types\">\n  <title>Index Types</title>\n\n  <para>\n   <productname>PostgreSQL</productname> provides several index types:\n   B-tree, Hash, GiST, SP-GiST, GIN, BRIN, and the extension <link\n   linkend=\"bloom\">bloom</link>.\n   Each index type uses a di", "score": 0.6706646084785461}, {"chunk_id": 5993, "source": "domains/postgresql_docs/data/indices.sgml", "text_preview": "nd=\"performance-tips\"/> for information about\n   how to find out whether an index is used and when and why the\n   planner might choose <emphasis>not</emphasis> to use an index.\n  </para>\n\n  <para>\n   Indexes can also benefit <command>UPDATE</command> and\n   <command>DELETE</command> commands with search conditions.\n   Indexes can moreover be used in join searches.  Thus,\n   an index defined on a column that is part of a join condition can\n   also significantly speed up queries with joins.\n  </para>\n\n  <para>\n   In general, <productname>PostgreSQL</productname> indexes can be used\n   to optimize queries that contain one or more <literal>WHERE</literal>\n   or <literal>JOIN</literal> clauses of the form\n\n<synopsis>\n<replaceable>indexed-column</replaceable> <replaceable>indexable-operator</replaceable> <replaceable>comparison-value</replaceable>\n</synopsis>\n\n   Here, the <replaceable>indexed", "score": 0.6317334175109863}, {"chunk_id": 11221, "source": "domains/postgresql_docs/data/ref/create_index.sgml", "text_preview": "an index's usefulness.\n   For new expression indexes, it is necessary to run <link\n   linkend=\"sql-analyze\"><command>ANALYZE</command></link> or wait for\n   the <link linkend=\"autovacuum\">autovacuum daemon</link> to analyze\n   the table to generate statistics for these indexes.\n  </para>\n\n  <para>\n   While <command>CREATE INDEX</command> is running, the <xref\n   linkend=\"guc-search-path\"/> is temporarily changed to <literal>pg_catalog,\n   pg_temp</literal>.\n  </para>\n\n  <para>\n   For most index methods, the speed of creating an index is\n   dependent on the setting of <xref linkend=\"guc-maintenance-work-mem\"/>.\n   Larger values will reduce the time needed for index creation, so long\n   as you don't make it larger than the amount of memory really available,\n   which would drive the machine into swapping.\n  </para>\n\n  <para>\n   <productname>PostgreSQL</productname> can build indexes while", "score": 0.6033602356910706}, {"chunk_id": 11178, "source": "domains/postgresql_docs/data/ref/create_index.sgml", "text_preview": "<!--\ndoc/src/sgml/ref/create_index.sgml\nPostgreSQL documentation\n-->\n\n<refentry id=\"sql-createindex\">\n <indexterm zone=\"sql-createindex\">\n  <primary>CREATE INDEX</primary>\n </indexterm>\n\n <refmeta>\n  <refentrytitle>CREATE INDEX</refentrytitle>\n  <manvolnum>7</manvolnum>\n  <refmiscinfo>SQL - Language Statements</refmiscinfo>\n </refmeta>\n\n <refnamediv>\n  <refname>CREATE INDEX</refname>\n  <refpurpose>define a new index</refpurpose>\n </refnamediv>\n\n <refsynopsisdiv>\n<synopsis>\nCREATE [ UNIQUE ] INDEX [ CONCURRENTLY ] [ [ IF NOT EXISTS ] <replaceable class=\"parameter\">name</replaceable> ] ON [ ONLY ] <replaceable class=\"parameter\">table_name</replaceable> [ USING <replaceable class=\"parameter\">method</replaceable> ]\n    ( { <replaceable class=\"parameter\">column_name</replaceable> | ( <replaceable class=\"parameter\">expression</replaceable> ) } [ COLLATE <replaceable class=\"parameter\">collation", "score": 0.5934208631515503}, {"chunk_id": 11181, "source": "domains/postgresql_docs/data/ref/create_index.sgml", "text_preview": "of\n   one or more columns of the table row.  This feature can be used\n   to obtain fast access to data based on some transformation of\n   the basic data. For example, an index computed on\n   <literal>upper(col)</literal> would allow the clause\n   <literal>WHERE upper(col) = 'JIM'</literal> to use an index.\n  </para>\n\n  <para>\n   <productname>PostgreSQL</productname> provides the index methods\n   B-tree, hash, GiST, SP-GiST, GIN, and BRIN.  Users can also define their own\n   index methods, but that is fairly complicated.\n  </para>\n\n  <para>\n    When the <literal>WHERE</literal> clause is present, a\n    <firstterm>partial index</firstterm> is created.\n    A partial index is an index that contains entries for only a portion of\n    a table, usually a portion that is more useful for indexing than the\n    rest of the table. For example, if you have a table that contains both\n    billed and un", "score": 0.5660547614097595}, {"chunk_id": 6048, "source": "domains/postgresql_docs/data/indices.sgml", "text_preview": "an index might be profitable.  Forming this knowledge\n   requires experience and understanding of how indexes in\n   <productname>PostgreSQL</productname> work.  In most cases, the\n   advantage of a partial index over a regular index will be minimal.\n   There are cases where they are quite counterproductive, as in <xref\n   linkend=\"indexes-partial-ex4\"/>.\n  </para>\n\n  <example id=\"indexes-partial-ex4\">\n   <title>Do Not Use Partial Indexes as a Substitute for Partitioning</title>\n\n   <para>\n    You might be tempted to create a large set of non-overlapping partial\n    indexes, for example\n\n<programlisting>\nCREATE INDEX mytable_cat_1 ON mytable (data) WHERE category = 1;\nCREATE INDEX mytable_cat_2 ON mytable (data) WHERE category = 2;\nCREATE INDEX mytable_cat_3 ON mytable (data) WHERE category = 3;\n...\nCREATE INDEX mytable_cat_<replaceable>N</replaceable> ON mytable (data) WHERE category = <", "score": 0.5651172399520874}], "flags": {}, "error": null}}, "evaluations": {"prompt": {"quality_score": 0.35, "penalty_total": 0.65, "rule_breakdown": [{"rule": "overconfident_language_check", "penalty": 0.15, "hallucination_flags": ["OVERCONFIDENT_LANGUAGE"], "grounding_flags": [], "note": "Overconfident language detected."}, {"rule": "prompt_docs_evidence_check", "penalty": 0.5, "hallucination_flags": [], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "note": "Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": ["OVERCONFIDENT_LANGUAGE"], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "notes": "Overconfident language detected. Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}, "rag": {"quality_score": 0.85, "penalty_total": 0.15, "rule_breakdown": [{"rule": "overconfident_language_check", "penalty": 0.15, "hallucination_flags": ["OVERCONFIDENT_LANGUAGE"], "grounding_flags": [], "note": "Overconfident language detected."}], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": ["OVERCONFIDENT_LANGUAGE"], "grounding_flags": [], "notes": "Overconfident language detected."}}, "summary_metrics": {"winner_by_quality": "rag", "winner_by_latency": "prompt", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": null, "winner_by_expect_ties": ["prompt", "rag"]}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251230T011239Z:006:explain_analyze", "timestamp": "2025-12-30T01:13:20.358992Z", "domain": "postgresql_docs", "mode": "docs", "query": "How do I use EXPLAIN (ANALYZE) to understand query performance?", "case": {"id": "explain_analyze", "tags": ["performance"], "answerable_from_general_knowledge": false, "requires_docs": true, "expected_abstain_in_docs": null}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "To use `EXPLAIN (ANALYZE)` in PostgreSQL to understand query performance, you can follow these steps:\n\n1. **Basic Usage**: You can prepend your SQL query with `EXPLAIN (ANALYZE, BUFFERS)` to get a detailed execution plan along with actual run-time statistics. For example:\n   ```sql\n   EXPLAIN (ANALYZE, BUFFERS) SELECT * FROM your_table WHERE your_condition;\n   ```\n\n2. **Understanding the Output**: The output will provide you with several pieces of information:\n   - **Execution Time**: The total time taken to execute the query.\n   - **Planning Time**: The time taken to plan the query.\n   - **Node Types**: Information about the different operations performed (e.g., Seq Scan, Index Scan, Join types).\n   - **Rows**: The estimated and actual number of rows processed at each step.\n   - **Buffers**: Information about buffer usage, which can help you understand how much data was read from disk versus memory.\n\n3. **Analyzing the Plan**: Look for:\n   - **Cost Estimates**: The planner's estimates of the cost of executing the query, which can help identify potential inefficiencies.\n   - **Actual Rows vs. Estimated Rows**: Discrepancies here can indicate issues with statistics or query design.\n   - **Execution Order**: The order in which operations are performed can impact performance.\n\n4. **Identifying Bottlenecks**: Focus on the parts of the plan that take the most time or have the highest cost. This can help you identify where optimizations may be needed.\n\n5. **Iterate**: After making changes to your query or database (like adding indexes), you can run `EXPLAIN (ANALYZE)` again to see how those changes affected performance.\n\nFor more detailed information, you can refer to the official PostgreSQL documentation on `EXPLAIN` and query performance analysis.", "latency_ms": 8893, "tokens_in": 152, "tokens_out": 409, "cost_estimate_usd": 0.0002682, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "To use `EXPLAIN (ANALYZE)` for understanding query performance, you can execute the command followed by your SQL query. This option not only shows the estimated execution plan but also executes the query, providing actual runtime statistics and row counts for each plan node. For example, the output will include true row counts and actual run times accumulated within each plan node, alongside the estimates that a plain `EXPLAIN` would show [8583].\n\nThe structure of the output from `EXPLAIN` is a tree of plan nodes, where the bottom-level nodes are scan nodes that return raw rows from a table. If your query involves operations like joining, aggregation, or sorting, there will be additional nodes above the scan nodes to perform these operations. Understanding the types of nodes and their costs can help you identify potential performance issues in your query [8545][8544]. \n\nAdditionally, the output can be formatted in different ways, such as text, XML, JSON, or YAML, which can be useful for further analysis or integration with other tools [8544][12228].", "latency_ms": 6468, "tokens_in": 1703, "tokens_out": 220, "cost_estimate_usd": 0.00038745, "retrieved_chunks": [{"chunk_id": 8583, "source": "domains/postgresql_docs/data/perform.sgml", "text_preview": "command>'s <literal>ANALYZE</literal> option.  With this\n    option, <command>EXPLAIN</command> actually executes the query, and then displays\n    the true row counts and true run time accumulated within each plan node,\n    along with the same estimates that a plain <command>EXPLAIN</command>\n    shows.  For example, we might get a result like this:\n\n<screen>\nEXPLAIN ANALYZE SELECT *\nFROM tenk1 t1, tenk2 t2\nWHERE t1.unique1 &lt; 10 AND t1.unique2 = t2.unique2;\n\n                                                           QUERY PLAN\n-------------------------------------------------------------------&zwsp;--------------------------------------------------------------\n Nested Loop  (cost=4.65..118.50 rows=10 width=488) (actual time=0.017..0.051 rows=10.00 loops=1)\n   Buffers: shared hit=36 read=6\n   -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=4.36..39.38 rows=10 width=244) (actual time=0.009..", "score": 0.6470310688018799}, {"chunk_id": 8545, "source": "domains/postgresql_docs/data/perform.sgml", "text_preview": "ct2 id=\"using-explain-basics\">\n   <title><command>EXPLAIN</command> Basics</title>\n\n   <para>\n    The structure of a query plan is a tree of <firstterm>plan nodes</firstterm>.\n    Nodes at the bottom level of the tree are scan nodes: they return raw rows\n    from a table.  There are different types of scan nodes for different\n    table access methods: sequential scans, index scans, and bitmap index\n    scans.  There are also non-table row sources, such as <literal>VALUES</literal>\n    clauses and set-returning functions in <literal>FROM</literal>, which have their\n    own scan node types.\n    If the query requires joining, aggregation, sorting, or other\n    operations on the raw rows, then there will be additional nodes\n    above the scan nodes to perform these operations.  Again,\n    there is usually more than one possible way to do these operations,\n    so different node types can appe", "score": 0.620867908000946}, {"chunk_id": 8544, "source": "domains/postgresql_docs/data/perform.sgml", "text_preview": "ng a <command>VACUUM ANALYZE</command>, using v18 development sources.\n    You should be able to get similar results if you try the examples\n    yourself, but your estimated costs and row counts might vary slightly\n    because <command>ANALYZE</command>'s statistics are random samples rather\n    than exact, and because costs are inherently somewhat platform-dependent.\n   </para>\n\n   <para>\n    The examples use <command>EXPLAIN</command>'s default <quote>text</quote> output\n    format, which is compact and convenient for humans to read.\n    If you want to feed <command>EXPLAIN</command>'s output to a program for further\n    analysis, you should use one of its machine-readable output formats\n    (XML, JSON, or YAML) instead.\n   </para>\n\n  <sect2 id=\"using-explain-basics\">\n   <title><command>EXPLAIN</command> Basics</title>\n\n   <para>\n    The structure of a query plan is a tree of <firstter", "score": 0.6203202605247498}, {"chunk_id": 8542, "source": "domains/postgresql_docs/data/perform.sgml", "text_preview": "<!-- doc/src/sgml/perform.sgml -->\n\n <chapter id=\"performance-tips\">\n  <title>Performance Tips</title>\n\n  <indexterm zone=\"performance-tips\">\n   <primary>performance</primary>\n  </indexterm>\n\n  <para>\n   Query performance can be affected by many things. Some of these can\n   be controlled by the user, while others are fundamental to the underlying\n   design of the system.  This chapter provides some hints about understanding\n   and tuning <productname>PostgreSQL</productname> performance.\n  </para>\n\n <sect1 id=\"using-explain\">\n  <title>Using <command>EXPLAIN</command></title>\n\n   <indexterm zone=\"using-explain\">\n    <primary>EXPLAIN</primary>\n   </indexterm>\n\n   <indexterm zone=\"using-explain\">\n    <primary>query plan</primary>\n   </indexterm>\n\n   <para>\n    <productname>PostgreSQL</productname> devises a <firstterm>query\n    plan</firstterm> for each query it receives.  Choosing the righ", "score": 0.6131755113601685}, {"chunk_id": 12206, "source": "domains/postgresql_docs/data/ref/explain.sgml", "text_preview": "<!--\ndoc/src/sgml/ref/explain.sgml\nPostgreSQL documentation\n-->\n\n<refentry id=\"sql-explain\">\n <indexterm zone=\"sql-explain\">\n  <primary>EXPLAIN</primary>\n </indexterm>\n\n <indexterm zone=\"sql-explain\">\n  <primary>prepared statements</primary>\n  <secondary>showing the query plan</secondary>\n </indexterm>\n\n <indexterm zone=\"sql-explain\">\n  <primary>cursor</primary>\n  <secondary>showing the query plan</secondary>\n </indexterm>\n\n <refmeta>\n  <refentrytitle>EXPLAIN</refentrytitle>\n  <manvolnum>7</manvolnum>\n  <refmiscinfo>SQL - Language Statements</refmiscinfo>\n </refmeta>\n\n <refnamediv>\n  <refname>EXPLAIN</refname>\n  <refpurpose>show the execution plan of a statement</refpurpose>\n </refnamediv>\n\n <refsynopsisdiv>\n<synopsis>\nEXPLAIN [ ( <replaceable class=\"parameter\">option</replaceable> [, ...] ) ] <replaceable class=\"parameter\">statement</replaceable>\n\n<phrase>where <replaceable class=\"param", "score": 0.5845823287963867}, {"chunk_id": 12228, "source": "domains/postgresql_docs/data/ref/explain.sgml", "text_preview": "condition, <command>EXPLAIN</command>\n   might show a different plan:\n\n<programlisting>\nEXPLAIN SELECT * FROM foo WHERE i = 4;\n\n                         QUERY PLAN\n--------------------------------------------------------------\n Index Scan using fi on foo  (cost=0.00..5.98 rows=1 width=4)\n   Index Cond: (i = 4)\n(2 rows)\n</programlisting>\n  </para>\n\n  <para>\n  Here is the same query, but in YAML format:\n<programlisting>\nEXPLAIN (FORMAT YAML) SELECT * FROM foo WHERE i='4';\n          QUERY PLAN\n-------------------------------\n - Plan:                      +\n     Node Type: \"Index Scan\"  +\n     Scan Direction: \"Forward\"+\n     Index Name: \"fi\"         +\n     Relation Name: \"foo\"     +\n     Alias: \"foo\"             +\n     Startup Cost: 0.00       +\n     Total Cost: 5.98         +\n     Plan Rows: 1             +\n     Plan Width: 4            +\n     Index Cond: \"(i = 4)\"\n(1 row)\n</programlisting", "score": 0.5782442092895508}], "flags": {}, "error": null}}, "evaluations": {"prompt": {"quality_score": 0.5, "penalty_total": 0.5, "rule_breakdown": [{"rule": "prompt_docs_evidence_check", "penalty": 0.5, "hallucination_flags": [], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "note": "Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "notes": "Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}, "rag": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}}, "summary_metrics": {"winner_by_quality": "rag", "winner_by_latency": "rag", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": null, "winner_by_expect_ties": ["prompt", "rag"]}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251230T011239Z:007:vacuum_basics", "timestamp": "2025-12-30T01:13:28.877879Z", "domain": "postgresql_docs", "mode": "docs", "query": "What does VACUUM do in PostgreSQL?", "case": {"id": "vacuum_basics", "tags": ["maintenance"], "answerable_from_general_knowledge": false, "requires_docs": true, "expected_abstain_in_docs": null}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "In PostgreSQL, the `VACUUM` command is used to reclaim storage occupied by dead tuples. When rows are updated or deleted, the old versions of those rows remain in the database until they are removed by the `VACUUM` process. This helps to prevent issues related to transaction visibility and ensures that the database can efficiently manage its storage.\n\nThe primary functions of `VACUUM` are:\n\n1. **Reclaiming Space**: It removes dead tuples from tables and indexes, thereby freeing up space that can be reused for future inserts and updates.\n\n2. **Preventing Transaction ID Wraparound**: PostgreSQL uses a transaction ID system to manage visibility of rows. Over time, if old tuples are not cleaned up, the transaction ID can wrap around, which can lead to data corruption. Regularly running `VACUUM` helps to mitigate this risk.\n\n3. **Updating Statistics**: While `VACUUM` itself does not update statistics, it can be followed by the `ANALYZE` command to update the statistics used by the query planner.\n\nThere are two types of `VACUUM`:\n\n- **Standard VACUUM**: This reclaims space and marks it as available for reuse but does not return it to the operating system.\n- **VACUUM FULL**: This is a more aggressive form that compacts the table and returns space to the operating system, but it requires an exclusive lock on the table, making it more disruptive.\n\nIn summary, `VACUUM` is essential for maintaining the health and performance of a PostgreSQL database by managing dead tuples and preventing transaction ID issues.", "latency_ms": 8511, "tokens_in": 144, "tokens_out": 332, "cost_estimate_usd": 0.0002208, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "The VACUUM command in PostgreSQL is used to garbage-collect and optionally analyze a database. It processes each table to recover or reuse disk space occupied by updated or deleted rows, and it can also analyze the database to update statistics for the query planner [14041][7793]. Additionally, VACUUM can complete any pending index insertions for tables with GIN indexes [14067]. Regular vacuuming is recommended to maintain database performance [14067].", "latency_ms": 2774, "tokens_in": 1760, "tokens_out": 93, "cost_estimate_usd": 0.0003198, "retrieved_chunks": [{"chunk_id": 14041, "source": "domains/postgresql_docs/data/ref/vacuum.sgml", "text_preview": "<!--\ndoc/src/sgml/ref/vacuum.sgml\nPostgreSQL documentation\n-->\n\n<refentry id=\"sql-vacuum\">\n <indexterm zone=\"sql-vacuum\">\n  <primary>VACUUM</primary>\n </indexterm>\n\n <refmeta>\n  <refentrytitle>VACUUM</refentrytitle>\n  <manvolnum>7</manvolnum>\n  <refmiscinfo>SQL - Language Statements</refmiscinfo>\n </refmeta>\n\n <refnamediv>\n  <refname>VACUUM</refname>\n  <refpurpose>garbage-collect and optionally analyze a database</refpurpose>\n </refnamediv>\n\n <refsynopsisdiv>\n<synopsis>\nVACUUM [ ( <replaceable class=\"parameter\">option</replaceable> [, ...] ) ] [ <replaceable class=\"parameter\">table_and_columns</replaceable> [, ...] ]\n\n<phrase>where <replaceable class=\"parameter\">option</replaceable> can be one of:</phrase>\n\n    FULL [ <replaceable class=\"parameter\">boolean</replaceable> ]\n    FREEZE [ <replaceable class=\"parameter\">boolean</replaceable> ]\n    VERBOSE [ <replaceable class=\"parameter\">bool", "score": 0.6652218699455261}, {"chunk_id": 14067, "source": "domains/postgresql_docs/data/ref/vacuum.sgml", "text_preview": "UM</command> is running, the <xref\n    linkend=\"guc-search-path\"/> is temporarily changed to <literal>pg_catalog,\n    pg_temp</literal>.\n   </para>\n\n   <para>\n    <command>VACUUM</command> cannot be executed inside a transaction block.\n   </para>\n\n   <para>\n    For tables with <acronym>GIN</acronym> indexes, <command>VACUUM</command> (in\n    any form) also completes any pending index insertions, by moving pending\n    index entries to the appropriate places in the main <acronym>GIN</acronym> index\n    structure.  See <xref linkend=\"gin-fast-update\"/> for details.\n   </para>\n\n   <para>\n    We recommend that all databases be vacuumed regularly in\n    order to remove dead rows.  <productname>PostgreSQL</productname> includes\n    an <quote>autovacuum</quote> facility which can automate routine vacuum\n    maintenance.  For more information about automatic and manual vacuuming,\n    see <xref li", "score": 0.6505534648895264}, {"chunk_id": 7793, "source": "domains/postgresql_docs/data/maintenance.sgml", "text_preview": "to\n   supplement or replace the daemon's activities with manually-managed\n   <command>VACUUM</command> commands, which typically are executed according to a\n   schedule by <application>cron</application> or <application>Task\n   Scheduler</application> scripts.  To set up manually-managed vacuuming properly,\n   it is essential to understand the issues discussed in the next few\n   subsections.  Administrators who rely on autovacuuming may still wish\n   to skim this material to help them understand and adjust autovacuuming.\n  </para>\n\n  <sect2 id=\"vacuum-basics\">\n   <title>Vacuuming Basics</title>\n\n   <para>\n    <productname>PostgreSQL</productname>'s\n    <link linkend=\"sql-vacuum\"><command>VACUUM</command></link> command has to\n    process each table on a regular basis for several reasons:\n\n    <orderedlist>\n     <listitem>\n      <simpara>To recover or reuse disk space occupied by updated", "score": 0.6440844535827637}, {"chunk_id": 14072, "source": "domains/postgresql_docs/data/ref/vacuumdb.sgml", "text_preview": "<!--\ndoc/src/sgml/ref/vacuumdb.sgml\nPostgreSQL documentation\n-->\n\n<refentry id=\"app-vacuumdb\">\n <indexterm zone=\"app-vacuumdb\">\n  <primary>vacuumdb</primary>\n </indexterm>\n\n <refmeta>\n  <refentrytitle><application>vacuumdb</application></refentrytitle>\n  <manvolnum>1</manvolnum>\n  <refmiscinfo>Application</refmiscinfo>\n </refmeta>\n\n <refnamediv>\n  <refname>vacuumdb</refname>\n  <refpurpose>garbage-collect and analyze a <productname>PostgreSQL</productname> database</refpurpose>\n </refnamediv>\n\n <refsynopsisdiv>\n  <cmdsynopsis>\n   <command>vacuumdb</command>\n   <arg rep=\"repeat\"><replaceable>connection-option</replaceable></arg>\n   <arg rep=\"repeat\"><replaceable>option</replaceable></arg>\n\n   <arg choice=\"plain\" rep=\"repeat\">\n    <arg choice=\"opt\">\n     <group choice=\"plain\">\n      <arg choice=\"plain\"><option>-t</option></arg>\n      <arg choice=\"plain\"><option>--table</option></arg>\n     <", "score": 0.6368962526321411}, {"chunk_id": 14070, "source": "domains/postgresql_docs/data/ref/vacuum.sgml", "text_preview": "command>VACUUM FULL</command> will instead report their progress in the\n    <structname>pg_stat_progress_cluster</structname> view. See\n    <xref linkend=\"vacuum-progress-reporting\"/> and\n    <xref linkend=\"cluster-progress-reporting\"/> for details.\n   </para>\n </refsect1>\n\n <refsect1>\n  <title>Examples</title>\n\n  <para>\n   To clean a single table <structname>onek</structname>, analyze it for\n   the optimizer and print a detailed vacuum activity report:\n\n<programlisting>\nVACUUM (VERBOSE, ANALYZE) onek;\n</programlisting></para>\n </refsect1>\n\n <refsect1>\n  <title>Compatibility</title>\n\n  <para>\n   There is no <command>VACUUM</command> statement in the SQL standard.\n  </para>\n\n  <para>\n   The following syntax was used before <productname>PostgreSQL</productname>\n   version 9.0 and is still supported:\n<synopsis>\nVACUUM [ FULL ] [ FREEZE ] [ VERBOSE ] [ ANALYZE ] [ <replaceable class=\"paramet", "score": 0.6348817348480225}, {"chunk_id": 7838, "source": "domains/postgresql_docs/data/maintenance.sgml", "text_preview": "arlier versions, it was sometimes necessary to stop the postmaster and\n     <command>VACUUM</command> the database in a single-user mode. In typical scenarios, this\n     is no longer necessary, and should be avoided whenever possible, since it involves taking\n     the system down. It is also riskier, since it disables transaction ID wraparound safeguards\n     that are designed to prevent data loss.  The only reason to use single-user mode in this\n     scenario is if you wish to <command>TRUNCATE</command> or <command>DROP</command> unneeded\n     tables to avoid needing to <command>VACUUM</command> them.  The three-million-transaction\n     safety margin exists to let the administrator do this. See the\n     <xref linkend=\"app-postgres\"/> reference page for details about using single-user mode.\n    </para>\n   </note>\n\n   <sect3 id=\"vacuum-for-multixact-wraparound\">\n    <title>Multixacts and", "score": 0.613677978515625}], "flags": {}, "error": null}}, "evaluations": {"prompt": {"quality_score": 0.5, "penalty_total": 0.5, "rule_breakdown": [{"rule": "prompt_docs_evidence_check", "penalty": 0.5, "hallucination_flags": [], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "note": "Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "notes": "Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}, "rag": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}}, "summary_metrics": {"winner_by_quality": "rag", "winner_by_latency": "rag", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": null, "winner_by_expect_ties": ["prompt", "rag"]}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251230T011239Z:008:jsonb_basics", "timestamp": "2025-12-30T01:13:38.598037Z", "domain": "postgresql_docs", "mode": "docs", "query": "What is JSONB in PostgreSQL and how is it different from JSON?", "case": {"id": "jsonb_basics", "tags": ["json"], "answerable_from_general_knowledge": true, "requires_docs": false, "expected_abstain_in_docs": null}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "In PostgreSQL, `JSONB` is a binary format for storing JSON (JavaScript Object Notation) data. It is one of the two data types provided by PostgreSQL for handling JSON data, the other being `JSON`.\n\nHere are the key differences between `JSON` and `JSONB` as outlined in the official PostgreSQL documentation:\n\n1. **Storage Format**:\n   - `JSON` stores the data as plain text, which means it retains the exact text representation of the JSON input.\n   - `JSONB`, on the other hand, stores the data in a binary format, which allows for more efficient processing and storage.\n\n2. **Performance**:\n   - `JSONB` is generally faster for querying and indexing because it is stored in a format that is optimized for these operations.\n   - `JSON` may be slower for certain operations since it requires parsing the text representation.\n\n3. **Functionality**:\n   - `JSONB` supports indexing, which allows for faster searches and queries on JSON data. You can create GIN (Generalized Inverted Index) indexes on `JSONB` columns.\n   - `JSON` does not support indexing in the same way, which can lead to slower performance for large datasets.\n\n4. **Data Manipulation**:\n   - `JSONB` allows for more advanced operations and functions, such as the ability to use the `@>` operator to check for containment, and it supports various functions that can manipulate JSON data more effectively.\n   - `JSON` has a more limited set of functions available for manipulation.\n\n5. **Duplication of Keys**:\n   - In `JSON`, duplicate keys are allowed, and the last key-value pair will be retained.\n   - In `JSONB`, duplicate keys are not allowed; if a duplicate key is encountered, it will overwrite the previous key-value pair.\n\nIn summary, `JSONB` is a more efficient and feature-rich option for storing and manipulating JSON data in PostgreSQL compared to the `JSON` type.", "latency_ms": 9699, "tokens_in": 149, "tokens_out": 411, "cost_estimate_usd": 0.00026894999999999995, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "In PostgreSQL, JSONB is a data type for storing JSON data in a decomposed binary format. It is designed for efficient processing and allows for indexing, which can provide significant performance advantages. The key differences between JSONB and the JSON data type are as follows:\n\n1. **Storage Format**: JSONB stores data in a binary format, while JSON stores an exact copy of the input text. This means that JSONB does not require reparsing during processing, making it faster to work with once the data is stored [6747][6752].\n\n2. **Whitespace and Key Order**: JSONB does not preserve semantically insignificant whitespace or the order of keys within JSON objects. In contrast, JSON retains the original formatting, including whitespace and the order of keys, and keeps duplicate keys, with the last value being operative [6748].\n\n3. **Input Constraints**: JSONB has additional constraints on valid input data compared to JSON. For example, JSONB will reject numbers that are outside the range of PostgreSQL's numeric data type, while JSON does not impose such restrictions [6753].\n\nOverall, JSONB is optimized for performance and efficiency in processing, while JSON is more flexible in terms of data representation.", "latency_ms": 5097, "tokens_in": 1652, "tokens_out": 247, "cost_estimate_usd": 0.000396, "retrieved_chunks": [{"chunk_id": 6747, "source": "domains/postgresql_docs/data/json.sgml", "text_preview": "s-json\"/>.\n </para>\n\n <para>\n  <productname>PostgreSQL</productname> offers two types for storing JSON\n  data: <type>json</type> and <type>jsonb</type>. To implement efficient query\n  mechanisms for these data types, <productname>PostgreSQL</productname>\n  also provides the <type>jsonpath</type> data type described in\n  <xref linkend=\"datatype-jsonpath\"/>.\n </para>\n\n <para>\n  The <type>json</type> and <type>jsonb</type> data types\n  accept <emphasis>almost</emphasis> identical sets of values as\n  input.  The major practical difference is one of efficiency.  The\n  <type>json</type> data type stores an exact copy of the input text,\n  which processing functions must reparse on each execution; while\n  <type>jsonb</type> data is stored in a decomposed binary format that\n  makes it slightly slower to input due to added conversion\n  overhead, but significantly faster to process, since no repars", "score": 0.6784816384315491}, {"chunk_id": 6752, "source": "domains/postgresql_docs/data/json.sgml", "text_preview": "y be considered a historical artifact, although\n   it does allow for simple storage (without processing) of JSON Unicode\n   escapes in a database encoding that does not support the represented\n   characters.\n  </para>\n </note>\n\n <para>\n  When converting textual JSON input into <type>jsonb</type>, the primitive\n  types described by <acronym>RFC</acronym> 7159 are effectively mapped onto\n  native <productname>PostgreSQL</productname> types, as shown\n  in <xref linkend=\"json-type-mapping-table\"/>.\n  Therefore, there are some minor additional constraints on what\n  constitutes valid <type>jsonb</type> data that do not apply to\n  the <type>json</type> type, nor to JSON in the abstract, corresponding\n  to limits on what can be represented by the underlying data type.\n  Notably, <type>jsonb</type> will reject numbers that are outside the\n  range of the <productname>PostgreSQL</productname> <type", "score": 0.6530764102935791}, {"chunk_id": 6746, "source": "domains/postgresql_docs/data/json.sgml", "text_preview": "<!-- doc/src/sgml/json.sgml -->\n\n<sect1 id=\"datatype-json\">\n <title><acronym>JSON</acronym> Types</title>\n\n <indexterm zone=\"datatype-json\">\n  <primary>JSON</primary>\n </indexterm>\n\n <indexterm zone=\"datatype-json\">\n  <primary>JSONB</primary>\n </indexterm>\n\n <para>\n  JSON data types are for storing JSON (JavaScript Object Notation)\n  data, as specified in <ulink url=\"https://datatracker.ietf.org/doc/html/rfc7159\">RFC\n  7159</ulink>. Such data can also be stored as <type>text</type>, but\n  the JSON data types have the advantage of enforcing that each\n  stored value is valid according to the JSON rules.  There are also\n  assorted JSON-specific functions and operators available for data stored\n  in these data types; see <xref linkend=\"functions-json\"/>.\n </para>\n\n <para>\n  <productname>PostgreSQL</productname> offers two types for storing JSON\n  data: <type>json</type> and <type>jsonb</type", "score": 0.6248601675033569}, {"chunk_id": 6748, "source": "domains/postgresql_docs/data/json.sgml", "text_preview": "mposed binary format that\n  makes it slightly slower to input due to added conversion\n  overhead, but significantly faster to process, since no reparsing\n  is needed.  <type>jsonb</type> also supports indexing, which can be a\n  significant advantage.\n </para>\n\n <para>\n  Because the <type>json</type> type stores an exact copy of the input text, it\n  will preserve semantically-insignificant white space between tokens, as\n  well as the order of keys within JSON objects. Also, if a JSON object\n  within the value contains the same key more than once, all the key/value\n  pairs are kept.  (The processing functions consider the last value as the\n  operative one.)  By contrast, <type>jsonb</type> does not preserve white\n  space, does not preserve the order of object keys, and does not keep\n  duplicate object keys.  If duplicate keys are specified in the input,\n  only the last value is kept.\n </pa", "score": 0.6095768213272095}, {"chunk_id": 6759, "source": "domains/postgresql_docs/data/json.sgml", "text_preview": "jsonb\n-----------------------+-------------------------\n {\"reading\": 1.230e-5} | {\"reading\": 0.00001230}\n(1 row)\n</programlisting>\n   However, <type>jsonb</type> will preserve trailing fractional zeroes, as seen\n   in this example, even though those are semantically insignificant for\n   purposes such as equality checks.\n  </para>\n\n  <para>\n    For the list of built-in functions and operators available for\n    constructing and processing JSON values, see <xref linkend=\"functions-json\"/>.\n  </para>\n </sect2>\n\n <sect2 id=\"json-doc-design\">\n  <title>Designing JSON Documents</title>\n  <para>\n   Representing data as JSON can be considerably more flexible than\n   the traditional relational data model, which is compelling in\n   environments where requirements are fluid.  It is quite possible\n   for both approaches to co-exist and complement each other within\n   the same application.  Howe", "score": 0.6078782081604004}, {"chunk_id": 6753, "source": "domains/postgresql_docs/data/json.sgml", "text_preview": "nderlying data type.\n  Notably, <type>jsonb</type> will reject numbers that are outside the\n  range of the <productname>PostgreSQL</productname> <type>numeric</type> data\n  type, while <type>json</type> will not.  Such implementation-defined\n  restrictions are permitted by <acronym>RFC</acronym> 7159.  However, in\n  practice such problems are far more likely to occur in other\n  implementations, as it is common to represent JSON's <type>number</type>\n  primitive type as IEEE 754 double precision floating point\n  (which <acronym>RFC</acronym> 7159 explicitly anticipates and allows for).\n  When using JSON as an interchange format with such systems, the danger\n  of losing numeric precision compared to data originally stored\n  by <productname>PostgreSQL</productname> should be considered.\n </para>\n\n <para>\n  Conversely, as noted in the table there are some minor restrictions on\n  the input fo", "score": 0.6052228212356567}], "flags": {}, "error": null}}, "evaluations": {"prompt": {"quality_score": 0.5, "penalty_total": 0.5, "rule_breakdown": [{"rule": "prompt_docs_evidence_check", "penalty": 0.5, "hallucination_flags": [], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "note": "Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "notes": "Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}, "rag": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}}, "summary_metrics": {"winner_by_quality": "rag", "winner_by_latency": "rag", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": null, "winner_by_expect_ties": ["prompt", "rag"]}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251230T011239Z:009:psql_connect", "timestamp": "2025-12-30T01:13:42.785561Z", "domain": "postgresql_docs", "mode": "docs", "query": "How do I connect to a PostgreSQL database using psql? Give a minimal example.", "case": {"id": "psql_connect", "tags": ["psql"], "answerable_from_general_knowledge": false, "requires_docs": true, "expected_abstain_in_docs": null}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "To connect to a PostgreSQL database using `psql`, you can use the following command in your terminal:\n\n```bash\npsql -h hostname -U username -d database_name\n```\n\nHere\u2019s a minimal example:\n\n```bash\npsql -h localhost -U postgres -d mydatabase\n```\n\nIn this example:\n- `-h localhost` specifies the host where the database server is running (in this case, it's on the local machine).\n- `-U postgres` specifies the username to connect as (in this case, the default PostgreSQL user).\n- `-d mydatabase` specifies the name of the database you want to connect to.\n\nYou will be prompted to enter the password for the specified user after running the command. If you are connecting to a database on the same machine and using the default user, you can also simply run `psql mydatabase` if you are logged in as the same user that owns the database.", "latency_ms": 4180, "tokens_in": 152, "tokens_out": 195, "cost_estimate_usd": 0.0001398, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "To connect to a PostgreSQL database using `psql`, you can use the command line with the `-d` option to specify the database name. A minimal example would be:\n\n```bash\npsql -d your_database_name\n```\n\nIf you omit the host name, `psql` will connect via a Unix-domain socket to a server on the local host, or via TCP/IP to `localhost` on Windows, using the default port [13373].", "latency_ms": 3586, "tokens_in": 1591, "tokens_out": 95, "cost_estimate_usd": 0.00029564999999999995, "retrieved_chunks": [{"chunk_id": 3307, "source": "domains/postgresql_docs/data/ecpg.sgml", "text_preview": "CONNECT TO connectdb AS :id;\nEXEC SQL CONNECT TO connectdb AS main USER connectuser/connectdb;\nEXEC SQL CONNECT TO connectdb AS main;\nEXEC SQL CONNECT TO connectdb@localhost AS main;\nEXEC SQL CONNECT TO tcp:postgresql://localhost/ USER connectdb;\nEXEC SQL CONNECT TO tcp:postgresql://localhost/connectdb USER connectuser IDENTIFIED BY connectpw;\nEXEC SQL CONNECT TO tcp:postgresql://localhost:20/connectdb USER connectuser IDENTIFIED BY connectpw;\nEXEC SQL CONNECT TO unix:postgresql://localhost/ AS main USER connectdb;\nEXEC SQL CONNECT TO unix:postgresql://localhost/connectdb AS main USER connectuser;\nEXEC SQL CONNECT TO unix:postgresql://localhost/connectdb USER connectuser IDENTIFIED BY \"connectpw\";\nEXEC SQL CONNECT TO unix:postgresql://localhost/connectdb USER connectuser USING \"connectpw\";\nEXEC SQL CONNECT TO unix:postgresql://localhost/connectdb?connect_timeout=14 USER connectuser;\n</p", "score": 0.5892977118492126}, {"chunk_id": 12822, "source": "domains/postgresql_docs/data/ref/pg_dumpall.sgml", "text_preview": "ut>psql -X -f db.out -d postgres</userinput>\n</screen>\n   It is not important which database you connect to here since the\n   script file created by <application>pg_dumpall</application> will\n   contain the appropriate commands to create and connect to the saved\n   databases.  An exception is that if you specified <option>--clean</option>,\n   you must connect to the <literal>postgres</literal> database initially;\n   the script will attempt to drop other databases immediately, and that\n   will fail for the database you are connected to.\n  </para>\n </refsect1>\n\n <refsect1>\n  <title>See Also</title>\n\n  <para>\n    Check <xref linkend=\"app-pgdump\"/> for details on possible\n    error conditions.\n  </para>\n </refsect1>\n\n</refentry>", "score": 0.5817400217056274}, {"chunk_id": 13373, "source": "domains/postgresql_docs/data/ref/psql-ref.sgml", "text_preview": "database user name you want to connect as. <application>psql</application>\n    can be told about those parameters via command line options, namely\n    <option>-d</option>, <option>-h</option>, <option>-p</option>, and\n    <option>-U</option> respectively. If an argument is found that does\n    not belong to any option it will be interpreted as the database name\n    (or the database user name, if the database name is already given). Not all\n    of these options are required; there are useful defaults. If you omit the host\n    name, <application>psql</application> will connect via a Unix-domain socket\n    to a server on the local host, or via TCP/IP to <literal>localhost</literal> on\n    Windows. The default port number is\n    determined at compile time.\n    Since the database server uses the same default, you will not have\n    to specify the port in most cases. The default database user na", "score": 0.56172114610672}, {"chunk_id": 14502, "source": "domains/postgresql_docs/data/runtime.sgml", "text_preview": "nused port.  (IANA\n   reserves ports 49152 through 65535 for private use.)  The name or IP\n   address after this is the remote bind address you are connecting to,\n   i.e., <literal>localhost</literal>, which is the default.  The second\n   number, 5432, is the remote end of the tunnel, e.g., the port number\n   your database server is using.  In order to connect to the database\n   server using this tunnel, you connect to port 63333 on the local\n   machine:\n<programlisting>\npsql -h localhost -p 63333 postgres\n</programlisting>\n   To the database server it will then look as though you are\n   user <literal>joe</literal> on host <literal>foo.com</literal>\n   connecting to the <literal>localhost</literal> bind address, and it\n   will use whatever authentication procedure was configured for\n   connections by that user to that bind address.  Note that the server will not\n   think the connection i", "score": 0.5512736439704895}, {"chunk_id": 14926, "source": "domains/postgresql_docs/data/start.sgml", "text_preview": "le>\n\n   <indexterm zone=\"tutorial-accessdb\">\n    <primary>psql</primary>\n   </indexterm>\n\n   <para>\n    Once you have created a database, you can access it by:\n\n    <itemizedlist spacing=\"compact\" mark=\"bullet\">\n     <listitem>\n      <para>\n       Running the <productname>PostgreSQL</productname> interactive\n       terminal program, called <application><firstterm>psql</firstterm></application>, which allows you\n       to interactively enter, edit, and execute\n       <acronym>SQL</acronym> commands.\n      </para>\n     </listitem>\n\n     <listitem>\n      <para>\n       Using an existing graphical frontend tool like\n       <application>pgAdmin</application> or an office suite with\n       <acronym>ODBC</acronym> or <acronym>JDBC</acronym> support to create and manipulate a\n       database.  These possibilities are not covered in this\n       tutorial.\n      </para>\n     </listitem>\n\n     <listi", "score": 0.537800669670105}, {"chunk_id": 13391, "source": "domains/postgresql_docs/data/ref/psql-ref.sgml", "text_preview": "d\n         query protocol from <application>psql</application>.\n        </para>\n\n       </listitem>\n      </varlistentry>\n\n      <varlistentry id=\"app-psql-meta-command-c-lc\">\n        <term><literal>\\c</literal> or <literal>\\connect [ -reuse-previous=<replaceable class=\"parameter\">on|off</replaceable> ] [ <replaceable class=\"parameter\">dbname</replaceable> [ <replaceable class=\"parameter\">username</replaceable> ] [ <replaceable class=\"parameter\">host</replaceable> ] [ <replaceable class=\"parameter\">port</replaceable> ] | <replaceable class=\"parameter\">conninfo</replaceable> ]</literal></term>\n        <listitem>\n        <para>\n        Establishes a new connection to a <productname>PostgreSQL</productname>\n        server.  The connection parameters to use can be specified either\n        using a positional syntax (one or more of database name, user,\n        host, and port), or using a <repl", "score": 0.5369553565979004}], "flags": {}, "error": null}}, "evaluations": {"prompt": {"quality_score": 0.5, "penalty_total": 0.5, "rule_breakdown": [{"rule": "prompt_docs_evidence_check", "penalty": 0.5, "hallucination_flags": [], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "note": "Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "notes": "Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}, "rag": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}}, "summary_metrics": {"winner_by_quality": "rag", "winner_by_latency": "rag", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": null, "winner_by_expect_ties": ["prompt", "rag"]}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251230T011239Z:010:create_index_concurrently", "timestamp": "2025-12-30T01:13:47.465195Z", "domain": "postgresql_docs", "mode": "docs", "query": "How do I create an index concurrently in PostgreSQL, and what is a key limitation?", "case": {"id": "create_index_concurrently", "tags": ["indexing", "performance"], "answerable_from_general_knowledge": false, "requires_docs": true, "expected_abstain_in_docs": null}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "To create an index concurrently in PostgreSQL, you can use the `CREATE INDEX` statement with the `CONCURRENTLY` option. The syntax is as follows:\n\n```sql\nCREATE INDEX CONCURRENTLY index_name ON table_name (column_name);\n```\n\nThis allows you to create an index without locking the table for writes, which means that other transactions can continue to insert, update, or delete rows in the table while the index is being built.\n\nA key limitation of creating an index concurrently is that you cannot run this command inside a transaction block. This means you must execute it as a standalone command, not wrapped in a `BEGIN` and `COMMIT` block.\n\nFor more details, you can refer to the official PostgreSQL documentation on the `CREATE INDEX` command.", "latency_ms": 4652, "tokens_in": 152, "tokens_out": 157, "cost_estimate_usd": 0.000117, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "To create an index concurrently in PostgreSQL, you can use the `CREATE INDEX` command with the `CONCURRENTLY` option. This allows the index to be built without locking out writes to the table, enabling concurrent inserts, updates, or deletes while the index is being created [11209][11185].\n\nA key limitation of creating an index concurrently is that it cannot be performed within a transaction block. Additionally, only one concurrent index build can occur on a table at a time, and schema modifications to the table are not allowed while the index is being built [11214].", "latency_ms": 3099, "tokens_in": 1579, "tokens_out": 117, "cost_estimate_usd": 0.00030705, "retrieved_chunks": [{"chunk_id": 11209, "source": "domains/postgresql_docs/data/ref/create_index.sgml", "text_preview": "they will block until the\n    index build is finished. This could have a severe effect if the system is\n    a live production database.  Very large tables can take many hours to be\n    indexed, and even for smaller tables, an index build can lock out writers\n    for periods that are unacceptably long for a production system.\n   </para>\n\n   <para>\n    <productname>PostgreSQL</productname> supports building indexes without locking\n    out writes.  This method is invoked by specifying the\n    <literal>CONCURRENTLY</literal> option of <command>CREATE INDEX</command>.\n    When this option is used,\n    <productname>PostgreSQL</productname> must perform two scans of the table, and in\n    addition it must wait for all existing transactions that could potentially\n    modify or use the index to terminate.  Thus\n    this method requires more total work than a standard index build and takes\n    sign", "score": 0.6457175016403198}, {"chunk_id": 11225, "source": "domains/postgresql_docs/data/ref/create_index.sgml", "text_preview": "setting it as part of tuning an index build.  This avoids\n    inadvertent changes to query plans, since\n    <literal>parallel_workers</literal> affects\n    <emphasis>all</emphasis> parallel table scans.\n   </para>\n  </tip>\n\n  <para>\n   While <command>CREATE INDEX</command> with the\n   <literal>CONCURRENTLY</literal> option supports parallel builds\n   without special restrictions, only the first table scan is actually\n   performed in parallel.\n  </para>\n\n  <para>\n   Use <link linkend=\"sql-dropindex\"><command>DROP INDEX</command></link>\n   to remove an index.\n  </para>\n\n  <para>\n   Like any long-running transaction, <command>CREATE INDEX</command> on a\n   table can affect which tuples can be removed by concurrent\n   <command>VACUUM</command> on any other table.\n  </para>\n\n  <para>\n   Prior releases of <productname>PostgreSQL</productname> also had an\n   R-tree index method.  This metho", "score": 0.6310847401618958}, {"chunk_id": 5996, "source": "domains/postgresql_docs/data/indices.sgml", "text_preview": "In production environments this is often unacceptable.\n   It is possible to allow writes to occur in parallel with index\n   creation, but there are several caveats to be aware of &mdash;\n   for more information see <xref linkend=\"sql-createindex-concurrently\"/>.\n  </para>\n\n  <para>\n   After an index is created, the system has to keep it synchronized with the\n   table.  This adds overhead to data manipulation operations.  Indexes can\n   also prevent the creation of <link linkend=\"storage-hot\">heap-only\n   tuples</link>.\n   Therefore indexes that are seldom or never used in queries\n   should be removed.\n  </para>\n </sect1>\n\n\n <sect1 id=\"indexes-types\">\n  <title>Index Types</title>\n\n  <para>\n   <productname>PostgreSQL</productname> provides several index types:\n   B-tree, Hash, GiST, SP-GiST, GIN, BRIN, and the extension <link\n   linkend=\"bloom\">bloom</link>.\n   Each index type uses a di", "score": 0.6307604312896729}, {"chunk_id": 11215, "source": "domains/postgresql_docs/data/ref/create_index.sgml", "text_preview": "on block, but <command>CREATE INDEX CONCURRENTLY</command>\n    cannot.\n   </para>\n\n   <para>\n    Concurrent builds for indexes on partitioned tables are currently not\n    supported.  However, you may concurrently build the index on each\n    partition individually and then finally create the partitioned index\n    non-concurrently in order to reduce the time where writes to the\n    partitioned table will be locked out.  In this case, building the\n    partitioned index is a metadata only operation.\n   </para>\n\n  </refsect2>\n </refsect1>\n\n <refsect1>\n  <title>Notes</title>\n\n  <para>\n   See <xref linkend=\"indexes\"/> for information about when indexes can\n   be used, when they are not used, and in which particular situations\n   they can be useful.\n  </para>\n\n  <para>\n   Currently, only the B-tree, GiST, GIN, and BRIN index methods support\n   multiple-key-column indexes.  Whether there can be m", "score": 0.6011314392089844}, {"chunk_id": 11214, "source": "domains/postgresql_docs/data/ref/create_index.sgml", "text_preview": "quote> index\n    continues to enforce its uniqueness constraint afterwards.\n   </para>\n\n   <para>\n    Concurrent builds of expression indexes and partial indexes are supported.\n    Errors occurring in the evaluation of these expressions could cause\n    behavior similar to that described above for unique constraint violations.\n   </para>\n\n   <para>\n    Regular index builds permit other regular index builds on the\n    same table to occur simultaneously, but only one concurrent index build\n    can occur on a table at a time.  In either case, schema modification of the\n    table is not allowed while the index is being built.  Another difference is\n    that a regular <command>CREATE INDEX</command> command can be performed\n    within a transaction block, but <command>CREATE INDEX CONCURRENTLY</command>\n    cannot.\n   </para>\n\n   <para>\n    Concurrent builds for indexes on partitioned tables a", "score": 0.5830897688865662}, {"chunk_id": 11185, "source": "domains/postgresql_docs/data/ref/create_index.sgml", "text_preview": "this option is used, <productname>PostgreSQL</productname> will build the\n        index without taking any locks that prevent concurrent inserts,\n        updates, or deletes on the table; whereas a standard index build\n        locks out writes (but not reads) on the table until it's done.\n        There are several caveats to be aware of when using this option\n        &mdash; see <xref linkend=\"sql-createindex-concurrently\"/> below.\n       </para>\n       <para>\n        For temporary tables, <command>CREATE INDEX</command> is always\n        non-concurrent, as no other session can access them, and\n        non-concurrent index creation is cheaper.\n       </para>\n      </listitem>\n     </varlistentry>\n\n     <varlistentry>\n      <term><literal>IF NOT EXISTS</literal></term>\n      <listitem>\n       <para>\n        Do not throw an error if a relation with the same name already exists.\n        A", "score": 0.5730980038642883}], "flags": {}, "error": null}}, "evaluations": {"prompt": {"quality_score": 0.35, "penalty_total": 0.65, "rule_breakdown": [{"rule": "overconfident_language_check", "penalty": 0.15, "hallucination_flags": ["OVERCONFIDENT_LANGUAGE"], "grounding_flags": [], "note": "Overconfident language detected."}, {"rule": "prompt_docs_evidence_check", "penalty": 0.5, "hallucination_flags": [], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "note": "Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}], "expect_score": 0.5, "expect_details": {"missing": ["cannot run inside a transaction | not in a transaction block | outside a transaction"]}, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": ["OVERCONFIDENT_LANGUAGE"], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "notes": "Overconfident language detected. Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}, "rag": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 0.0, "expect_details": {"missing": ["CREATE INDEX CONCURRENTLY", "cannot run inside a transaction | not in a transaction block | outside a transaction"]}, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}}, "summary_metrics": {"winner_by_quality": "rag", "winner_by_latency": "rag", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": "prompt"}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251230T011239Z:011:vacuum_full_lock", "timestamp": "2025-12-30T01:13:50.452709Z", "domain": "postgresql_docs", "mode": "docs", "query": "What does VACUUM FULL do, and what kind of lock does it require?", "case": {"id": "vacuum_full_lock", "tags": ["maintenance", "edge_case"], "answerable_from_general_knowledge": false, "requires_docs": true, "expected_abstain_in_docs": null}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "`VACUUM FULL` in PostgreSQL is a command that reclaims storage by compacting the table and its associated indexes. It does this by creating a new copy of the table with the dead tuples removed and then replacing the old table with the new one. This process can significantly reduce the size of the table on disk.\n\nRegarding locking, `VACUUM FULL` requires an exclusive lock on the table it is processing. This means that while `VACUUM FULL` is running, no other transactions can access the table for reading or writing until the vacuum operation is complete.\n\nFor more details, you can refer to the official PostgreSQL documentation on the `VACUUM` command.", "latency_ms": 2981, "tokens_in": 151, "tokens_out": 139, "cost_estimate_usd": 0.00010605, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "`VACUUM FULL` rewrites the entire contents of a table into a new disk file with no extra space, allowing unused space to be returned to the operating system. This process is much slower than a standard `VACUUM` and requires an `ACCESS EXCLUSIVE` lock on each table while it is being processed [14046].", "latency_ms": 1713, "tokens_in": 1663, "tokens_out": 69, "cost_estimate_usd": 0.00029084999999999994, "retrieved_chunks": [{"chunk_id": 14046, "source": "domains/postgresql_docs/data/ref/vacuum.sgml", "text_preview": "l workers as zero.  <command>VACUUM FULL</command> rewrites\n   the entire contents of the table into a new disk file with no extra space,\n   allowing unused space to be returned to the operating system.  This form is\n   much slower and requires an <literal>ACCESS EXCLUSIVE</literal> lock on\n   each table while it is being processed.\n  </para>\n </refsect1>\n\n <refsect1>\n  <title>Parameters</title>\n\n  <variablelist>\n   <varlistentry>\n    <term><literal>FULL</literal></term>\n    <listitem>\n     <para>\n      Selects <quote>full</quote> vacuum, which can reclaim more\n      space, but takes much longer and exclusively locks the table.\n      This method also requires extra disk space, since it writes a\n      new copy of the table and doesn't release the old copy until\n      the operation is complete.  Usually this should only be used when a\n      significant amount of space needs to be reclaimed", "score": 0.528120756149292}, {"chunk_id": 14070, "source": "domains/postgresql_docs/data/ref/vacuum.sgml", "text_preview": "command>VACUUM FULL</command> will instead report their progress in the\n    <structname>pg_stat_progress_cluster</structname> view. See\n    <xref linkend=\"vacuum-progress-reporting\"/> and\n    <xref linkend=\"cluster-progress-reporting\"/> for details.\n   </para>\n </refsect1>\n\n <refsect1>\n  <title>Examples</title>\n\n  <para>\n   To clean a single table <structname>onek</structname>, analyze it for\n   the optimizer and print a detailed vacuum activity report:\n\n<programlisting>\nVACUUM (VERBOSE, ANALYZE) onek;\n</programlisting></para>\n </refsect1>\n\n <refsect1>\n  <title>Compatibility</title>\n\n  <para>\n   There is no <command>VACUUM</command> statement in the SQL standard.\n  </para>\n\n  <para>\n   The following syntax was used before <productname>PostgreSQL</productname>\n   version 9.0 and is still supported:\n<synopsis>\nVACUUM [ FULL ] [ FREEZE ] [ VERBOSE ] [ ANALYZE ] [ <replaceable class=\"paramet", "score": 0.5025314092636108}, {"chunk_id": 14068, "source": "domains/postgresql_docs/data/ref/vacuum.sgml", "text_preview": "acuum</quote> facility which can automate routine vacuum\n    maintenance.  For more information about automatic and manual vacuuming,\n    see <xref linkend=\"routine-vacuuming\"/>.\n   </para>\n\n   <para>\n    The <option>FULL</option> option is not recommended for routine use,\n    but might be useful in special cases.  An example is when you have deleted\n    or updated most of the rows in a table and would like the table to\n    physically shrink to occupy less disk space and allow faster table\n    scans. <command>VACUUM FULL</command> will usually shrink the table\n    more than a plain <command>VACUUM</command> would.\n   </para>\n\n   <para>\n     The <option>PARALLEL</option> option is used only for vacuum purposes.\n     If this option is specified with the <option>ANALYZE</option> option,\n     it does not affect <option>ANALYZE</option>.\n   </para>\n\n   <para>\n    <command>VACUUM</command> cau", "score": 0.4862546920776367}, {"chunk_id": 7801, "source": "domains/postgresql_docs/data/maintenance.sgml", "text_preview": "ated to the point that <command>VACUUM FULL</command> is really necessary\n    to reclaim space.  Using the autovacuum daemon alleviates this problem,\n    since the daemon schedules vacuuming dynamically in response to update\n    activity.  It is unwise to disable the daemon completely unless you\n    have an extremely predictable workload.  One possible compromise is\n    to set the daemon's parameters so that it will only react to unusually\n    heavy update activity, thus keeping things from getting out of hand,\n    while scheduled <command>VACUUM</command>s are expected to do the bulk of the\n    work when the load is typical.\n   </para>\n\n   <para>\n    For those not using autovacuum, a typical approach is to schedule a\n    database-wide <command>VACUUM</command> once a day during a low-usage period,\n    supplemented by more frequent vacuuming of heavily-updated tables as\n    necessary. (S", "score": 0.4721943736076355}, {"chunk_id": 7796, "source": "domains/postgresql_docs/data/maintenance.sgml", "text_preview": "t be able to modify the definition of a table with commands such as\n    <command>ALTER TABLE</command> while it is being vacuumed.)\n    <command>VACUUM FULL</command> requires an\n    <literal>ACCESS EXCLUSIVE</literal> lock on the table it is\n    working on, and therefore cannot be done in parallel with other use\n    of the table.  Generally, therefore,\n    administrators should strive to use standard <command>VACUUM</command> and\n    avoid <command>VACUUM FULL</command>.\n   </para>\n\n   <para>\n    <command>VACUUM</command> creates a substantial amount of I/O\n    traffic, which can cause poor performance for other active sessions.\n    There are configuration parameters that can be adjusted to reduce the\n    performance impact of background vacuuming &mdash; see\n    <xref linkend=\"runtime-config-resource-vacuum-cost\"/>.\n   </para>\n  </sect2>\n\n  <sect2 id=\"vacuum-for-space-recovery\">\n   <ti", "score": 0.4600721001625061}, {"chunk_id": 14054, "source": "domains/postgresql_docs/data/ref/vacuum.sgml", "text_preview": "ignored if the <literal>FULL</literal> option is used.  It also\n      has no effect on the transaction ID wraparound failsafe\n      mechanism.  When triggered it will skip index vacuuming, even\n      when <literal>INDEX_CLEANUP</literal> is set to\n      <literal>ON</literal>.\n     </para>\n    </listitem>\n   </varlistentry>\n\n   <varlistentry>\n    <term><literal>PROCESS_MAIN</literal></term>\n    <listitem>\n     <para>\n      Specifies that <command>VACUUM</command> should attempt to process the\n      main relation. This is usually the desired behavior and is the default.\n      Setting this option to false may be useful when it is only necessary to\n      vacuum a relation's corresponding <literal>TOAST</literal> table.\n     </para>\n    </listitem>\n   </varlistentry>\n\n   <varlistentry>\n    <term><literal>PROCESS_TOAST</literal></term>\n    <listitem>\n     <para>\n      Specifies that <command>V", "score": 0.4518793821334839}], "flags": {}, "error": null}}, "evaluations": {"prompt": {"quality_score": 0.5, "penalty_total": 0.5, "rule_breakdown": [{"rule": "prompt_docs_evidence_check", "penalty": 0.5, "hallucination_flags": [], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "note": "Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "notes": "Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}, "rag": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}}, "summary_metrics": {"winner_by_quality": "rag", "winner_by_latency": "rag", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": null, "winner_by_expect_ties": ["prompt", "rag"]}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251230T011239Z:012:identity_columns", "timestamp": "2025-12-30T01:13:54.458449Z", "domain": "postgresql_docs", "mode": "docs", "query": "How do I define an IDENTITY column in PostgreSQL? Show a minimal example.", "case": {"id": "identity_columns", "tags": ["sql", "ddl"], "answerable_from_general_knowledge": false, "requires_docs": true, "expected_abstain_in_docs": null}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "In PostgreSQL, you can define an IDENTITY column using the `IDENTITY` keyword in your table definition. This feature allows you to create a column that automatically generates unique values, similar to the `SERIAL` type but with more flexibility.\n\nHere is a minimal example of how to define an IDENTITY column:\n\n```sql\nCREATE TABLE example_table (\n    id INT GENERATED ALWAYS AS IDENTITY,\n    name VARCHAR(100)\n);\n```\n\nIn this example, the `id` column is defined as an `INT` type and is set to automatically generate unique values using the `GENERATED ALWAYS AS IDENTITY` clause. You can also use `GENERATED BY DEFAULT AS IDENTITY` if you want to allow explicit values to be inserted into the column.\n\nThis is how you define an IDENTITY column in PostgreSQL.", "latency_ms": 3998, "tokens_in": 151, "tokens_out": 167, "cost_estimate_usd": 0.00012285, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "To define an IDENTITY column in PostgreSQL, you can use the `CREATE TABLE` statement with the `IDENTITY` keyword. Here is a minimal example:\n\n```sql\nCREATE TABLE example (\n    id INT GENERATED ALWAYS AS IDENTITY,\n    name TEXT\n);\n```\n\nIn this example, the `id` column is defined as an identity column that automatically generates values. The `GENERATED ALWAYS AS IDENTITY` clause specifies that the values for this column will be generated automatically by PostgreSQL [11672].", "latency_ms": 2220, "tokens_in": 1610, "tokens_out": 104, "cost_estimate_usd": 0.0003039, "retrieved_chunks": [{"chunk_id": 11673, "source": "domains/postgresql_docs/data/ref/create_table.sgml", "text_preview": "le>Multiple Identity Columns</title>\n\n   <para>\n    <productname>PostgreSQL</productname> allows a table to have more than one\n    identity column.  The standard specifies that a table can have at most one\n    identity column.  This is relaxed mainly to give more flexibility for\n    doing schema changes or migrations.  Note that\n    the <command>INSERT</command> command supports only one override clause\n    that applies to the entire statement, so having multiple identity columns\n    with different behaviors is not well supported.\n   </para>\n  </refsect2>\n\n  <refsect2>\n   <title>Generated Columns</title>\n\n   <para>\n    The options <literal>STORED</literal> and <literal>VIRTUAL</literal> are\n    not standard but are also used by other SQL implementations.  The SQL\n    standard does not specify the storage of generated columns.\n   </para>\n  </refsect2>\n\n  <refsect2>\n   <title><literal>LIKE", "score": 0.6397973895072937}, {"chunk_id": 6175, "source": "domains/postgresql_docs/data/information_schema.sgml", "text_preview": "an identity column, then the increment of the internal\n       sequence, else null.\n      </para></entry>\n     </row>\n\n     <row>\n      <entry role=\"catalog_table_entry\"><para role=\"column_definition\">\n       <structfield>identity_maximum</structfield> <type>character_data</type>\n      </para>\n      <para>\n       If the column is an identity column, then the maximum value of the\n       internal sequence, else null.\n      </para></entry>\n     </row>\n\n     <row>\n      <entry role=\"catalog_table_entry\"><para role=\"column_definition\">\n       <structfield>identity_minimum</structfield> <type>character_data</type>\n      </para>\n      <para>\n       If the column is an identity column, then the minimum value of the\n       internal sequence, else null.\n      </para></entry>\n     </row>\n\n     <row>\n      <entry role=\"catalog_table_entry\"><para role=\"column_definition\">\n       <structfield>identity_", "score": 0.5899851322174072}, {"chunk_id": 6174, "source": "domains/postgresql_docs/data/information_schema.sgml", "text_preview": "ara>\n       If the column is an identity column, then <literal>ALWAYS</literal>\n       or <literal>BY DEFAULT</literal>, reflecting the definition of the\n       column.\n      </para></entry>\n     </row>\n\n     <row>\n      <entry role=\"catalog_table_entry\"><para role=\"column_definition\">\n       <structfield>identity_start</structfield> <type>character_data</type>\n      </para>\n      <para>\n       If the column is an identity column, then the start value of the\n       internal sequence, else null.\n      </para></entry>\n     </row>\n\n     <row>\n      <entry role=\"catalog_table_entry\"><para role=\"column_definition\">\n       <structfield>identity_increment</structfield> <type>character_data</type>\n      </para>\n      <para>\n       If the column is an identity column, then the increment of the internal\n       sequence, else null.\n      </para></entry>\n     </row>\n\n     <row>\n      <entry role=\"ca", "score": 0.5752883553504944}, {"chunk_id": 2276, "source": "domains/postgresql_docs/data/datatype.sgml", "text_preview": "mary>\n    </indexterm>\n\n    <indexterm>\n     <primary>auto-increment</primary>\n     <see>serial</see>\n    </indexterm>\n\n    <indexterm>\n     <primary>sequence</primary>\n     <secondary>and serial type</secondary>\n    </indexterm>\n\n    <note>\n     <para>\n      This section describes a PostgreSQL-specific way to create an\n      autoincrementing column.  Another way is to use the SQL-standard\n      identity column feature, described at <xref linkend=\"ddl-identity-columns\"/>.\n     </para>\n    </note>\n\n    <para>\n     The data types <type>smallserial</type>, <type>serial</type> and\n     <type>bigserial</type> are not true types, but merely\n     a notational convenience for creating unique identifier columns\n     (similar to the <literal>AUTO_INCREMENT</literal> property\n     supported by some other databases). In the current\n     implementation, specifying:\n\n<programlisting>\nCREATE TABLE <rep", "score": 0.569333553314209}, {"chunk_id": 2640, "source": "domains/postgresql_docs/data/ddl.sgml", "text_preview": "afterwards (see\n   <xref linkend=\"sql-altertable\"/>).\n  </para>\n\n  <para>\n   An identity column is automatically marked as <literal>NOT NULL</literal>.\n   An identity column, however, does not guarantee uniqueness.  (A sequence\n   normally returns unique values, but a sequence could be reset, or values\n   could be inserted manually into the identity column, as discussed above.)\n   Uniqueness would need to be enforced using a <literal>PRIMARY KEY</literal>\n   or <literal>UNIQUE</literal> constraint.\n  </para>\n\n  <para>\n   In table inheritance hierarchies, identity columns and their properties in\n   a child table are independent of those in its parent tables.  A child table\n   does not inherit identity columns or their properties automatically from\n   the parent. During <command>INSERT</command> or <command>UPDATE</command>,\n   a column is treated as an identity column if that column is an", "score": 0.5688140392303467}, {"chunk_id": 11672, "source": "domains/postgresql_docs/data/ref/create_table.sgml", "text_preview": "le inheritance using a\n    different syntax and different semantics.  SQL:1999-style\n    inheritance is not yet supported by\n    <productname>PostgreSQL</productname>.\n   </para>\n  </refsect2>\n\n  <refsect2>\n   <title>Zero-Column Tables</title>\n\n   <para>\n    <productname>PostgreSQL</productname> allows a table of no columns\n    to be created (for example, <literal>CREATE TABLE foo();</literal>).  This\n    is an extension from the SQL standard, which does not allow zero-column\n    tables.  Zero-column tables are not in themselves very useful, but\n    disallowing them creates odd special cases for <command>ALTER TABLE\n    DROP COLUMN</command>, so it seems cleaner to ignore this spec restriction.\n   </para>\n  </refsect2>\n\n  <refsect2>\n   <title>Multiple Identity Columns</title>\n\n   <para>\n    <productname>PostgreSQL</productname> allows a table to have more than one\n    identity column.  T", "score": 0.5682658553123474}], "flags": {}, "error": null}}, "evaluations": {"prompt": {"quality_score": 0.35, "penalty_total": 0.65, "rule_breakdown": [{"rule": "overconfident_language_check", "penalty": 0.15, "hallucination_flags": ["OVERCONFIDENT_LANGUAGE"], "grounding_flags": [], "note": "Overconfident language detected."}, {"rule": "prompt_docs_evidence_check", "penalty": 0.5, "hallucination_flags": [], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "note": "Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": ["OVERCONFIDENT_LANGUAGE"], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "notes": "Overconfident language detected. Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}, "rag": {"quality_score": 0.85, "penalty_total": 0.15, "rule_breakdown": [{"rule": "overconfident_language_check", "penalty": 0.15, "hallucination_flags": ["OVERCONFIDENT_LANGUAGE"], "grounding_flags": [], "note": "Overconfident language detected."}], "expect_score": 1.0, "expect_details": null, "abstained": false, "abstention_expected": false, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": ["OVERCONFIDENT_LANGUAGE"], "grounding_flags": [], "notes": "Overconfident language detected."}}, "summary_metrics": {"winner_by_quality": "rag", "winner_by_latency": "rag", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": null, "winner_by_expect_ties": ["prompt", "rag"]}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251230T011239Z:013:trap_builtin_sharding", "timestamp": "2025-12-30T01:13:56.287989Z", "domain": "postgresql_docs", "mode": "docs", "query": "Does PostgreSQL support sharding out of the box? Answer only if the PostgreSQL docs explicitly say so.", "case": {"id": "trap_builtin_sharding", "tags": ["trap", "edge_case", "unsupported_claim"], "answerable_from_general_knowledge": true, "requires_docs": false, "expected_abstain_in_docs": true}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "The PostgreSQL documentation does not state that sharding is supported out of the box. Sharding typically requires third-party solutions or custom implementations, as PostgreSQL does not natively include built-in sharding functionality.", "latency_ms": 1798, "tokens_in": 156, "tokens_out": 42, "cost_estimate_usd": 4.86e-05, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "I don't know.", "latency_ms": 727, "tokens_in": 1681, "tokens_out": 4, "cost_estimate_usd": 0.00025455, "retrieved_chunks": [{"chunk_id": 6644, "source": "domains/postgresql_docs/data/installation.sgml", "text_preview": "n it is convenient if every\n    user that plans to use the database sets <envar>PGHOST</envar>.  This\n    is not required, however; the settings can be communicated via command\n    line options to most client programs.\n   </para>\n  </sect2>\n </sect1>\n\n <sect1 id=\"supported-platforms\">\n  <title>Supported Platforms</title>\n\n  <para>\n   A platform (that is, a CPU architecture and operating system combination)\n   is considered supported by the <productname>PostgreSQL</productname> development\n   community if the code contains provisions to work on that platform and\n   it has recently been verified to build and pass its regression tests\n   on that platform.  Currently, most testing of platform compatibility\n   is done automatically by test machines in the\n   <ulink url=\"https://buildfarm.postgresql.org/\">PostgreSQL Build Farm</ulink>.\n   If you are interested in using <productname>PostgreSQL<", "score": 0.48643308877944946}, {"chunk_id": 5711, "source": "domains/postgresql_docs/data/high-availability.sgml", "text_preview": "though its big\n     advantage is that any server can accept write requests &mdash;\n     there is no need to partition workloads between primary and\n     standby servers, and because the data changes are sent from one\n     server to another, there is no problem with non-deterministic\n     functions like <function>random()</function>.\n    </para>\n\n    <para>\n     <productname>PostgreSQL</productname> does not offer this type of replication,\n     though <productname>PostgreSQL</productname> two-phase commit (<xref\n     linkend=\"sql-prepare-transaction\"/> and <xref\n     linkend=\"sql-commit-prepared\"/>)\n     can be used to implement this in application code or middleware.\n    </para>\n   </listitem>\n  </varlistentry>\n\n </variablelist>\n\n <para>\n  <xref linkend=\"high-availability-matrix\"/> summarizes\n  the capabilities of the various solutions listed above.\n </para>\n\n <table id=\"high-availabili", "score": 0.4832221269607544}, {"chunk_id": 7872, "source": "domains/postgresql_docs/data/manage-ag.sgml", "text_preview": "different databases.\n   Database-level security has two components: access control\n   (see <xref linkend=\"auth-pg-hba-conf\"/>), managed at the\n   connection level, and authorization control\n   (see <xref linkend=\"ddl-priv\"/>), managed via the grant system.\n   Foreign data wrappers (see <xref linkend=\"postgres-fdw\"/>)\n   allow for objects within one database to act as proxies for objects in\n   other database or clusters.\n   The older dblink module (see <xref linkend=\"dblink\"/>) provides a similar capability.\n   By default, all users can connect to all databases using all connection methods.\n  </para>\n\n  <para>\n   If one <productname>PostgreSQL</productname> server cluster is planned to contain\n   unrelated projects or users that should be, for the most part, unaware\n   of each other, it is recommended to put them into separate databases and\n   adjust authorizations and access controls acc", "score": 0.4763585925102234}, {"chunk_id": 10813, "source": "domains/postgresql_docs/data/ref/clusterdb.sgml", "text_preview": "<!--\ndoc/src/sgml/ref/clusterdb.sgml\nPostgreSQL documentation\n-->\n\n<refentry id=\"app-clusterdb\">\n <indexterm zone=\"app-clusterdb\">\n  <primary>clusterdb</primary>\n </indexterm>\n\n <refmeta>\n  <refentrytitle><application>clusterdb</application></refentrytitle>\n  <manvolnum>1</manvolnum>\n  <refmiscinfo>Application</refmiscinfo>\n </refmeta>\n\n <refnamediv>\n  <refname>clusterdb</refname>\n  <refpurpose>cluster a <productname>PostgreSQL</productname> database</refpurpose>\n </refnamediv>\n\n <refsynopsisdiv>\n  <cmdsynopsis>\n   <command>clusterdb</command>\n   <arg rep=\"repeat\"><replaceable>connection-option</replaceable></arg>\n   <arg rep=\"repeat\"><replaceable>option</replaceable></arg>\n\n   <arg choice=\"plain\" rep=\"repeat\">\n     <arg choice=\"opt\">\n       <group choice=\"plain\">\n         <arg choice=\"plain\"><option>--table</option></arg>\n         <arg choice=\"plain\"><option>-t</option></arg>\n       </g", "score": 0.475017249584198}, {"chunk_id": 10800, "source": "domains/postgresql_docs/data/ref/cluster.sgml", "text_preview": "<!--\ndoc/src/sgml/ref/cluster.sgml\nPostgreSQL documentation\n-->\n\n<refentry id=\"sql-cluster\">\n <indexterm zone=\"sql-cluster\">\n  <primary>CLUSTER</primary>\n </indexterm>\n\n <refmeta>\n  <refentrytitle>CLUSTER</refentrytitle>\n  <manvolnum>7</manvolnum>\n  <refmiscinfo>SQL - Language Statements</refmiscinfo>\n </refmeta>\n\n <refnamediv>\n  <refname>CLUSTER</refname>\n  <refpurpose>cluster a table according to an index</refpurpose>\n </refnamediv>\n\n <refsynopsisdiv>\n<synopsis>\nCLUSTER [ ( <replaceable class=\"parameter\">option</replaceable> [, ...] ) ] [ <replaceable class=\"parameter\">table_name</replaceable> [ USING <replaceable class=\"parameter\">index_name</replaceable> ] ]\n\n<phrase>where <replaceable class=\"parameter\">option</replaceable> can be one of:</phrase>\n\n    VERBOSE [ <replaceable class=\"parameter\">boolean</replaceable> ]\n</synopsis>\n </refsynopsisdiv>\n\n <refsect1>\n  <title>Description</ti", "score": 0.4738888144493103}, {"chunk_id": 922, "source": "domains/postgresql_docs/data/catalogs.sgml", "text_preview": "es are made\n   in <structname>pg_shdepend</structname> that would have a pinned\n   object as either referenced or dependent object.\n  </para>\n\n </sect1>\n\n <sect1 id=\"catalog-pg-shdescription\">\n  <title><structname>pg_shdescription</structname></title>\n\n  <indexterm zone=\"catalog-pg-shdescription\">\n   <primary>pg_shdescription</primary>\n  </indexterm>\n\n  <para>\n   The catalog <structname>pg_shdescription</structname> stores optional\n   descriptions (comments) for shared database objects.  Descriptions can be\n   manipulated with the <link linkend=\"sql-comment\"><command>COMMENT</command></link> command and viewed with\n   <application>psql</application>'s <literal>\\d</literal> commands.\n  </para>\n\n  <para>\n   See also <link linkend=\"catalog-pg-description\"><structname>pg_description</structname></link>,\n   which performs a similar function for descriptions involving objects\n   within a singl", "score": 0.4698563814163208}], "flags": {}, "error": null}}, "evaluations": {"prompt": {"quality_score": 0.5, "penalty_total": 0.5, "rule_breakdown": [{"rule": "prompt_docs_evidence_check", "penalty": 0.5, "hallucination_flags": [], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "note": "Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}], "expect_score": 0.0, "expect_details": {"missing": ["IDK_EXPECTED"]}, "abstained": false, "abstention_expected": true, "abstention_correct": false, "abstention_score": 0.0, "hallucination_flags": [], "grounding_flags": ["PROMPT_NO_EVIDENCE_IN_DOCS"], "notes": "Docs-grounded mode: prompt-only has no retrieved evidence; treat non-abstaining answers as ungrounded."}, "rag": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": true, "abstention_expected": true, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}}, "summary_metrics": {"winner_by_quality": "rag", "winner_by_latency": "rag", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": "rag"}, "judge": null, "proxies": null}
{"run_id": "regression:postgresql_docs_mvp_v1:20251230T011239Z:014:trap_capital_france", "timestamp": "2025-12-30T01:13:57.109066Z", "domain": "postgresql_docs", "mode": "docs", "query": "What is the capital of France? Answer only if the PostgreSQL docs explicitly say so.", "case": {"id": "trap_capital_france", "tags": ["trap", "edge_case", "unsupported_claim"], "answerable_from_general_knowledge": true, "requires_docs": false, "expected_abstain_in_docs": true}, "scoring": null, "results": {"prompt": {"pipeline": "prompt", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "I don't know.", "latency_ms": 500, "tokens_in": 152, "tokens_out": 4, "cost_estimate_usd": 2.5200000000000003e-05, "retrieved_chunks": null, "flags": {}, "error": null}, "rag": {"pipeline": "rag", "model": "gpt-4o-mini", "generation_config": {"temperature": 0.2, "top_p": 1.0, "max_tokens": 800}, "answer": "I don't know.", "latency_ms": 796, "tokens_in": 1713, "tokens_out": 4, "cost_estimate_usd": 0.00025935, "retrieved_chunks": [{"chunk_id": 13276, "source": "domains/postgresql_docs/data/ref/postgres-ref.sgml", "text_preview": "<!--\ndoc/src/sgml/ref/postgres-ref.sgml\nPostgreSQL documentation\n-->\n\n<refentry id=\"app-postgres\">\n <indexterm zone=\"app-postgres\">\n  <primary>postgres</primary>\n </indexterm>\n\n <refmeta>\n  <refentrytitle><application>postgres</application></refentrytitle>\n  <manvolnum>1</manvolnum>\n  <refmiscinfo>Application</refmiscinfo>\n </refmeta>\n\n <refnamediv>\n  <refname>postgres</refname>\n  <refpurpose><productname>PostgreSQL</productname> database server</refpurpose>\n </refnamediv>\n\n <refsynopsisdiv>\n  <cmdsynopsis>\n   <command>postgres</command>\n   <arg rep=\"repeat\"><replaceable>option</replaceable></arg>\n  </cmdsynopsis>\n </refsynopsisdiv>\n\n <refsect1>\n  <title>Description</title>\n\n  <para>\n   <command>postgres</command> is the\n   <productname>PostgreSQL</productname> database server.  In order\n   for a client application to access a database it connects (over a\n   network or locally) to a runn", "score": 0.426818311214447}, {"chunk_id": 9621, "source": "domains/postgresql_docs/data/problems.sgml", "text_preview": "d <quote>PostgreSQL</quote>,\n   sometimes <quote>Postgres</quote> for short. If you\n   are specifically talking about the backend process, mention that, do not\n   just say <quote>PostgreSQL crashes</quote>.  A crash of a single\n   backend process is quite different from crash of the parent\n   <quote>postgres</quote> process; please don't say <quote>the server\n   crashed</quote> when you mean a single backend process went down, nor vice versa.\n   Also, client programs such as the interactive frontend <quote><application>psql</application></quote>\n   are completely separate from the backend.  Please try to be specific\n   about whether the problem is on the client or server side.\n  </para>\n </sect2>\n\n <sect2 id=\"bug-reporting-where-to-report-bugs\">\n  <title>Where to Report Bugs</title>\n\n  <para>\n   In general, send bug reports to the bug report mailing list at\n   <email>pgsql-bugs@lists.pos", "score": 0.4207918047904968}, {"chunk_id": 6646, "source": "domains/postgresql_docs/data/installation.sgml", "text_preview": "n current\n   versions of these operating systems: Linux, Windows,\n   FreeBSD, OpenBSD, NetBSD, DragonFlyBSD, macOS, Solaris, and illumos.\n   Other Unix-like systems may also work but are not currently\n   being tested.  In most cases, all CPU architectures supported by\n   a given operating system will work.  Look in\n   <xref linkend=\"installation-platform-notes\"/> below to see if\n   there is information\n   specific to your operating system, particularly if using an older system.\n  </para>\n\n  <para>\n   If you have installation problems on a platform that is known\n   to be supported according to recent build farm results, please report\n   it to <email>pgsql-bugs@lists.postgresql.org</email>.  If you are interested\n   in porting <productname>PostgreSQL</productname> to a new platform,\n   <email>pgsql-hackers@lists.postgresql.org</email> is the appropriate place\n   to discuss that.\n  </para>", "score": 0.4104219079017639}, {"chunk_id": 15011, "source": "domains/postgresql_docs/data/syntax.sgml", "text_preview": "ctname>PostgreSQL</productname> is\n     following the standard.)\n    </para>\n   </sect3>\n\n   <sect3 id=\"sql-syntax-strings-escape\">\n    <title>String Constants with C-Style Escapes</title>\n\n     <indexterm zone=\"sql-syntax-strings-escape\">\n      <primary>escape string syntax</primary>\n     </indexterm>\n     <indexterm zone=\"sql-syntax-strings-escape\">\n      <primary>backslash escapes</primary>\n     </indexterm>\n\n    <para>\n     <productname>PostgreSQL</productname> also accepts <quote>escape</quote>\n     string constants, which are an extension to the SQL standard.\n     An escape string constant is specified by writing the letter\n     <literal>E</literal> (upper or lower case) just before the opening single\n     quote, e.g., <literal>E'foo'</literal>.  (When continuing an escape string\n     constant across lines, write <literal>E</literal> only before the first opening\n     quote.)", "score": 0.40709689259529114}, {"chunk_id": 59, "source": "domains/postgresql_docs/data/advanced.sgml", "text_preview": "name>capitals</structname>\n    <firstterm>inherits</firstterm> all columns (<structfield>name</structfield>,\n    <structfield>population</structfield>, and <structfield>elevation</structfield>) from its\n    <firstterm>parent</firstterm>, <structname>cities</structname>.  The\n    type of the column <structfield>name</structfield> is\n    <type>text</type>, a native <productname>PostgreSQL</productname>\n    type for variable length character strings.  The\n    <structname>capitals</structname> table has\n    an additional column, <structfield>state</structfield>, which shows its\n    state abbreviation.  In\n    <productname>PostgreSQL</productname>, a table can inherit from\n    zero or more other tables.\n   </para>\n\n   <para>\n    For example, the  following  query finds the  names  of  all  cities,\n    including  state capitals, that are located at an elevation\n    over 500 feet:\n\n<programlist", "score": 0.4068037271499634}, {"chunk_id": 9594, "source": "domains/postgresql_docs/data/postgres.sgml", "text_preview": "<!-- doc/src/sgml/postgres.sgml -->\n\n<!DOCTYPE book PUBLIC \"-//OASIS//DTD DocBook XML V4.5//EN\"\n          \"http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd\"\n[\n\n<!ENTITY % version SYSTEM \"version.sgml\">\n%version;\n<!ENTITY % filelist SYSTEM \"filelist.sgml\">\n%filelist;\n\n<!ENTITY commit_baseurl \"https://postgr.es/c/\">\n<!ENTITY reference  SYSTEM \"reference.sgml\">\n\n<!--\nZero-width space.  Use this to allow line breaks at desirable places in\ntable cells, examples, etc. without causing an unwanted space when the\nbreak is not needed in a wider output rendering.\n-->\n<!ENTITY zwsp \"&#x200B;\">\n\n]>\n\n<book id=\"postgres\">\n <title>PostgreSQL &version; Documentation</title>\n\n <bookinfo>\n  <corpauthor>The PostgreSQL Global Development Group</corpauthor>\n  <productname>PostgreSQL</productname>\n  <productnumber>&version;</productnumber>\n  &legal;\n </bookinfo>\n\n &intro;\n\n <part id=\"tutorial\">\n  <title>", "score": 0.4064069986343384}], "flags": {}, "error": null}}, "evaluations": {"prompt": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": true, "abstention_expected": true, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}, "rag": {"quality_score": 1.0, "penalty_total": 0.0, "rule_breakdown": [], "expect_score": 1.0, "expect_details": null, "abstained": true, "abstention_expected": true, "abstention_correct": true, "abstention_score": 1.0, "hallucination_flags": [], "grounding_flags": [], "notes": null}}, "summary_metrics": {"winner_by_quality": null, "winner_by_quality_ties": ["prompt", "rag"], "winner_by_latency": "prompt", "winner_by_cost": "prompt", "tradeoff_summary": "Compare quality vs latency vs cost; prefer grounded answers when needed.", "winner_by_expect": null, "winner_by_expect_ties": ["prompt", "rag"]}, "judge": null, "proxies": null}
