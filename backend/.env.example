# Required
OPENAI_API_KEY=

# Provider
LLM_PROVIDER=openai

# Models
OPENAI_MODEL=gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Generation (shared across pipelines per /run)
GEN_TEMPERATURE=0.2
GEN_TOP_P=1.0
GEN_MAX_OUTPUT_TOKENS=800

# RAG limits
RAG_MAX_CONTEXT_CHARS=12000
RAG_MAX_CHUNKS=8

# Timeouts
PIPELINE_TIMEOUT_S=30

# Safety
MAX_RUN_COST_USD=0.05

# Optional cost estimation (USD per 1M tokens)
OPENAI_COST_INPUT_PER_1M=
OPENAI_COST_OUTPUT_PER_1M=

