# Required
OPENAI_API_KEY=

# Provider
LLM_PROVIDER=openai

# Models
OPENAI_MODEL=gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OPENAI_FINETUNED_MODEL=

# Generation (shared across pipelines per /run)
GEN_TEMPERATURE=0.2
GEN_TOP_P=1.0
GEN_MAX_OUTPUT_TOKENS=800

# RAG limits
RAG_MAX_CONTEXT_CHARS=12000
RAG_MAX_CHUNKS=8

# Timeouts
PIPELINE_TIMEOUT_S=30

# Safety
MAX_RUN_COST_USD=0.05

# Optional cost estimation (USD per 1M tokens)
# Defaults are for gpt-4o-mini (adjust if you change models).
OPENAI_COST_INPUT_PER_1M=0.15
OPENAI_COST_OUTPUT_PER_1M=0.60

# Optional fine-tuned override (if unset, the app assumes ~2x the base rates for ft:* models).
OPENAI_COST_INPUT_PER_1M_FINETUNED=0.30
OPENAI_COST_OUTPUT_PER_1M_FINETUNED=1.20
